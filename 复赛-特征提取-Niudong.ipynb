{"cells":[{"cell_type":"markdown","metadata":{"id":"CD15BE576B4C4D128B3AA9EB9A9A8C76","mdEditEnable":false},"source":"# 特征提取"},{"cell_type":"code","execution_count":4,"metadata":{"id":"40F26B9530E44CC49103F8FD48BE1CBA","scrolled":false,"collapsed":false},"outputs":[{"output_type":"stream","text":"OFFLINE: True\n","name":"stdout"}],"source":"import sys, os, gc, pickle\nimport numpy as np\nimport pandas as pd\nimport scipy\n# import modin.pandas as pd\nsys.path.append(\"./common\")\nsys.path.append(\"./dongdong\")\nsys.path.append(\"./dongdong/utils\")\nfrom np_utils import try_divide\nfrom utils import ReadCSV, Timer, ExtractFeature, ORI_TRAIN_NAMES, ORI_TEST_NAMES, AnalysisCSV, \\\nFuncMap2, FuncMap1, AnalysisHDF, ExtractFeature1\nimport dist_utils, ngram_utils\nbase_feature_save_dir = \"/home/kesci/work/common/features/\"\ntfidf_model_file = \"/home/kesci/work/common/util_models/tfidf_word_ngram-13_online_allUnique.bin\"\nword2vec_kv_model_file = \"/home/kesci/work/common/util_models/word2vec_online_concatHorizontal.kv\"\nword2vec_embed_size = 100\nfrom gensim.models import Word2Vec\n# True: 离线训练(100w)\n# False: 上线训练(5000w)\nOFFLINE = True\ntrain_name = ORI_TRAIN_NAMES\nif OFFLINE:\n    base_prefix = \"debug_\"\n    train_file = \"/home/kesci/work/inputs/train_flast_400w.csv\"\n    test_file = \"/home/kesci/work/inputs/train_flast_100w.csv\"\n    CHUNK_SIZE = 500000\n    test_name = ORI_TRAIN_NAMES\nelse:\n    base_prefix = \"online_\"\n    train_file = \"/home/kesci/work/inputs/train_first_5000w.csv\"\n    test_file = \"/home/kesci/work/inputs/test_final_part1.csv\"\n    CHUNK_SIZE = 50000000 # 256*1024*1024\n    test_name = ORI_TEST_NAMES\nprint(\"OFFLINE:\", OFFLINE)"},{"metadata":{"id":"837CA2757746479A985B5031E81E0E19","mdEditEnable":false},"cell_type":"markdown","source":"## 公共函数"},{"metadata":{"id":"32FF4D349AF642DBA597D049E3755BBC","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"ratio_func = lambda a, b: try_divide(a, b)\ndiff_func = lambda a, b: abs(a-b)\navg_func = lambda a, b: (a+b)/2\nmax_func = lambda a, b: max(a, b)\nmin_func = lambda a, b: min(a, b)\nngram_funcs = {\n    \"unichars\": ngram_utils.unichars,\n    \"bichars\": ngram_utils.bichars,\n    \"trichars\": ngram_utils.trichars,\n    \"unigrams\": ngram_utils.unigrams,\n    \"bigrams\": ngram_utils.bigrams,\n    \"trigrams\": ngram_utils.trigrams,\n}","execution_count":2},{"cell_type":"markdown","metadata":{"id":"3C6CEED2F1574088BFB7BD0B3AFA68C0","mdEditEnable":false},"source":"## 文本挖掘特征"},{"cell_type":"code","execution_count":4,"metadata":{"id":"C1B9B465F2234AD68651BF514CC7D8E6","scrolled":false,"collapsed":false},"outputs":[{"output_type":"stream","text":"total 6.3G\r\ndrwxr-xr-x 2 kesci root  4.0K Aug  4 03:33 .\r\ndrwxr-xr-x 7 kesci root  4.0K Aug  4 03:00 ..\r\n-rw-r--r-- 1 kesci users  12M Aug  2 14:57 debug_testTextMining_editSim.h5\r\n-rw-r--r-- 1 kesci users 2.7M Aug  2 13:50 debug_testTextMining_idfWordShare.h5\r\n-rw-r--r-- 1 kesci users  12M Aug  2 14:13 debug_testTextMining_len.h5\r\n-rw-r--r-- 1 kesci users  15M Aug  4 03:33 debug_testTextMining_ngramSim.h5\r\n-rw-r--r-- 1 kesci users 1.9M Aug  2 13:35 debug_testTextMining_normalWordShare.h5\r\n-rw-r--r-- 1 kesci users 1.9M Aug  2 13:11 debug_testTextMining_wordShare.h5\r\n-rw-r--r-- 1 kesci users  29M Aug  2 14:55 debug_trainTextMining_editSim.h5\r\n-rw-r--r-- 1 kesci users  15M Jul 23 08:47 debug_trainTextMining_editSim_xp.h5\r\n-rw-r--r-- 1 kesci users 724K Jul 20 06:54 debug_trainTextMining_hashSim.h5\r\n-rw-r--r-- 1 kesci users 6.8M Aug  2 13:49 debug_trainTextMining_idfWordShare.h5\r\n-rw-r--r-- 1 kesci users  29M Aug  2 14:10 debug_trainTextMining_len.h5\r\n-rw-r--r-- 1 kesci users 6.0M Jul 22 09:26 debug_trainTextMining_len_xp.h5\r\n-rw-r--r-- 1 kesci users  38M Aug  4 03:32 debug_trainTextMining_ngramSim.h5\r\n-rw-r--r-- 1 kesci users  37M Jul 23 13:29 debug_trainTextMining_ngramSim_xp.h5\r\n-rw-r--r-- 1 kesci users 4.7M Aug  2 13:35 debug_trainTextMining_normalWordShare.h5\r\n-rw-r--r-- 1 kesci users 396M Aug  3 17:13 online_testTextMining_editSim.h5\r\n-rw-r--r-- 1 kesci users 132M Aug  4 02:09 online_testTextMining_idfWordShare.h5\r\n-rw-r--r-- 1 kesci users 438M Aug  2 16:03 online_testTextMining_len.h5\r\n-rw-r--r-- 1 kesci users 648M Aug  4 05:01 online_testTextMining_ngramSim.h5\r\n-rw-r--r-- 1 kesci users  91M Aug  3 00:23 online_testTextMining_normalWordShare.h5\r\n-rw-r--r-- 1 kesci users 996M Aug  3 14:25 online_trainTextMining_editSim.h5\r\n-rw-r--r-- 1 kesci users 328M Aug  4 01:40 online_trainTextMining_idfWordShare.h5\r\n-rw-r--r-- 1 kesci users 1.2G Aug  2 15:49 online_trainTextMining_len.h5\r\n-rw-r--r-- 1 kesci users 1.8G Aug  4 04:40 online_trainTextMining_ngramSim.h5\r\n-rw-r--r-- 1 kesci users 224M Aug  3 00:17 online_trainTextMining_normalWordShare.h5\r\n","name":"stdout"}],"source":"from fuzzywuzzy import fuzz\nfeature_save_dir = base_feature_save_dir + \"textMining/\"\ntrain_feature_prefix = base_prefix + \"trainTextMining\"\ntest_feature_prefix = base_prefix + \"testTextMining\"\n! ls -alh /home/kesci/work/common/features/textMining/"},{"metadata":{"id":"56BC7EA4121247A0B660A56959416FF1","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisHDF(\"/home/kesci/work/common/features/textMining/online_trainTextMining_editSim.h5\")","execution_count":41},{"metadata":{"id":"2BF8A7DF5B2E420287E31CE585C5D4C6","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisHDF(\"/home/kesci/work/common/features/textMining/online_trainTextMining_ngramSim.h5\")","execution_count":42},{"cell_type":"markdown","metadata":{"id":"EBE478C8B05D40B680CBD2AB3E3CAFF1","mdEditEnable":false},"source":"### 提取长度特征"},{"cell_type":"code","execution_count":5,"metadata":{"id":"E7F6EF4CF5FB44CC850D8E2DA410704C","scrolled":false,"collapsed":false},"outputs":[],"source":"regen_len_feature = True\nfeature_name = \"len\""},{"cell_type":"code","execution_count":6,"metadata":{"id":"60DD46D6363B47688636727332B06FBA","scrolled":false,"collapsed":false},"outputs":[],"source":"def run_text_len(df, ngram, prefix):\n    with Timer(\"build {}\".format(ngram)):\n        if ngram == \"text\":\n            q_list = df['query']\n            t_list = df['title']\n        else:\n            q_list = FuncMap1(ngram_funcs[ngram], df['query'])\n            t_list = FuncMap1(ngram_funcs[ngram], df['title'])\n    with Timer(\"extract length\"):\n        q_len = FuncMap1(len, q_list)\n        t_len = FuncMap1(len, t_list)\n        del q_list, t_list\n        gc.collect()\n        df['%s_qLen' % prefix] = q_len\n        df['%s_tLen' % prefix] = t_len\n        df['%s_qtLenRatio'%prefix] = FuncMap2(ratio_func, q_len, t_len)\n        df['%s_tqLenRatio'%prefix] = FuncMap2(ratio_func, t_len, q_len)\n        df['%s_qtMax'%prefix] = FuncMap2(max_func, q_len, t_len)\n        df['%s_qtMin'%prefix] = FuncMap2(min_func, q_len, t_len)\n        df['%s_qtDiff'%prefix] = FuncMap2(diff_func, q_len, t_len)\n        df['%s_qtAvg'%prefix] = FuncMap2(avg_func, q_len, t_len)\n        df['%s_diffRatio'%prefix] = FuncMap2(ratio_func, df['%s_qtMin'%prefix], df['%s_qtMax'%prefix])\n        del q_len, t_len\n        gc.collect()\n    return df\ndef process_text_len(df, save_dir, prefix, feature_name):\n    df = run_text_len(df, \"text\", '%s_%s' % (prefix, 'text'))\n    df = run_text_len(df, \"unigrams\", '%s_%s' % (prefix, 'unigrams'))\n    return df"},{"cell_type":"code","execution_count":7,"metadata":{"id":"CBD06EEC5BBD4004B33CE283911513CF","scrolled":false,"collapsed":false},"outputs":[{"output_type":"stream","text":"----->started 'extract len feature' block...\n----->started 'build text' block...\n----->finished 'build text' block, time used:0.0s.\n----->started 'extract length' block...\n----->finished 'extract length' block, time used:14.99s.\n----->started 'build unigrams' block...\n----->finished 'build unigrams' block, time used:16.49s.\n----->started 'extract length' block...\n----->finished 'extract length' block, time used:16.55s.\n----->started 'save feature' block...\nsaved len feature to /home/kesci/work/common/features/textMining/debug_trainTextMining_len.h5\n----->finished 'save feature' block, time used:50.68s.\n----->finished 'extract len feature' block, time used:106.42s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_len_feature:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, feature_name, \n        process_func=process_text_len, names=train_name, process_chunkly=False, \n        chunk_size=CHUNK_SIZE, drop_first_cols=['query_id', 'query_title_id', 'label'], \n        drop_last_cols=['query', 'title'])"},{"cell_type":"code","execution_count":11,"metadata":{"id":"B490167AEC954DE19717808444B13724","scrolled":false,"collapsed":false},"outputs":[],"source":"# AnalysisHDF(\"/home/kesci/work/common/features/textMining/debug_trainTextMining_len.h5\")"},{"cell_type":"code","execution_count":8,"metadata":{"id":"5CEF3CB2AEB44E038AD28D5EBC235D88","scrolled":false,"collapsed":false},"outputs":[{"output_type":"stream","text":"----->started 'extract len feature' block...\n----->started 'build text' block...\n----->finished 'build text' block, time used:0.0s.\n----->started 'extract length' block...\n----->finished 'extract length' block, time used:3.63s.\n----->started 'build unigrams' block...\n----->finished 'build unigrams' block, time used:4.19s.\n----->started 'extract length' block...\n----->finished 'extract length' block, time used:3.99s.\n----->started 'save feature' block...\nsaved len feature to /home/kesci/work/common/features/textMining/debug_testTextMining_len.h5\n----->finished 'save feature' block, time used:12.36s.\n----->finished 'extract len feature' block, time used:26.0s.\n","name":"stdout"}],"source":"if regen_len_feature:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, feature_name, \n    process_func=process_text_len, names=test_name, process_chunkly=False, \n    chunk_size=CHUNK_SIZE, drop_first_cols=['query_id', 'query_title_id', 'label'],\n    drop_last_cols=['query', 'title'])"},{"metadata":{"id":"2108A91517D14BFC9790AF0898FC5396","mdEditEnable":false},"cell_type":"markdown","source":"### word share"},{"metadata":{"id":"9535B474DBD6403D954C150F9FFBF8EC","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"regen_word_share = True\nword_share_mode = \"normal\"  # normal or idf\nfeature_name = \"{}WordShare\".format(word_share_mode)","execution_count":9},{"metadata":{"id":"A5D260FE37E84CDD8606D3171AA3EDE1","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"if word_share_mode == \"idf\":\n    with open(tfidf_model_file, \"rb\") as ff:\n        tfidf_model = pickle.load(ff)\n        idf_ = tfidf_model.idf_\n        voc_ = tfidf_model.vocabulary_\n        del tfidf_model\n        gc.collect()","execution_count":10},{"metadata":{"id":"EA0D29E84BF144F882A8CACCF292BE4C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def get_idf(word):\n    return idf_[voc_[word]] if word in voc_ else 0.0\ndef stat_word_count(words):\n    stat = {}\n    for _ in words:\n        stat[_] = stat.get(_, 0) + 1\n    return stat\ndef stat_share_word(words1, words2):\n    if word_share_mode == \"normal\":\n        tol = sum(words1.values()) + sum(words2.values())\n    elif word_share_mode == \"idf\":\n        tol = sum(words1[w] * get_idf(w) for w in words1) + sum(words2[w] * get_idf(w) for w in words2)\n    if tol < 1e-6:\n        return 0.0\n    if word_share_mode == \"normal\":\n        n_shared_word_in_q1 = sum([words1[w] for w in words1 if w in words2])\n        n_shared_word_in_q2 = sum([words2[w] for w in words2 if w in words1])\n    elif word_share_mode == \"idf\":\n        n_shared_word_in_q1 = sum([words1[w] * get_idf(w) for w in words1 if w in words2])\n        n_shared_word_in_q2 = sum([words2[w] * get_idf(w) for w in words2 if w in words1])\n    return (n_shared_word_in_q1 + n_shared_word_in_q2) / tol","execution_count":11},{"metadata":{"id":"17B068C8A9694B94899D7941D8B8D757","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def run_word_share(df, ngram, prefix):\n    with Timer(\"build {}\".format(ngram)):\n        q_list = FuncMap1(ngram_funcs[ngram], df['query'])\n        t_list = FuncMap1(ngram_funcs[ngram], df['title'])\n    with Timer(\"extract feature\"):\n        q_count = FuncMap1(stat_word_count, q_list)\n        t_count = FuncMap1(stat_word_count, t_list)\n        del q_list, t_list\n        gc.collect()\n        df['{}_{}_{}'.format(prefix, feature_name, word_share_mode)] = FuncMap2(stat_share_word, q_count, t_count)\n    return df\n    \ndef process_word_share(df, save_dir, prefix, feature_name):\n    df = run_word_share(df, \"unigrams\", '%s_%s' % (prefix, 'unigrams'))\n    return df","execution_count":12},{"metadata":{"id":"AE811BF5EF64490A85A5C96788D969C7","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->started 'extract normalWordShare feature' block...\n----->started 'build unigrams' block...\n----->finished 'build unigrams' block, time used:16.64s.\n----->started 'extract feature' block...\n----->finished 'extract feature' block, time used:31.08s.\n----->started 'save feature' block...\nsaved normalWordShare feature to /home/kesci/work/common/features/textMining/debug_trainTextMining_normalWordShare.h5\n----->finished 'save feature' block, time used:4.68s.\n----->finished 'extract normalWordShare feature' block, time used:62.38s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_word_share:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, feature_name, \n        process_func=process_word_share, names=train_name, process_chunkly=False, \n        chunk_size=CHUNK_SIZE, drop_first_cols=['query_id', 'query_title_id', 'label'], \n        drop_last_cols=['query', 'title'])","execution_count":13},{"metadata":{"id":"B1E1821D0E844F688B2796A55BFB7F6E","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# !rm /home/kesci/work/common/features/textMining/debug_trainTextMining_wordShare.h5","execution_count":3},{"metadata":{"id":"2D3708D740A642F88AF3F3136DAC90FB","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->started 'extract normalWordShare feature' block...\n----->started 'build unigrams' block...\n----->finished 'build unigrams' block, time used:4.21s.\n----->started 'extract feature' block...\n----->finished 'extract feature' block, time used:7.71s.\n----->started 'save feature' block...\nsaved normalWordShare feature to /home/kesci/work/common/features/textMining/debug_testTextMining_normalWordShare.h5\n----->finished 'save feature' block, time used:1.13s.\n----->finished 'extract normalWordShare feature' block, time used:15.26s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_word_share:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, feature_name, \n        process_func=process_word_share, names=test_name, process_chunkly=False, \n        chunk_size=CHUNK_SIZE, drop_first_cols=['query_id', 'query_title_id', 'label'], \n        drop_last_cols=['query', 'title'])","execution_count":14},{"cell_type":"markdown","metadata":{"id":"2B76B2EE7B7C45258B815B1BB4F0C1C5","mdEditEnable":false},"source":"### 提取字符编辑距离特征"},{"cell_type":"code","execution_count":15,"metadata":{"id":"E68A493A8B244468942CF4859F548D1E","scrolled":false,"collapsed":false},"outputs":[],"source":"import Levenshtein\nregen_edit_sim_feature = True\nfeature_name = \"editSim\""},{"cell_type":"code","execution_count":16,"metadata":{"id":"66D053F91FB442728158DCA5C25ABE62","scrolled":false,"collapsed":false},"outputs":[],"source":"similar_arr = [\n    # https://www.jb51.net/article/98449.htm;\n    # http://www.coli.uni-saarland.de/courses/LT1/2011/slides/Python-Levenshtein.html#Levenshtein-inverse\n    Levenshtein.distance,\n    Levenshtein.jaro,\n    Levenshtein.jaro_winkler,\n    # https://blog.csdn.net/qq_43174128/article/details/82595317\n    fuzz.ratio,\n    fuzz.partial_ratio,\n    fuzz.token_sort_ratio,\n    fuzz.partial_token_sort_ratio,\n    fuzz.token_set_ratio,\n    # dist_utils.edit_dist,\n    # dist_utils.is_str_match,\n    dist_utils.longest_match_size,\n    dist_utils.longest_match_ratio,\n    # dist_utils.compression_dist\n]"},{"cell_type":"code","execution_count":17,"metadata":{"id":"6FDAF1DCC57F4B958F5DB383FC836159","scrolled":false,"collapsed":false},"outputs":[],"source":"def run_edit_sim_feature(df, prefix):\n    q_list = df['query']\n    t_list = df['title']\n    with Timer(\"extract edit sim\"):\n        for _ in similar_arr:\n            name = _.__name__\n            with Timer(\"cal {} sim\".format(name)):\n                df[\"{}_{}\".format(prefix, name)] = FuncMap2(_, q_list, t_list)\n        del q_list, t_list\n        gc.collect()\n    return df\ndef process_edit_sim_feature(df, save_dir, prefix, feature_name):\n    df = run_edit_sim_feature(df, '%s_%s' % (prefix, 'text'))\n    return df"},{"cell_type":"code","execution_count":18,"metadata":{"id":"E20960C2CED0432089F1FE9D935EAB72","scrolled":false,"collapsed":false},"outputs":[{"output_type":"stream","text":"----->started 'extract editSim feature' block...\n----->started 'extract edit sim' block...\n----->started 'cal distance sim' block...\n----->finished 'cal distance sim' block, time used:11.56s.\n----->started 'cal jaro sim' block...\n----->finished 'cal jaro sim' block, time used:4.66s.\n----->started 'cal jaro_winkler sim' block...\n----->finished 'cal jaro_winkler sim' block, time used:4.75s.\n----->started 'cal ratio sim' block...\n----->finished 'cal ratio sim' block, time used:23.46s.\n----->started 'cal partial_ratio sim' block...\n----->finished 'cal partial_ratio sim' block, time used:126.22s.\n----->started 'cal token_sort_ratio sim' block...\n----->finished 'cal token_sort_ratio sim' block, time used:94.28s.\n----->started 'cal partial_token_sort_ratio sim' block...\n----->finished 'cal partial_token_sort_ratio sim' block, time used:202.95s.\n----->started 'cal token_set_ratio sim' block...\n----->finished 'cal token_set_ratio sim' block, time used:136.93s.\n----->started 'cal longest_match_size sim' block...\n----->finished 'cal longest_match_size sim' block, time used:187.75s.\n----->started 'cal longest_match_ratio sim' block...\n----->finished 'cal longest_match_ratio sim' block, time used:192.38s.\n----->finished 'extract edit sim' block, time used:985.0s.\n----->started 'save feature' block...\nsaved editSim feature to /home/kesci/work/common/features/textMining/debug_trainTextMining_editSim.h5\n----->finished 'save feature' block, time used:23.88s.\n----->finished 'extract editSim feature' block, time used:1016.31s.\n","name":"stdout"}],"source":"if regen_edit_sim_feature:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, feature_name, \n        process_func=process_edit_sim_feature, names=train_name, process_chunkly=False, \n        chunk_size=CHUNK_SIZE, drop_first_cols=['query_id', 'query_title_id', 'label'], \n        drop_last_cols=['query', 'title'])"},{"metadata":{"id":"D32EBA95A6A6484EA5E5339E752E7828","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"/home/kesci/work/common/features/textMining/debug_trainTextMining_editSim.csv.gz\", print_rows=10)","execution_count":36},{"cell_type":"code","execution_count":19,"metadata":{"id":"1314AD4E4E794EDB9BC13AA8140CD441","scrolled":false,"collapsed":false},"outputs":[{"output_type":"stream","text":"----->started 'extract editSim feature' block...\n----->started 'extract edit sim' block...\n----->started 'cal distance sim' block...\n----->finished 'cal distance sim' block, time used:2.9s.\n----->started 'cal jaro sim' block...\n----->finished 'cal jaro sim' block, time used:1.16s.\n----->started 'cal jaro_winkler sim' block...\n----->finished 'cal jaro_winkler sim' block, time used:1.18s.\n----->started 'cal ratio sim' block...\n----->finished 'cal ratio sim' block, time used:5.9s.\n----->started 'cal partial_ratio sim' block...\n----->finished 'cal partial_ratio sim' block, time used:31.75s.\n----->started 'cal token_sort_ratio sim' block...\n----->finished 'cal token_sort_ratio sim' block, time used:23.21s.\n----->started 'cal partial_token_sort_ratio sim' block...\n----->finished 'cal partial_token_sort_ratio sim' block, time used:50.16s.\n----->started 'cal token_set_ratio sim' block...\n----->finished 'cal token_set_ratio sim' block, time used:34.19s.\n----->started 'cal longest_match_size sim' block...\n----->finished 'cal longest_match_size sim' block, time used:46.78s.\n----->started 'cal longest_match_ratio sim' block...\n----->finished 'cal longest_match_ratio sim' block, time used:47.77s.\n----->finished 'extract edit sim' block, time used:245.02s.\n----->started 'save feature' block...\nsaved editSim feature to /home/kesci/work/common/features/textMining/debug_testTextMining_editSim.h5\n----->finished 'save feature' block, time used:5.87s.\n----->finished 'extract editSim feature' block, time used:252.69s.\n","name":"stdout"}],"source":"if regen_edit_sim_feature:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, feature_name, \n        process_func=process_edit_sim_feature, names=test_name, process_chunkly=False, \n        chunk_size=CHUNK_SIZE, drop_first_cols=['query_id', 'query_title_id', \"label\"], \n        drop_last_cols=['query', 'title'])"},{"cell_type":"markdown","metadata":{"id":"7DDCC4D135FF46D086F1D9D77D7C29F3","mdEditEnable":false},"source":"### 提取集合相似度特征"},{"cell_type":"code","execution_count":20,"metadata":{"id":"A9F24C2040384D4BBE2B355D542EA06F","scrolled":false,"collapsed":false},"outputs":[],"source":"import Levenshtein\nregen_ngram_sim_feature = True\nfeature_name = \"ngramSim\""},{"cell_type":"code","execution_count":21,"metadata":{"id":"C8534A0F74A54363AE989AD3FBED6EC9","scrolled":false,"collapsed":false},"outputs":[],"source":"ratio_arr = [\n    # 集合的交集关系\n    # 可以操作字符串，如\"abc\"；也可以操作字符数组，如['a', 'b', 'c']\n    dist_utils.dice_ratio,\n    dist_utils.jaccard_ratio,\n    dist_utils.edit_seq_ratio,\n    dist_utils.edit_set_ratio,\n]"},{"cell_type":"code","execution_count":22,"metadata":{"id":"F06C42D8A5B649B2868E541787C39840","scrolled":false,"collapsed":false},"outputs":[],"source":"def run_ngram_similarity(df, ngram, prefix):\n    q_list = FuncMap1(ngram_funcs[ngram], df['query'])\n    t_list = FuncMap1(ngram_funcs[ngram], df['title'])\n    with Timer(\"extract ngram sim\"):\n        for _ in ratio_arr:\n            name = _.__name__\n            with Timer(\"cal {} sim\".format(name)):\n                df[\"{}_{}\".format(prefix, name)] = FuncMap2(_, q_list, t_list)\n        del q_list, t_list\n        gc.collect()\n    return df\n\ndef process_ngram_similarity(df, save_dir, prefix, feature_name):\n    # df = run_ngram_similarity(df, 'unichars', '%s_%s' % (prefix, 'unichars'))\n    # df = run_ngram_similarity(df, 'bichars', '%s_%s' % (prefix, 'bichars'))\n    # df = run_ngram_similarity(df, 'trichars', '%s_%s' % (prefix, 'trichars'))\n    df = run_ngram_similarity(df, 'unigrams', '%s_%s' % (prefix, 'unigrams'))\n    df = run_ngram_similarity(df, 'bigrams', '%s_%s' % (prefix, 'bigrams'))\n    # df = run_ngram_similarity(df, 'trigrams', '%s_%s' % (prefix, 'trigrams'))\n    return df"},{"cell_type":"code","execution_count":23,"metadata":{"id":"B042F9B774C24DFD848620F742E833B1","scrolled":false,"collapsed":false},"outputs":[{"output_type":"stream","text":"----->started 'extract ngramSim feature' block...\n----->started 'extract ngram sim' block...\n----->started 'cal dice_ratio sim' block...\n----->finished 'cal dice_ratio sim' block, time used:10.1s.\n----->started 'cal jaccard_ratio sim' block...\n----->finished 'cal jaccard_ratio sim' block, time used:8.21s.\n----->started 'cal edit_seq_ratio sim' block...\n----->finished 'cal edit_seq_ratio sim' block, time used:22.47s.\n----->started 'cal edit_set_ratio sim' block...\n----->finished 'cal edit_set_ratio sim' block, time used:26.72s.\n----->finished 'extract ngram sim' block, time used:70.31s.\n----->started 'extract ngram sim' block...\n----->started 'cal dice_ratio sim' block...\n----->finished 'cal dice_ratio sim' block, time used:9.69s.\n----->started 'cal jaccard_ratio sim' block...\n----->finished 'cal jaccard_ratio sim' block, time used:7.73s.\n----->started 'cal edit_seq_ratio sim' block...\n----->finished 'cal edit_seq_ratio sim' block, time used:30.95s.\n----->started 'cal edit_set_ratio sim' block...\n----->finished 'cal edit_set_ratio sim' block, time used:34.17s.\n----->finished 'extract ngram sim' block, time used:86.44s.\n----->started 'save feature' block...\nsaved ngramSim feature to /home/kesci/work/common/features/textMining/debug_trainTextMining_ngramSim.h5\n----->finished 'save feature' block, time used:30.77s.\n----->finished 'extract ngramSim feature' block, time used:250.13s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_ngram_sim_feature:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, feature_name, \n        process_func=process_ngram_similarity, names=train_name, process_chunkly=False, \n        chunk_size=CHUNK_SIZE, drop_first_cols=['query_id', 'query_title_id', 'label'], \n        drop_last_cols=['query', 'title'])"},{"cell_type":"code","execution_count":41,"metadata":{"id":"FBBBDAAE926D49038C9C5E824014F74C","scrolled":false},"outputs":[],"source":"# AnalysisCSV(\"./stage1/output/text_mining_feature/debug_trainTextMining_ngramSim.csv.gz\")"},{"metadata":{"id":"BFBFE9BFD0AB47998666C82D20FB3066","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->started 'extract ngramSim feature' block...\n----->started 'extract ngram sim' block...\n----->started 'cal dice_ratio sim' block...\n----->finished 'cal dice_ratio sim' block, time used:2.51s.\n----->started 'cal jaccard_ratio sim' block...\n----->finished 'cal jaccard_ratio sim' block, time used:2.07s.\n----->started 'cal edit_seq_ratio sim' block...\n----->finished 'cal edit_seq_ratio sim' block, time used:5.57s.\n----->started 'cal edit_set_ratio sim' block...\n----->finished 'cal edit_set_ratio sim' block, time used:6.56s.\n----->finished 'extract ngram sim' block, time used:17.4s.\n----->started 'extract ngram sim' block...\n----->started 'cal dice_ratio sim' block...\n----->finished 'cal dice_ratio sim' block, time used:2.38s.\n----->started 'cal jaccard_ratio sim' block...\n----->finished 'cal jaccard_ratio sim' block, time used:1.92s.\n----->started 'cal edit_seq_ratio sim' block...\n----->finished 'cal edit_seq_ratio sim' block, time used:7.73s.\n----->started 'cal edit_set_ratio sim' block...\n----->finished 'cal edit_set_ratio sim' block, time used:8.42s.\n----->finished 'extract ngram sim' block, time used:21.34s.\n----->started 'save feature' block...\nsaved ngramSim feature to /home/kesci/work/common/features/textMining/debug_testTextMining_ngramSim.h5\n----->finished 'save feature' block, time used:7.54s.\n----->finished 'extract ngramSim feature' block, time used:61.95s.\n","name":"stdout"}],"source":"if regen_ngram_sim_feature:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, feature_name, \n        process_func=process_ngram_similarity, names=test_name, process_chunkly=False, \n        chunk_size=CHUNK_SIZE, drop_first_cols=['query_id', 'query_title_id', \"label\"], \n        drop_last_cols=['query', 'title'])","execution_count":24},{"cell_type":"markdown","metadata":{"id":"34FF8ADD40D042E38EAA9C8DC3357D5C","mdEditEnable":false},"source":"### SimHash特征"},{"cell_type":"code","execution_count":29,"metadata":{"id":"EC370B7E7BD245158D2734F1EC4630EB","scrolled":false,"collapsed":false},"outputs":[],"source":"# https://github.com/cjauvin/simhash/blob/master/tests/test_simhash.py\n# https://leons.im/posts/a-python-implementation-of-simhash-algorithm/\n# 这个不错: http://yanyiwu.com/work/2014/01/30/simhash-shi-xian-xiang-jie.html\nfrom simhash import Simhash\nregen_hashsim = False\nfeature_name = \"hashSim\""},{"cell_type":"code","execution_count":32,"metadata":{"id":"B904E065A5484A0EBC4C2F9A27C9384D","scrolled":false,"collapsed":false},"outputs":[],"source":"def run_ngram_hashsim(df, prefix):\n    with Timer(\"cal tfidf vec\"):\n        with open(tfidf_model_file, \"rb\") as ff:\n            tfidf_model = pickle.load(ff)\n            voc = {i:w for w, i in tfidf_model.vocabulary_.items()}\n        q_vecs = tfidf_model.transform(df['query'])\n        t_vecs = tfidf_model.transform(df['title'])\n    with Timer(\"cal hash pairs\"):\n        q_simhash = [\n            Simhash(\n                zip([voc[j] for j in Di.indices], Di.data)\n            )\n            for Di in q_vecs\n        ]\n        t_simhash = [\n            Simhash(\n                zip([voc[j] for j in Di.indices], Di.data)\n            )\n            for Di in t_vecs\n        ]\n    with Timer(\"cal hash sim\"):\n        df[\"{}_hashSim\".format(prefix)] = FuncMap2(lambda x,y: x.distance(y), q_simhash, t_simhash)\n        \n    del q_vecs, t_vecs, q_simhash, t_simhash, tfidf_model, voc\n    gc.collect()\n    \n    return df\n\ndef process_ngram_hashsim(df, save_dir, prefix, feature_name):\n    df = run_ngram_hashsim(df, prefix)\n    return df"},{"cell_type":"code","execution_count":33,"metadata":{"id":"C3DF38230E854BE18E69868A0606675D","scrolled":false,"collapsed":false},"outputs":[{"output_type":"stream","text":"----->started 'extract hashSim feature' block...\n----->started 'cal tfidf vec' block...\n----->finished 'cal tfidf vec' block, time used:198.89s.\n----->started 'cal sim hash' block...\n----->finished 'cal sim hash' block, time used:1239.1s.\n----->started 'cal hash sim' block...\n----->finished 'cal hash sim' block, time used:3.57s.\n----->started 'save feature' block...\nsaved hashSim feature to /home/kesci/work/common/features/textMining/debug_trainTextMining_hashSim.h5\n----->finished 'save feature' block, time used:0.51s.\n----->finished 'extract hashSim feature' block, time used:1576.93s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_hashsim:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, feature_name, \n                   process_func=process_ngram_hashsim, names=ORI_TRAIN_NAMES, process_chunkly=False, \n                   chunk_size=CHUNK_SIZE, drop_first_cols=['query_id', 'query_title_id', 'label'], \n                   drop_last_cols=['query', 'title'])"},{"metadata":{"id":"0C702B7D7ADC4FD493493118C4350AAF","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisHDF(\"/home/kesci/work/common/features/textMining/debug_trainTextMining_hashSim.h5\", print_rows=10)","execution_count":35},{"metadata":{"id":"C59FC30C0BAB497F8DD90FA01B33BF40"},"cell_type":"code","outputs":[],"source":"# 提取训练数据特征\nif regen_hashsim and not OFFLINE:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, feature_name, \n                   process_func=process_ngram_hashsim, names=ORI_TEST_NAMES, process_chunkly=False, \n                   chunk_size=CHUNK_SIZE, drop_first_cols=['query_id', 'query_title_id'], \n                   drop_last_cols=['query', 'title'])","execution_count":null},{"cell_type":"markdown","metadata":{"id":"67AD058D138E43BAA3781D9CC9CCC2E2","mdEditEnable":false},"source":"### 最长公共子串"},{"cell_type":"code","execution_count":48,"metadata":{"id":"8271DCC453B24D2EB8F0BF3667D464E7","scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["{'', '23', '123', '2', '3', '1', '13', '12'}\n"]}],"source":"import py_common_subseq\nregen_subseq = False\nfeature_name = \"commonSeq\"\nprint(py_common_subseq.find_common_subsequences(\"123\", \"13423\"))"},{"cell_type":"code","execution_count":49,"metadata":{"id":"2B000BEFCADD436AB632AEF50D087C27","scrolled":false},"outputs":[],"source":"def run_ngram_subseq(df, ngram, prefix):\n    query = df[\"query\"].apply(ngram)\n    title = df[\"title\"].apply(ngram)\n    with Timer(\"cal sub seq\"):\n        df[\"{}LCSValue\".format(prefix)] = FuncMap2(lambda x, y:py_common_subseq.find_common_subsequences(x, y),query, title)\n        del query, title\n        gc.collect()\n    return df\n\ndef process_ngram_subseq(df, save_dir, prefix, feature_name):\n    df = run_ngram_subseq(df, ngram_utils.unichars, '%s_%s' % (prefix, 'unichars'))\n    df = run_ngram_subseq(df, ngram_utils.bichars, '%s_%s' % (prefix, 'bichars'))\n    df = run_ngram_subseq(df, ngram_utils.trichars, '%s_%s' % (prefix, 'trichars'))\n    df = run_ngram_subseq(df, ngram_utils.unigrams, '%s_%s' % (prefix, 'unigrams'))\n    df = run_ngram_subseq(df, ngram_utils.bigrams, '%s_%s' % (prefix, 'bigrams'))\n    df = run_ngram_subseq(df, ngram_utils.trigrams, '%s_%s' % (prefix, 'trigrams'))\n    return df "},{"cell_type":"code","execution_count":50,"metadata":{"id":"6A0AB78AA49747CC95B2F27A078CF871","scrolled":false},"outputs":[],"source":"# 提取训练数据特征\nif regen_subseq:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, feature_name, \n        process_func=process_ngram_subseq, names=ORI_TRAIN_NAMES, process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], drop_last_cols=['query', 'title'])"},{"cell_type":"code","execution_count":51,"metadata":{"id":"29C92F1B1B794E7194CD02D53FC5BFC1","scrolled":false},"outputs":[],"source":"# 提取训练数据特征\nif not OFFLINE and regen_subseq:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, feature_name, \n        process_func=process_ngram_subseq, names=ORI_TEST_NAMES, process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], drop_last_cols=['query', 'title'])"},{"cell_type":"markdown","metadata":{"id":"15E7A63098994D708D5CD5744E814A33","mdEditEnable":false},"source":"## 向量空间特征"},{"cell_type":"code","execution_count":5,"metadata":{"id":"BBE2052F8A5D48EBAFF63A4DC5CEE6AB","scrolled":false,"collapsed":false},"outputs":[{"output_type":"stream","text":"/home/kesci/work/common/util_models/tfidf_word_ngram-13_online_allUnique.bin\ntotal 8.0G\ndrwxr-xr-x 2 kesci root  4.0K Aug  1 20:25 .\ndrwxr-xr-x 7 kesci root  4.0K Aug  4 03:00 ..\n-rw-r--r-- 1 kesci users  34M Aug  6 13:36 debug_testVectorSpace_tfidfVecFeat.h5\n-rw-r--r-- 1 kesci users 132M Aug  6 13:27 debug_trainVectorSpace_tfidfVecFeat.h5\n-rw-r--r-- 1 kesci users  52M Jul 21 08:02 debug_trainVectorSpace_tfidfVecLen.h5\n-rw-r--r-- 1 kesci users  19M Jul 22 11:26 debug_trainVectorSpace_tfidfVecSim.h5\n-rw-r--r-- 1 kesci users  20M Jul 22 03:09 debug_trainVectorSpace_tfidfVecSim_xp.h5\n-rw-r--r-- 1 kesci users 894M Aug  1 20:30 online_testVectorSpace_tfidfVecFeat.h5\n-rw-r--r-- 1 kesci users 980M Jul 24 04:13 online_testVectorSpace_tfidfVecLen.h5\n-rw-r--r-- 1 kesci users 373M Jul 24 01:58 online_testVectorSpace_tfidfVecSim.h5\n-rw-r--r-- 1 kesci users 2.2G Aug  1 19:14 online_trainVectorSpace_tfidfVecFeat.h5\n-rw-r--r-- 1 kesci users 2.5G Jul 24 03:33 online_trainVectorSpace_tfidfVecLen.h5\n-rw-r--r-- 1 kesci users 932M Jul 24 01:22 online_trainVectorSpace_tfidfVecSim.h5\n","name":"stdout"}],"source":"import pickle\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfeature_save_dir = base_feature_save_dir + \"vectorSpace/\"\ntrain_feature_prefix = base_prefix + \"trainVectorSpace\"\ntest_feature_prefix = base_prefix + \"testVectorSpace\"\nprint(tfidf_model_file)\n! ls -alh /home/kesci/work/common/features/vectorSpace\n# debug_trainVectorSpace_tfidfVecLen.h5"},{"cell_type":"markdown","metadata":{"id":"75C8C3F4EF534B12ADC50BF155A934BE","mdEditEnable":false},"source":"### tfidf向量相似性"},{"cell_type":"code","execution_count":4,"metadata":{"id":"FDBEAC0E2434445CBE2B3784BBFA4F56","scrolled":false,"collapsed":false},"outputs":[{"output_type":"stream","text":"/home/kesci/work/common/util_models/tfidf_word_ngram-13_online_allUnique.bin\n","name":"stdout"}],"source":"# https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics.pairwise\nfrom sklearn.metrics.pairwise import *\nregen_tfidf_vec_sim = True\nfeature_name = \"tfidfVecFeat\"\nprint(tfidf_model_file)"},{"cell_type":"code","execution_count":5,"metadata":{"id":"691C30D600E84925BEB68A9F656939A2","scrolled":false,"collapsed":false},"outputs":[],"source":"dis_arr = [\n    paired_cosine_distances,\n    paired_euclidean_distances,\n    paired_manhattan_distances\n]"},{"cell_type":"code","execution_count":7,"metadata":{"id":"1418FD4036F544B58A4A0532E2EB875C","scrolled":false,"collapsed":false},"outputs":[],"source":"def process_tfidf_vec_feat(df, save_dir, prefix, feature_name):\n    with Timer(\"cal tfidf vec\"):\n        with open(tfidf_model_file, \"rb\") as ff:\n            tfidf_model = pickle.load(ff)\n        q_vec = tfidf_model.transform(df[\"query\"])\n        t_vec = tfidf_model.transform(df[\"title\"])\n    with Timer(\"cal tfidf vec value\"):\n        df['{}_{}_QSum'.format(prefix, feature_name)] = np.array(q_vec.sum(1)).squeeze()\n        df['{}_{}_TSum'.format(prefix, feature_name)] = np.array(t_vec.sum(1)).squeeze()\n        # df['{}_{}_QMean'.format(prefix, feature_name)] = np.array(q_vec.mean(1)).squeeze()\n        # df['{}_{}_TMean'.format(prefix, feature_name)] = np.array(t_vec.mean(1)).squeeze()\n        df['{}_{}_QLen'.format(prefix, feature_name)] = [len(Di.data) for Di in q_vec]\n        df['{}_{}_TLen'.format(prefix, feature_name)] = [len(Di.data) for Di in t_vec]\n    with Timer(\"cal tfidf vec sim\"):\n        for _ in dis_arr:\n            name = _.__name__\n            with Timer(\"cal {} sim\".format(name)):\n                df[\"{}_{}_{}\".format(prefix, feature_name, name)] = _(q_vec, t_vec)\n        del q_vec, t_vec, tfidf_model\n        gc.collect()\n    return df"},{"metadata":{"id":"87C6FF7ACB0F40C5928662C904475D70","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->started 'extract tfidfVecFeat feature' block...\n----->started 'cal tfidf vec' block...\n----->finished 'cal tfidf vec' block, time used:421.39s.\n----->started 'cal tfidf vec value' block...\n----->finished 'cal tfidf vec value' block, time used:379.11s.\n----->started 'cal tfidf vec sim' block...\n----->started 'cal paired_cosine_distances sim' block...\n----->finished 'cal paired_cosine_distances sim' block, time used:8.93s.\n----->started 'cal paired_euclidean_distances sim' block...\n----->finished 'cal paired_euclidean_distances sim' block, time used:7.85s.\n----->started 'cal paired_manhattan_distances sim' block...\n----->finished 'cal paired_manhattan_distances sim' block, time used:8.0s.\n----->finished 'cal tfidf vec sim' block, time used:200.43s.\n----->started 'save feature' block...\nsaved tfidfVecFeat feature to /home/kesci/work/common/features/vectorSpace/debug_trainVectorSpace_tfidfVecFeat.h5\n----->finished 'save feature' block, time used:40.01s.\n----->finished 'extract tfidfVecFeat feature' block, time used:1049.89s.\n","name":"stdout"}],"source":"if regen_tfidf_vec_sim:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, feature_name, \n                  process_func=process_tfidf_vec_feat, names=train_name, process_chunkly=False, \n                  chunk_size=CHUNK_SIZE, drop_first_cols=['query_id', 'query_title_id', 'label'], \n                  drop_last_cols=['query', 'title'])","execution_count":8},{"metadata":{"id":"D336DA917E96459D9020E737F4978C46","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->started 'extract tfidfVecFeat feature' block...\n----->started 'cal tfidf vec' block...\n----->finished 'cal tfidf vec' block, time used:253.96s.\n----->started 'cal tfidf vec value' block...\n----->finished 'cal tfidf vec value' block, time used:94.76s.\n----->started 'cal tfidf vec sim' block...\n----->started 'cal paired_cosine_distances sim' block...\n----->finished 'cal paired_cosine_distances sim' block, time used:2.73s.\n----->started 'cal paired_euclidean_distances sim' block...\n----->finished 'cal paired_euclidean_distances sim' block, time used:2.31s.\n----->started 'cal paired_manhattan_distances sim' block...\n----->finished 'cal paired_manhattan_distances sim' block, time used:2.51s.\n----->finished 'cal tfidf vec sim' block, time used:224.99s.\n----->started 'save feature' block...\nsaved tfidfVecFeat feature to /home/kesci/work/common/features/vectorSpace/debug_testVectorSpace_tfidfVecFeat.h5\n----->finished 'save feature' block, time used:9.04s.\n----->finished 'extract tfidfVecFeat feature' block, time used:584.89s.\n","name":"stdout"}],"source":"if regen_tfidf_vec_sim:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, feature_name, \n                   process_func=process_tfidf_vec_feat, names=test_name, process_chunkly=False, \n                   chunk_size=CHUNK_SIZE, drop_first_cols=['query_id', 'query_title_id', 'label'], \n                   drop_last_cols=['query', 'title'])","execution_count":9},{"metadata":{"id":"66309242AC1B417D8930E68330830027","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"--->file shape:\n(400000, 9)\n--->2 rows of file:\n   debug_testVectorSpace_tfidfVecFeat_QSum  \\\n0                                 1.913374   \n1                                 1.913374   \n\n   debug_testVectorSpace_tfidfVecFeat_TSum  \\\n0                                 5.618418   \n1                                 4.642403   \n\n   debug_testVectorSpace_tfidfVecFeat_QMean  \\\n0                              3.504090e-08   \n1                              3.504090e-08   \n\n   debug_testVectorSpace_tfidfVecFeat_TMean  \\\n0                              1.028939e-07   \n1                              8.501944e-08   \n\n   debug_testVectorSpace_tfidfVecFeat_QLen  \\\n0                                        4   \n1                                        4   \n\n   debug_testVectorSpace_tfidfVecFeat_TLen  \\\n0                                       36   \n1                                       26   \n\n   debug_testVectorSpace_tfidfVecFeat_paired_cosine_distances  \\\n0                                           0.704403            \n1                                           0.635939            \n\n   debug_testVectorSpace_tfidfVecFeat_paired_euclidean_distances  \\\n0                                           1.186931               \n1                                           1.127776               \n\n   debug_testVectorSpace_tfidfVecFeat_paired_manhattan_distances  \n0                                           6.473185              \n1                                           5.251984              \n","name":"stdout"}],"source":"AnalysisHDF(\"/home/kesci/work/common/features/vectorSpace/debug_testVectorSpace_tfidfVecFeat.h5\")","execution_count":11},{"cell_type":"markdown","metadata":{"id":"571373829A4B43CFA173AEDB3BCC8EAF","mdEditEnable":false},"source":"### tfidf值特征"},{"cell_type":"code","execution_count":9,"metadata":{"id":"74796697CD964CE596198B4451A5D8A8","scrolled":false,"collapsed":false},"outputs":[],"source":"regen_tfidf_vec_len = True\nfeature_name = \"tfidfVecLen\"\nprint(tfidf_model_file)"},{"cell_type":"code","execution_count":10,"metadata":{"id":"31EBDDCAB43D45A28B1F7B7F827F1D28","scrolled":false,"collapsed":false},"outputs":[],"source":"def process_tfidf_vec_len(df, save_dir, prefix, feature_name):\n    with Timer(\"cal tfidf vec\"):\n        with open(tfidf_model_file, \"rb\") as ff:\n            tfidf_model = pickle.load(ff)\n        q_vec = tfidf_model.transform(df[\"query\"])\n        t_vec = tfidf_model.transform(df[\"title\"])\n    with Timer(\"cal tfidf len\"):\n        q_vec_sum = np.array(q_vec.sum(1)).squeeze()\n        t_vec_sum = np.array(t_vec.sum(1)).squeeze()\n        q_vec_mean = np.array(q_vec.mean(1)).squeeze()\n        t_vec_mean = np.array(t_vec.mean(1)).squeeze()\n        df['%s_%s_QSum' % (feature_name, prefix)] = q_vec_sum\n        df['%s_%s_TSum' % (feature_name, prefix)] = t_vec_sum\n        # df['%s_%s_QMean' % (feature_name, prefix)] = q_vec_mean\n        # df['%s_%s_TMean' % (feature_name, prefix)] = t_vec_mean\n        # df['%s_QTLenRatio'%prefix] = FuncMap2(ratio_func, q_vec_len, t_vec_len)\n        # df['%s_TQLenRatio'%prefix] = FuncMap2(ratio_func, t_vec_len, q_vec_len)\n        # df['%s_QTDiff'%prefix] = FuncMap2(diff_func, q_vec_len, t_vec_len)\n        # df['%s_QTMax'%prefix] = FuncMap2(max_func, q_vec_len, t_vec_len)\n        # df['%s_QTMin'%prefix] = FuncMap2(min_func, q_vec_len, t_vec_len)\n        # df['%s_QTAvg'%prefix] = FuncMap2(avg_func, q_vec_len, t_vec_len)\n        # df['%s_QTMulti'%prefix] = FuncMap2(lambda a, b: a*b, q_vec_len, t_vec_len)\n        # df['%s_QSquare2'%prefix] = numpy.square(q_vec_len)\n        # df['%s_TSquare2'%prefix] = numpy.square(t_vec_len)\n        # df['%s_QSqrt'%prefix] = numpy.sqrt(q_vec_len)\n        # df['%s_TSqrt'%prefix] = numpy.sqrt(t_vec_len)\n        # df['%s_QLog'%prefix] = numpy.log(q_vec_len)\n        # df['%s_TLog'%prefix] = numpy.log(t_vec_len)\n        # p_corr = scipy.stats.pearsonr(q_vec_len, t_vec_len)[0]\n        # df['%s_PCorr'%prefix] = [p_corr] * len(q_vec_len)\n        del q_vec, t_vec, q_vec_sum, t_vec_sum, q_vec_mean, t_vec_mean, tfidf_model\n        gc.collect()\n    return df"},{"cell_type":"code","execution_count":11,"metadata":{"id":"6669F53B4AFC4B5F84762938D65BFE97","scrolled":false,"collapsed":false},"outputs":[],"source":"if regen_tfidf_vec_len:\n    ExtractFeature1(train_csv=train_file, test_csv=test_file, \n        train_name=train_name, test_name=test_name, \n        process_func=process_tfidf_vec_len, \n        save_dir=feature_save_dir, \n        prefix=feature_prefix, \n        feature_name=feature_name)"},{"cell_type":"markdown","metadata":{"id":"5985318916B1435D8687DE64F698F4E5","mdEditEnable":false},"source":"## 提取word2vec特征"},{"cell_type":"code","execution_count":6,"metadata":{"id":"07E9877B444D484E93CB0BC611F297FE","scrolled":false,"collapsed":false},"outputs":[{"output_type":"stream","text":"total 1.4G\r\ndrwxr-xr-x 2 kesci root  4.0K Aug  5 21:51 .\r\ndrwxr-xr-x 7 kesci root  4.0K Aug  4 03:00 ..\r\n-rw-r--r-- 1 kesci users 5.7M Aug  2 04:09 debug_testWord2vec_avgSenVecSim.h5\r\n-rw-r--r-- 1 kesci users 2.7M Aug  4 05:30 debug_testWord2vec_tfidfSenVecSim.h5\r\n-rw-r--r-- 1 kesci users  14M Aug  2 04:07 debug_trainWord2vec_avgSenVecSim.h5\r\n-rw-r--r-- 1 kesci users 6.7M Aug  4 05:21 debug_trainWord2vec_tfidfSenVecSim.h5\r\n-rw-r--r-- 1 kesci users 264M Aug  2 02:41 online_testWord2vec_avgSenVecSim.h5\r\n-rw-r--r-- 1 kesci users 130M Aug  5 21:51 online_testWord2vec_tfidfSenVecSim.h5\r\n-rw-r--r-- 1 kesci users 649M Aug  2 00:53 online_trainWord2vec_avgSenVecSim.h5\r\n-rw-r--r-- 1 kesci users 323M Aug  5 19:57 online_trainWord2vec_tfidfSenVecSim.h5\r\n","name":"stdout"}],"source":"import pickle\nfrom gensim.models.word2vec import LineSentence\nfrom gensim.models.callbacks import CallbackAny2Vec\nfrom gensim.models import Word2Vec\nfrom gensim.models import KeyedVectors\nfrom scipy.stats import skew, kurtosis\nfeature_save_dir = base_feature_save_dir + \"word2vec/\"\ntrain_feature_prefix = base_prefix + \"trainWord2vec\"\ntest_feature_prefix = base_prefix + \"testWord2vec\"\n! ls -alh /home/kesci/work/common/features/word2vec"},{"cell_type":"code","execution_count":26,"metadata":{"id":"76A3616FFE05428F83B7C636DE6CE552","scrolled":false,"collapsed":false},"outputs":[],"source":"def get_idf(word):\n    return tfidf_idf[tfidf_vocab[word]] if word in tfidf_vocab else 0.0\ndef sent2vec1(text):\n    global word2vec_model\n    word_count = {}\n    for _ in text.split():\n        word_count[_] = word_count.get(_, 0) + 1\n    return np.nan_to_num(\n          np.array([np.array(word2vec_model[w])*get_idf(w)*word_count[_] for w in word_count if w in word2vec_model] or [0.0] * word2vec_embed_size).mean(axis=0)\n      )"},{"cell_type":"code","execution_count":7,"metadata":{"id":"CDECCF235D094B0182DED24769FAF3F0","scrolled":false,"collapsed":false},"outputs":[],"source":"def sent2vec(text):\n    global word2vec_model\n    # TODO: 只能计算unigrams的值\n    return np.nan_to_num(\n          np.array([word2vec_model[w] for w in text.split() if w in word2vec_model] or [0.0] * word2vec_embed_size\n          ).mean(axis=0)\n      )"},{"cell_type":"markdown","metadata":{"id":"00019D0B86C54FAC8E9CCDEF35F7E344","mdEditEnable":false,"scrolled":false},"source":"### 生成word2vec句子相似度"},{"cell_type":"code","execution_count":8,"metadata":{"id":"FE844A39B4D441F588A8C50DA105123E","scrolled":false,"collapsed":false},"outputs":[],"source":"# word2vec to sent: https://www.zhihu.com/question/29978268\nregen_word2vec_sen_vec_sim = True\nprocess_word2vec_sen_vec_mode = \"avg\"  # \"avg\" or \"tfidf\"\nfeature_name = \"{}SenVecSim\".format(process_word2vec_sen_vec_mode)"},{"cell_type":"code","execution_count":9,"metadata":{"id":"E81C29274AFD4D838D3D2455266D6A3C","scrolled":false,"collapsed":false},"outputs":[],"source":"similar_dis = [\n    dist_utils.cosine_distance, \n    dist_utils.euclidean_distance,\n    dist_utils.cityblock_distance,\n    # dist_utils.jaccard_distance,\n    # dist_utils.braycurtis_distance,\n    # dist_utils.canberra_distance,\n    # dist_utils.minkowski_distance\n]"},{"cell_type":"code","execution_count":10,"metadata":{"id":"8DDC1915D9AF4A0692DDC47880088AC9","scrolled":false,"collapsed":false},"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n","name":"stderr"}],"source":"if regen_word2vec_sen_vec_sim:\n    word2vec_model = KeyedVectors.load(word2vec_kv_model_file, mmap='r')"},{"cell_type":"code","execution_count":31,"metadata":{"id":"1C8A8131A3B24C538E2C5A29DE4A3873","scrolled":false,"collapsed":false},"outputs":[],"source":"if regen_word2vec_sen_vec_sim and process_word2vec_sen_vec_mode == \"tfidf\":\n    with open(tfidf_model_file, \"rb\") as ff:\n        tfidf_model = pickle.load(ff)\n    tfidf_idf = tfidf_model.idf_\n    tfidf_vocab = tfidf_model.vocabulary_"},{"cell_type":"code","execution_count":11,"metadata":{"id":"FEF992DC1226417590B0BA329DC801B1","scrolled":false,"collapsed":false},"outputs":[],"source":"def process_word2vec_sen_vec(df, save_dir, prefix, feature_name):\n    with Timer(\"cal sent vec\"):\n        if process_word2vec_sen_vec_mode == \"avg\":\n            q_sen_vec = FuncMap1(sent2vec, df[\"query\"])\n            t_sen_vec = FuncMap1(sent2vec, df[\"title\"])\n        elif process_word2vec_sen_vec_mode == \"tfidf\":\n            q_sen_vec = FuncMap1(sent2vec1, df[\"query\"])\n            t_sen_vec = FuncMap1(sent2vec1, df[\"title\"])\n    with Timer(\"cal sent vec sim\"):\n        for _ in similar_dis:\n            name = _.__name__\n            with Timer(\"cal {} sim\".format(name)):\n                df[\"{}_{}\".format(prefix, name)] = FuncMap2(_, q_sen_vec, t_sen_vec)\n        del q_sen_vec, t_sen_vec\n        gc.collect()\n    return df"},{"metadata":{"id":"6482975D0DE74C0284187439555F141A","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->started 'extract avgSenVecSim feature' block...\n----->started 'cal sent vec' block...\n----->finished 'cal sent vec' block, time used:683.36s.\n----->started 'cal sent vec sim' block...\n----->started 'cal cosine_distance sim' block...\n----->finished 'cal cosine_distance sim' block, time used:158.8s.\n----->started 'cal euclidean_distance sim' block...\n----->finished 'cal euclidean_distance sim' block, time used:173.26s.\n----->started 'cal cityblock_distance sim' block...\n----->finished 'cal cityblock_distance sim' block, time used:129.03s.\n----->finished 'cal sent vec sim' block, time used:463.35s.\n----->started 'save feature' block...\nsaved avgSenVecSim feature to /home/kesci/work/common/features/word2vec/debug_trainWord2vec_avgSenVecSim.h5\n----->finished 'save feature' block, time used:32.64s.\n----->finished 'extract avgSenVecSim feature' block, time used:1188.21s.\n","name":"stdout"}],"source":"if regen_word2vec_sen_vec_sim:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, feature_name, \n                   process_func=process_word2vec_sen_vec, names=train_name, process_chunkly=False, \n                   chunk_size=CHUNK_SIZE, drop_first_cols=['query_id', 'query_title_id', \"label\"], \n                   drop_last_cols=['query', 'title'])","execution_count":12},{"metadata":{"id":"1CCEB5E6084A48848C9D5BE2ABB094A0","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->started 'extract avgSenVecSim feature' block...\n----->started 'cal sent vec' block...\n----->finished 'cal sent vec' block, time used:167.04s.\n----->started 'cal sent vec sim' block...\n----->started 'cal cosine_distance sim' block...\n----->finished 'cal cosine_distance sim' block, time used:39.84s.\n----->started 'cal euclidean_distance sim' block...\n----->finished 'cal euclidean_distance sim' block, time used:43.86s.\n----->started 'cal cityblock_distance sim' block...\n----->finished 'cal cityblock_distance sim' block, time used:32.43s.\n----->finished 'cal sent vec sim' block, time used:116.85s.\n----->started 'save feature' block...\nsaved avgSenVecSim feature to /home/kesci/work/common/features/word2vec/debug_testWord2vec_avgSenVecSim.h5\n----->finished 'save feature' block, time used:7.95s.\n----->finished 'extract avgSenVecSim feature' block, time used:293.33s.\n","name":"stdout"}],"source":"if regen_word2vec_sen_vec_sim:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, feature_name, \n                   process_func=process_word2vec_sen_vec, names=test_name, process_chunkly=False, \n                   chunk_size=CHUNK_SIZE, drop_first_cols=['query_id', 'query_title_id', \"label\"], \n                   drop_last_cols=['query', 'title'])","execution_count":13},{"cell_type":"markdown","metadata":{"id":"F8BC5809EC534E3680559FD378A629F1","mdEditEnable":false},"source":"### word2vec其他特征"},{"cell_type":"code","execution_count":9,"metadata":{"id":"E2F0C59AC64C48FB88C1DD00F8E6792F","scrolled":false,"collapsed":false},"outputs":[],"source":"word2vec_model_norm = None\nregen_word2vec_sen_vec_other = False\nprocess_word2vec_sen_vec_mode = \"avg\"\nfeature_name = \"{}SenVecOther\".format(process_word2vec_sen_vec_mode)"},{"cell_type":"code","execution_count":111,"metadata":{"id":"335A3AC4342F45A8B6409E565BD59C0F","scrolled":false},"outputs":[],"source":"def norm_wmd(s1, s2):\n    global word2vec_model_norm\n    dis = np.nan_to_num(word2vec_model_norm.wmdistance(s1, s2))\n    return dis if dis<100 else 100"},{"cell_type":"code","execution_count":112,"metadata":{"id":"A75CAA83ECB7483A85E18278583B7282","scrolled":false},"outputs":[],"source":"def wmd(s1, s2):\n    global word2vec_model\n    dis = np.nan_to_num(word2vec_model.wmdistance(s1, s2))\n    return dis if dis<100 else 100"},{"cell_type":"code","execution_count":113,"metadata":{"id":"D37E5667CBE84D61BD94A54807D4AC59","scrolled":false},"outputs":[],"source":"def run_word2vec_sen_vec_wmd(df, ngram, prefix, name):\n    q_list = df['query'].apply(ngram)\n    t_list = df['title'].apply(ngram)\n    df['%s_wmd%s' % (prefix, name)] = FuncMap2(wmd, q_list, t_list)\n    df['%s_normWmd%s' % (prefix, name)] = FuncMap2(norm_wmd, q_list, t_list)\n    del q_list, t_list\n    gc.collect()\n    return df"},{"cell_type":"code","execution_count":114,"metadata":{"id":"DFD1EBFA93D54C63B798ACFD526C3F8C","scrolled":false},"outputs":[],"source":"def run_word2vec_sen_vec_sk(df, func, q_sen_vec, t_sen_vec, prefix, name):\n    q_value = FuncMap1(func, q_sen_vec)\n    t_value = FuncMap1(func, t_sen_vec)\n    df['%s_q%s' % (prefix, name)] = q_value\n    df['%s_t%s' % (prefix, name)] = t_value\n    df['%s_%sDiff'%(prefix, name)] = FuncMap2(lambda a, b: abs(a-b), q_value, t_value)\n    df['%s_%sMax'%(prefix, name)] = FuncMap2(lambda a, b: max(a, b), q_value, t_value)\n    df['%s_%sMin'%(prefix, name)] = FuncMap2(lambda a, b: min(a, b), q_value, t_value)\n    df['%s_%sAvg'%(prefix, name)] = FuncMap2(lambda a, b: (a+b)/2, q_value, t_value)\n    return df"},{"cell_type":"code","execution_count":115,"metadata":{"id":"3CC24C2852BD4FCFAF855DA809F7A497","scrolled":false},"outputs":[],"source":"def process_word2vec_sen_vec_other(df, save_dir, prefix, feature_name):\n    \n    global word2vec_model_norm, word2vec_model_file\n    word2vec_model_norm = KeyedVectors.load(word2vec_model_file)\n    word2vec_model_norm.init_sims(replace=True)\n    \n    # with Timer(\"cal uni-wmd dis\"):\n    #     df = run_word2vec_sen_vec_wmd(df, ngram_utils.unigrams, prefix, \"Unigrams\")\n    # with Timer(\"cal bi-wmd dis\"):\n    #     df = run_word2vec_sen_vec_wmd(df, ngram_utils.bigrams, prefix, \"Bigrams\")\n        \n    with Timer(\"cal sent vec\"):\n        global process_word2vec_sen_vec_mode\n        if process_word2vec_sen_vec_mode == \"avg\":\n            q_sen_vec = FuncMap1(sent2vec, df[\"query\"])\n            t_sen_vec = FuncMap1(sent2vec, df[\"title\"])\n        elif process_word2vec_sen_vec_mode == \"tfidf\":\n            q_sen_vec = FuncMap1(sent2vec1, df[\"query\"])\n            t_sen_vec = FuncMap1(sent2vec1, df[\"title\"])\n    \n    with Timer(\"cal skew\"):\n        df = run_word2vec_sen_vec_sk(df, skew, q_sen_vec, t_sen_vec, prefix, \"Skew\")\n    with Timer(\"cal kurtosis\"):\n        df = run_word2vec_sen_vec_sk(df, kurtosis, q_sen_vec, t_sen_vec, prefix, \"Kurtosis\")\n        \n    del q_sen_vec, t_sen_vec\n    gc.collect()\n    \n    return df"},{"cell_type":"code","execution_count":117,"metadata":{"id":"DBD6C46BAC0345B68376EC52A2203471","scrolled":false},"outputs":[],"source":"if regen_word2vec_sen_vec_other:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, feature_name,\n        process_func=process_word2vec_sen_vec_other, names=ORI_TRAIN_NAMES,\n        process_chunkly=True, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], \n        drop_last_cols=['query', 'title'])"},{"cell_type":"markdown","metadata":{"id":"152557B408BF4CEEA6C5FE653C6CD8D6","mdEditEnable":false},"source":"## Magic特征"},{"cell_type":"code","execution_count":22,"metadata":{"id":"4C2E0149E5FE465EBCB250DEAD7FB466","scrolled":false,"collapsed":false},"outputs":[{"output_type":"stream","text":"total 63M\r\ndrwxr-xr-x 2 kesci root  4.0K Jul 23 15:40 .\r\ndrwxr-xr-x 6 kesci root  4.0K Jul 22 01:47 ..\r\n-rw-r--r-- 1 kesci users 716K Jul 22 11:57 debug_trainMagic_localCTR.h5\r\n-rw-r--r-- 1 kesci users  19M Jul 23 15:40 debug_trainMagic_localTfidfSim.h5\r\n-rw-r--r-- 1 kesci users 217K Jul 20 14:39 debug_trainMagic_queryFreq.h5\r\n-rw-r--r-- 1 kesci users  12M Jul 22 01:37 online_testMagic_localCTR.h5\r\n-rw-r--r-- 1 kesci users 2.4M Jul 22 01:34 online_testMagic_queryFreq.h5\r\n-rw-r--r-- 1 kesci users  24M Jul 22 01:36 online_trainMagic_localCTR.h5\r\n-rw-r--r-- 1 kesci users 5.0M Jul 22 01:33 online_trainMagic_queryFreq.h5\r\n","name":"stdout"}],"source":"feature_save_dir = base_feature_save_dir + \"magic/\"\ntrain_feature_prefix = base_prefix + \"trainMagic\"\ntest_feature_prefix = base_prefix + \"testMagic\"\n! ls -alh /home/kesci/work/common/features/magic"},{"cell_type":"markdown","metadata":{"id":"415BAFF0C7C146A587DB4BA7DD677742","mdEditEnable":false},"source":"### 提取query频率"},{"cell_type":"code","execution_count":3,"metadata":{"id":"82F529A01DFF4B1483991308775A9972","scrolled":false,"collapsed":false},"outputs":[],"source":"regen_query_freq = True\nfeature_name = \"queryFreq\""},{"metadata":{"id":"0CD493EB9F9448108A0E6DF1FA016721","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def process_query_freq(df, save_dir, prefix, feature_name):\n    grouped = df.groupby(\"query_id\", as_index=False)[\"query_title_id\"].count()\n    res = np.concatenate(FuncMap1(lambda x: [x]*x, grouped[\"query_title_id\"]))\n    del grouped, df\n    gc.collect()\n    return pd.DataFrame({\n        feature_name: res\n    })","execution_count":4},{"cell_type":"code","execution_count":5,"metadata":{"id":"3DC627A6B95E47B8AF09E6D22B442777","scrolled":false,"collapsed":false},"outputs":[{"output_type":"stream","text":"----->started 'extract queryFreq feature' block...\n----->started 'save feature' block...\nsaved queryFreq feature to /home/kesci/work/common/features/magic/online_trainMagic_queryFreq.h5\n----->finished 'save feature' block, time used:26.75s.\n----->finished 'extract queryFreq feature' block, time used:122.85s.\n","name":"stdout"}],"source":"if regen_query_freq:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, feature_name, \n        process_func=process_query_freq, names=ORI_TRAIN_NAMES,\n        process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query', 'title', 'label'], \n        drop_last_cols=['query_id', 'query_title_id'], strip=False)"},{"metadata":{"id":"9495A0941BA646488CDDACEFB54D84FE","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisHDF(\"/home/kesci/work/common/features/magic/debug_trainMagic_queryFreq.h5\", print_rows=10)","execution_count":103},{"cell_type":"code","execution_count":6,"metadata":{"id":"B64F181229BD4E02B1D613A1F334D5E6","scrolled":false,"collapsed":false},"outputs":[{"output_type":"stream","text":"----->started 'extract queryFreq feature' block...\n----->started 'save feature' block...\nsaved queryFreq feature to /home/kesci/work/common/features/magic/online_testMagic_queryFreq.h5\n----->finished 'save feature' block, time used:11.87s.\n----->finished 'extract queryFreq feature' block, time used:51.33s.\n","name":"stdout"}],"source":"if regen_query_freq and not OFFLINE:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, feature_name, \n        process_func=process_query_freq, names=ORI_TEST_NAMES,\n        process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query', 'title'], \n        drop_last_cols=['query_id', 'query_title_id'],strip=False)"},{"metadata":{"id":"E241C24FECC24CE682B6E66F4D336F05","mdEditEnable":false},"cell_type":"markdown","source":"### 局部tfidf特征"},{"metadata":{"id":"CA89A551570E4A638D84B2CC67860C2D","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"regen_localTfidf = True\nfeature_name = \"localTfidf\"\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import *","execution_count":39},{"metadata":{"id":"F2FDB8E7087A46C78E0F84BC56C4CBA8","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"dis_arr = [\n    paired_cosine_distances,\n    paired_euclidean_distances,\n    paired_manhattan_distances\n]","execution_count":40},{"metadata":{"id":"2C7D81C0433B4BE7B3A4F5BDEB23BFC0","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def process_local_tfidf(df, save_dir, prefix, feature_name):\n    grouped = df.groupby(\"query_id\")\n    dis_res = {}\n    for _ in dis_arr:\n        dis_res[_.__name__] = []\n    all_q_vec_len, all_t_vec_len = [], []\n    with Timer(\"cal local tfidf vec\"):\n        for name, group in grouped:\n            word_tfidf = TfidfVectorizer(norm=\"l2\",  # 'l2 norm' can cal similarty\n                                strip_accents=\"unicode\",\n                                analyzer=\"word\",\n                                ngram_range=(1, 3),\n                                use_idf=True,\n                                smooth_idf=True,\n                                sublinear_tf=True, min_df=1, max_df=1.0)\n            corpus = [_ for _ in group[\"title\"]]\n            corpus.append(group[\"query\"].iloc[-1])\n            word_tfidf.fit(corpus)\n            q_vec = word_tfidf.transform(group[\"query\"])\n            t_vec = word_tfidf.transform(group[\"title\"])\n            for _ in dis_arr:\n                dis_res[_.__name__].append(_(q_vec, t_vec))\n            all_q_vec_len.append(np.array(q_vec.sum(1)).squeeze())\n            all_t_vec_len.append(np.array(t_vec.sum(1)).squeeze())\n    with Timer(\"cal sim\"):\n        for _ in dis_arr:\n            name = _.__name__\n            df[\"{}_{}\".format(prefix, name)] = np.concatenate(dis_res[name])\n        del dis_res\n        gc.collect()\n    with Timer(\"cal len\"):\n        q_vec_len = np.concatenate(all_q_vec_len)\n        t_vec_len = np.concatenate(all_t_vec_len)\n        df['%s_QLen' % prefix] = q_vec_len\n        df['%s_TLen' % prefix] = t_vec_len\n        df['%s_QTLenRatio'%prefix] = FuncMap2(ratio_func, q_vec_len, t_vec_len)\n        df['%s_TQLenRatio'%prefix] = FuncMap2(ratio_func, t_vec_len, q_vec_len)\n        df['%s_QTDiff'%prefix] = FuncMap2(diff_func, q_vec_len, t_vec_len)\n        df['%s_QTMax'%prefix] = FuncMap2(max_func, q_vec_len, t_vec_len)\n        df['%s_QTMin'%prefix] = FuncMap2(min_func, q_vec_len, t_vec_len)\n        df['%s_QTAvg'%prefix] = FuncMap2(avg_func, q_vec_len, t_vec_len)\n        del all_q_vec_len, all_t_vec_len, q_vec_len, t_vec_len\n    return df","execution_count":41},{"metadata":{"id":"EEF2A88A47524D0D86D9A0152289DA38","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->started 'extract localTfidf feature' block...\n----->started 'cal local tfidf vec' block...\n----->finished 'cal local tfidf vec' block, time used:13410.16s.\n----->finished 'extract localTfidf feature' block, time used:13520.84s.\n","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-2598ca5e2d7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprocess_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess_local_tfidf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mORI_TRAIN_NAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_chunkly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         drop_first_cols=['query_title_id', 'label'], drop_last_cols=['query_id', 'query', 'title'])\n\u001b[0m","\u001b[0;32m~/work/common/utils.py\u001b[0m in \u001b[0;36mExtractFeature\u001b[0;34m(source_csv, save_dir, prefix, feature_name, process_func, names, process_chunkly, chunk_size, drop_first_cols, drop_last_cols, reduce_mem, strip)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0msource_csv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0miterator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m                 )\n\u001b[1;32m    174\u001b[0m             )\n","\u001b[0;32m~/work/common/utils.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(df, params)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;31m# 提取特征\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m             \u001b[0;31m# 如果有结果返回\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-41-a88fef72d7ba>\u001b[0m in \u001b[0;36mprocess_local_tfidf\u001b[0;34m(df, save_dir, prefix, feature_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mword_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mq_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mt_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1582\u001b[0m         \"\"\"\n\u001b[1;32m   1583\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1584\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1585\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1586\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1032\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    326\u001b[0m                                                tokenize)\n\u001b[1;32m    327\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 328\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_word_ngrams\u001b[0;34m(self, tokens, stop_words)\u001b[0m\n\u001b[1;32m    173\u001b[0m                             min(max_n + 1, n_original_tokens + 1)):\n\u001b[1;32m    174\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_original_tokens\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                     \u001b[0mtokens_append\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspace_join\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":"if regen_localTfidf:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, feature_name, \n        process_func=process_local_tfidf, \n        names=ORI_TRAIN_NAMES, process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_title_id', 'label'], drop_last_cols=['query_id', 'query', 'title'])","execution_count":35},{"metadata":{"id":"DFD6467364454A6F8252AF80A0FCCBC5","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisHDF(\"/home/kesci/work/common/features/magic/debug_trainMagic_localTfidfSim.h5\")","execution_count":10},{"metadata":{"id":"E1DB92E081A545C798B3261FA96E935C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"if regen_localTfidf and not OFFLINE:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, feature_name, \n        process_func=process_local_tfidf, \n        names=ORI_TEST_NAMES, process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_title_id'], drop_last_cols=['query_id', 'query', 'title'])","execution_count":null},{"cell_type":"markdown","metadata":{"id":"2570D7A6D15A40A4BDC5AA14272C062F","mdEditEnable":false},"source":"### 局部点击率特征"},{"cell_type":"code","execution_count":22,"metadata":{"id":"11F0EF4C03A04CA982BE108D9CB0B36B","scrolled":false,"collapsed":false},"outputs":[],"source":"regen_ctr = True\nfeature_name = \"localCTR\"\nstat = {}"},{"cell_type":"code","execution_count":23,"metadata":{"id":"39BF45B506314BF9A8D04616B20D221A","scrolled":false,"collapsed":false},"outputs":[],"source":"def ExtractLocalCTR(df, save_dir, prefix, feature_name):\n    global stat\n    grouped = df.groupby(\"query_id\", as_index=False)\n    count = grouped.size().values\n    if not stat:\n        label_sum = grouped[\"label\"].sum()[\"label\"].values.astype(\"int32\")\n        for _ in range(len(count)):\n            item_len = count[_]\n            if item_len not in stat:\n                stat[item_len] = [1, label_sum[_]]\n            else:\n                stat[item_len][0] += 1\n                stat[item_len][1] += label_sum[_]\n        del label_sum\n    res = [[ stat[_][1] / (_ * stat[_][0])]*_ for _ in count]\n    result = []\n    for _ in res:\n        result.extend(_)\n    del grouped, res\n    gc.collect()\n    df[\"{}_localCTR\".format(prefix)] = result\n    return df"},{"cell_type":"code","execution_count":24,"metadata":{"id":"33E353FEFC7D4577A377992D5FE489C5","scrolled":false,"collapsed":false},"outputs":[{"output_type":"stream","text":"----->started 'extract localCTR feature' block...\n----->started 'save feature' block...\nsaved localCTR feature to /home/kesci/work/common/features/magic/debug_trainMagic_localCTR.h5\n----->finished 'save feature' block, time used:0.6s.\n----->finished 'extract localCTR feature' block, time used:3.25s.\n","name":"stdout"}],"source":"if regen_ctr:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, feature_name, \n    ExtractLocalCTR, names=ORI_TRAIN_NAMES,process_chunkly=False, \n    drop_first_cols=['query_title_id', 'query', 'title'], \n    drop_last_cols=['query_id', 'label'], strip=False)"},{"metadata":{"id":"F6B9A06D2F464B2C8E0D751233777B94","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisHDF(\"/home/kesci/work/common/features/magic/debug_trainMagic_localCTR.h5\", print_rows=10)","execution_count":33},{"cell_type":"code","execution_count":10,"metadata":{"id":"6360746B670045F4BB764785F47B713C","scrolled":false,"collapsed":false},"outputs":[{"output_type":"stream","text":"----->started 'extract localCTR feature' block...\n----->started 'save feature' block...\nsaved localCTR feature to /home/kesci/work/common/features/magic/online_testMagic_localCTR.h5\n----->finished 'save feature' block, time used:12.38s.\n----->finished 'extract localCTR feature' block, time used:61.49s.\n","name":"stdout"}],"source":"if not OFFLINE and regen_ctr:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, feature_name, \n    ExtractLocalCTR, names=ORI_TEST_NAMES,process_chunkly=False, \n    drop_first_cols=['query_title_id', 'query', 'title'], \n    drop_last_cols=['query_id'], strip=False)"},{"metadata":{"id":"D448A25A7F604AB98C5A2788AC23AB63","mdEditEnable":false},"cell_type":"markdown","source":"## 杂项"},{"metadata":{"id":"D548613B659A4E5882553098BD318375","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"1713\n","name":"stdout"}],"source":"import os\nprint(os.getpid())","execution_count":7},{"metadata":{"id":"9FE76FD6A45F4D548C7244AAC41CCD07","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"! kill -9 1713","execution_count":null},{"metadata":{"id":"7C5DCE31383140A182518F5E8C1D8F6F"},"cell_type":"code","outputs":[],"source":"","execution_count":null}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}