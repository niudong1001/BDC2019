{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 包引入与变量准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import csv\n",
    "sys.path.append(\"./global\")\n",
    "from helper import Timer, usetime, OFFLINE, cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始训练与测试数据位置\n",
    "if OFFLINE:\n",
    "    ori_train_file = \"./legacy/data/train.csv\"\n",
    "    ori_test_file = \"./legacy/data/test.csv\"\n",
    "    ori_test_label_file = \"./legacy/data/test_label.csv\"\n",
    "else:\n",
    "    ori_train_file = \"/home/kesci/input/bytedance/first-round/train.csv\"\n",
    "    ori_test_file = \"/home/kesci/input/bytedance/first-round/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage0阶段\n",
    "stage0_output_dir = \"./stage1/input/\"\n",
    "## 训练数据相关\n",
    "if OFFLINE:\n",
    "    train_file = stage0_output_dir + \"train.csv\"\n",
    "else:\n",
    "    random_sample = False\n",
    "    if random_sample:\n",
    "        random_rate = 0.05\n",
    "        train_file = stage0_output_dir + \"train_random_005.csv\"\n",
    "    else:\n",
    "        sample_num = 5000000\n",
    "        # 默认取前500w条\n",
    "        train_file = stage0_output_dir + \"train_front_500w.csv\"\n",
    "## 测试数据相关\n",
    "test_file = stage0_output_dir + \"test.csv\"\n",
    "# 线下可以增加测试集label\n",
    "if OFFLINE:\n",
    "    test_label_file = stage0_output_dir + \"test_label.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage1阶段\n",
    "state1_dir = \"./stage1/\"\n",
    "stage1_code_dir = state1_dir + \"code/\"\n",
    "stage1_input_dir = state1_dir + \"input/\"\n",
    "stage1_output_dir = state1_dir + \"output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage2阶段\n",
    "state2_dir = \"./stage2/\"\n",
    "stage2_input_dir = state2_dir + \"input/\"\n",
    "stage2_output_dir = state2_dir + \"output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerate_all = False  # 谨慎使用这个参数 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage0阶段\n",
    "\n",
    "这一阶段主要是数据准备，且只需要运行一次。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stage0.code.data_prepare import RandomSampleCSV, SampleCSV\n",
    "regenerate_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if regenerate_all or regenerate_data:\n",
    "    # 训练数据准备\n",
    "    if OFFLINE:\n",
    "        cp(ori_train_file, train_file)\n",
    "    else:\n",
    "        if random_sample:\n",
    "            # 随机从一亿数据中采样rate比例的数据来训练\n",
    "            RandomSampleCSV(source_csv=ori_train_file, save_file=train_file, rate=random_rate)\n",
    "        else:\n",
    "            # 取前c条数据来训练   \n",
    "            SampleCSV(source_csv=ori_train_file, save_file=train_file, count=sample_num)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if regenerate_all or regenerate_data:\n",
    "    # 测试数据准备\n",
    "    if OFFLINE:\n",
    "        cp(ori_test_file, test_file)\n",
    "        cp(ori_test_label_file, test_label_file)\n",
    "    else:\n",
    "        cp(ori_test_file, test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage1阶段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提取词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stage1.code.build_word2vec import PrepareWord2vecSamples, TrainWord2vec\n",
    "stage1_word2vec_sentences = stage1_input_dir+\"word2vec_sentences.txt\"\n",
    "stage1_word2vec_model = stage1_output_dir+\"word2vec\"\n",
    "regenerate_embedding_samples = False  # 重新生成适合embedding训练的样本集\n",
    "regenerate_embedding_model = False  # 重新生成适合embedding模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2vec\n",
    "\n",
    "1. 生成Word2vec可直接训练的sentences文件\n",
    "2. 训练word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->Started 'Prepare for word2vec samples' block...\n",
      "----->Finished 'Prepare for word2vec samples' block, time used: 0.07s.\n"
     ]
    }
   ],
   "source": [
    "# 生成适合word2vec训练的样本集\n",
    "if regenerate_all or regenerate_embedding_samples:\n",
    "    PrepareWord2vecSamples(train_file, stage1_word2vec_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->Started 'Train word2vec' block...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niudong/workon_home/py3/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->Finished 'Train word2vec' block, time used: 0.98s.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niudong/workon_home/py3/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "/Users/niudong/workon_home/py3/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "# 生成word2vec模型\n",
    "if regenerate_all or regenerate_embedding_model:\n",
    "    TrainWord2vec(stage1_word2vec_sentences, stage1_word2vec_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FastText\n",
    "\n",
    "FastText的使用：https://blog.csdn.net/ymaini/article/details/81489599\n",
    "\n",
    "1. 生成适合fastText训练的文本格式\n",
    "2. 有监督训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProcessForTrainFastText(train_file_data, stage1_input_dir+\"fastText_labeled_content.txt\", add_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd stage1/code; python build_fastText.py -f \"../input/fastText_labeled_content.txt\" -d \"../output/\" -s \"fastText_supervised.bin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stage1.code.feature_text import ExtractTextFeature\n",
    "from stage1.code.feature_embed import ExtractEmbedFeature\n",
    "from helper import ORI_TRAIN_NAMES, ORI_TEST_NAMES, ORI_TRAIN_DTYPE, ORI_TEST_DTYPE\n",
    "feature_prefix = \"v1\"\n",
    "regenerate_feature = False\n",
    "regenerate_text_feature = False\n",
    "regenerate_embed_feature = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Mining Featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->Started 'Extract text feature' block...\n",
      "----->Finished 'Extract text feature' block, time used: 10.8s.\n"
     ]
    }
   ],
   "source": [
    "if regenerate_all or regenerate_feature or regenerate_text_feature:\n",
    "    # 提取train的特征\n",
    "    ExtractTextFeature(train_file, save_dir=stage1_output_dir, prefix=\"train_{}\".format(feature_prefix), \n",
    "                       names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, process_chunkly=False,\n",
    "                       drop_cols=['query', 'title', 'label', \"query_id\", \"query_title_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->Started 'Extract text feature' block...\n",
      "----->Finished 'Extract text feature' block, time used: 3.5s.\n"
     ]
    }
   ],
   "source": [
    "if regenerate_all or regenerate_feature or regenerate_text_feature:\n",
    "    # 提取test的特征\n",
    "    ExtractTextFeature(test_file, save_dir=stage1_output_dir, prefix=\"test_{}\".format(feature_prefix), \n",
    "                       names=ORI_TEST_NAMES, dtype=ORI_TEST_DTYPE, process_chunkly=False,\n",
    "                       drop_cols=['query', 'title', \"query_id\", \"query_title_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----->Started 'Extract embedding feature' block...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/niudong/workon_home/py3/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
      "/Users/niudong/workon_home/py3/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "if regenerate_all or regenerate_feature or regenerate_embed_feature:\n",
    "    # 提取train的特征 \n",
    "    ExtractEmbedFeature(train_file, save_dir=stage1_output_dir, prefix=\"train_{}\".format(feature_prefix), \n",
    "                       names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, process_chunkly=False,\n",
    "                       drop_cols=['query', 'title', 'label', \"query_id\", \"query_title_id\"], \n",
    "                       embed_mode=\"word2vec\", embed_model_file=stage1_word2vec_model+\".kv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if regenerate_all or regenerate_feature or regenerate_embed_feature:\n",
    "    # 提取test的特征 \n",
    "    ExtractEmbedFeature(test_file, save_dir=stage1_output_dir, prefix=\"test_{}\".format(feature_prefix), \n",
    "                       names=ORI_TEST_NAMES, dtype=ORI_TEST_DTYPE, process_chunkly=False,\n",
    "                       drop_cols=['query', 'title', \"query_id\", \"query_title_id\"], \n",
    "                       embed_mode=\"word2vec\", embed_model_file=stage1_word2vec_model+\".kv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for Stage2\n",
    "\n",
    "本节是将一些stage1产生的结果进过处理后放到stage2的input里面去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stage1.code.prepare_for_stage2 import ExtractTrainLabel, ConvertCSVToNPY, CombineFeatures\n",
    "\n",
    "# stage1\n",
    "## text feature\n",
    "train_text_feature_stage1 = stage1_output_dir + \"train_{}_feature_text.csv\".format(feature_prefix)\n",
    "test_text_feature_stage1 = stage1_output_dir + \"test_{}_feature_text.csv\".format(feature_prefix)\n",
    "## embed feature\n",
    "train_embed_feature_stage1 = stage1_output_dir + \"train_{}_feature_embed.csv\".format(feature_prefix)\n",
    "test_embed_feature_stage1 = stage1_output_dir + \"test_{}_feature_embed.csv\".format(feature_prefix)\n",
    "## concat\n",
    "train_concat_feature_stage1 = stage1_output_dir + \"train_{}_feature_concat.csv\".format(feature_prefix)\n",
    "test_concat_feature_stage1 = stage1_output_dir + \"test_{}_feature_concat.csv\".format(feature_prefix)\n",
    "\n",
    "# stage2\n",
    "## text feature\n",
    "train_feature_stage2 = stage2_input_dir + \"train_{}_feature_concat.npy\".format(feature_prefix)\n",
    "test_feature_stage2 = stage2_input_dir + \"test_{}_feature_concat.npy\".format(feature_prefix)\n",
    "train_labels_stage2 = stage2_input_dir+\"train_labels.npy\"\n",
    "test_labels_stage2 = None\n",
    "if OFFLINE:\n",
    "    test_labels_stage2 = stage2_input_dir+\"test_labels.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取标签\n",
    "if regenerate_all or regenerate_data:\n",
    "    # 提取训练集的标签并单独存储\n",
    "    ExtractTrainLabel(train_file, train_labels_stage2)\n",
    "    if OFFLINE:\n",
    "        # 提取测试集的标签并单独存储\n",
    "        ExtractTrainLabel(test_label_file, test_labels_stage2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接特征并输出到stage2\n",
    "if regenerate_all or regenerate_feature:\n",
    "    CombineFeatures([train_text_feature_stage1, train_embed_feature_stage1], train_concat_feature_stage1)\n",
    "    CombineFeatures([test_text_feature_stage1, test_embed_feature_stage1], test_concat_feature_stage1)\n",
    "    ConvertCSVToNPY(train_concat_feature_stage1, train_feature_stage2)\n",
    "    ConvertCSVToNPY(test_concat_feature_stage1, test_feature_stage2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage2阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stage2.code.run_hyperopt import LoadDataset, run_lgb_gbdt, run_lgb_dart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "LoadDataset(in_train_feature=train_feature_stage2, \n",
    "            in_train_label=train_labels_stage2, \n",
    "            in_test_feature=test_feature_stage2,\n",
    "            in_test_label=test_labels_stage2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_lgb_gbdt(eval_num=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_lgb_dart(eval_num=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
