{"cells":[{"metadata":{"id":"CD15BE576B4C4D128B3AA9EB9A9A8C76","mdEditEnable":false},"cell_type":"markdown","source":"# 特征提取"},{"metadata":{"id":"40F26B9530E44CC49103F8FD48BE1CBA","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"True\n","name":"stdout"}],"source":"import sys, os, gc\nimport numpy as np\nimport pandas as pd\nsys.path.append(\"./global\")\nfrom helper import ReadCSV, Timer, ExtractFeature, ORI_TRAIN_NAMES, ORI_TRAIN_DTYPE, ORI_TEST_NAMES, ORI_TEST_DTYPE, AnalysisCSV, OFFLINE, cal_sim\nimport dist_utils, ngram_utils\ntest_file = \"./stage1/input/test.csv\"\nbase_feature_save_dir = \"./stage1/output/\"\nif OFFLINE:\n    base_prefix = \"debug_\"\n    train_file = \"./stage1/input/train_last_50w.csv\"\n    CHUNK_SIZE = 500000\nelse:\n    base_prefix = \"online_\"\n    train_file = \"./stage1/input/train_last_1000w.csv\"\n    CHUNK_SIZE = 1000000\nprint(OFFLINE)","execution_count":1},{"metadata":{"id":"73FFBA10732C44358124FA09B33BC75E","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"tmp = np.load(\"./stage2/input/online_train_concat_feature.npy\")","execution_count":11},{"metadata":{"id":"3329075EBF6141EEAB3B8ADED3B774EA","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# print(tmp[:5])","execution_count":2},{"metadata":{"id":"761C585EC2274901AB7E188FED28CA82","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Collecting fuzzywuzzy\n  Downloading http://pypi/simple/fuzzywuzzy/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\nInstalling collected packages: fuzzywuzzy\nSuccessfully installed fuzzywuzzy-0.17.0\n","name":"stdout"}],"source":"! pip install  --index \"http://pypi/simple\" --trusted-host pypi fuzzywuzzy","execution_count":4},{"metadata":{"id":"3C6CEED2F1574088BFB7BD0B3AFA68C0","mdEditEnable":false},"cell_type":"markdown","source":"## 文本挖掘特征"},{"metadata":{"id":"C1B9B465F2234AD68651BF514CC7D8E6","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"total 945M\r\ndrwxr-xr-x 2 kesci root  4.0K Jun 20 16:39 .\r\ndrwxr-xr-x 7 kesci root  4.0K Jun 19 09:08 ..\r\n-rw-r--r-- 1 kesci users 4.6M Jun 20 11:29 debug_trainTextMining_len.csv.gz\r\n-rw-r--r-- 1 kesci users  26M Jun 20 11:41 debug_trainTextMining_ngramSim.csv.gz\r\n-rw-r--r-- 1 kesci users  47M Jun 20 13:22 online_testTextMining_len.csv.gz\r\n-rw-r--r-- 1 kesci users 262M Jun 20 16:46 online_testTextMining_ngramSim.csv.gz\r\n-rw-r--r-- 1 kesci users  92M Jun 20 13:19 online_trainTextMining_len.csv.gz\r\n-rw-r--r-- 1 kesci users 515M Jun 20 15:35 online_trainTextMining_ngramSim.csv.gz\r\n","name":"stdout"}],"source":"from fuzzywuzzy import fuzz\nfeature_save_dir = base_feature_save_dir + \"text_mining_feature/\"\ntrain_feature_prefix = base_prefix + \"trainTextMining\"\ntest_feature_prefix = base_prefix + \"testTextMining\"\n! ls -alh ./stage1/output/text_mining_feature/","execution_count":5},{"metadata":{"id":"EBE478C8B05D40B680CBD2AB3E3CAFF1","mdEditEnable":false},"cell_type":"markdown","source":"提取长度特征"},{"metadata":{"id":"E7F6EF4CF5FB44CC850D8E2DA410704C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"regen_len_feature = False","execution_count":6},{"metadata":{"id":"60DD46D6363B47688636727332B06FBA","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def run_text_len(df, ngram, prefix):\n    # ngram\n    if ngram:\n        q_list = df['query'].apply(ngram)\n        t_list = df['title'].apply(ngram)\n    else:\n        q_list = df['query']\n        t_list = df['title']\n    ## 长度特征\n    with Timer(\"extract length\"):\n        df['%s_q-len' % prefix] = np.vectorize(len)(q_list)\n        df['%s_t-len' % prefix] = np.vectorize(len)(t_list)\n        df['%s_qt-len-radio'%prefix] = list(map(lambda a, b: a/b, \n            df['%s_q-len' % prefix], \n            df['%s_t-len' % prefix]))\n        df['%s_tq-len-radio'%prefix] = list(map(lambda a, b: b/a, \n            df['%s_q-len' % prefix], \n            df['%s_t-len' % prefix]))\n    del q_list, t_list\n    gc.collect()\n    return df\ndef process_text_len(df, prefix, savefile):\n    df = run_text_len(df, None, '%s_%s' % (prefix, 'text'))\n    df = run_text_len(df, ngram_utils.unigrams, '%s_%s' % (prefix, 'unigrams'))\n    return df","execution_count":4},{"metadata":{"id":"CBD06EEC5BBD4004B33CE283911513CF","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract len feature' block...\nMem. usage decreased to 152.59 Mb (0.0% reduction)\n----->Started 'extract length' block...\n----->Finished 'extract length' block, time used:10.52s.\n----->Started 'extract length' block...\n----->Finished 'extract length' block, time used:10.98s.\nsaved len feature to ./stage1/output/text_mining_feature/online_trainTextMining_len.csv.gz\n----->Finished 'extract len feature' block, time used:318.4s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_len_feature:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"len\", process_func=process_text_len, \n        names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], drop_last_cols=['query', 'title'])","execution_count":5},{"metadata":{"id":"B490167AEC954DE19717808444B13724","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"./stage1/output/text_mining_feature/debug_trainTextMining_feature_len.csv\")","execution_count":15},{"metadata":{"id":"5CEF3CB2AEB44E038AD28D5EBC235D88","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract len feature' block...\nMem. usage decreased to 76.29 Mb (0.0% reduction)\n----->Started 'extract length' block...\n----->Finished 'extract length' block, time used:5.65s.\n----->Started 'extract length' block...\n----->Finished 'extract length' block, time used:5.59s.\nsaved len feature to ./stage1/output/text_mining_feature/online_testTextMining_len.csv.gz\n----->Finished 'extract len feature' block, time used:165.49s.\n","name":"stdout"}],"source":"if not OFFLINE and regen_len_feature:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, \"len\", process_func=process_text_len, \n    names=ORI_TEST_NAMES, dtype=ORI_TEST_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n    drop_first_cols=['query_id', 'query_title_id'], drop_last_cols=['query', 'title'])","execution_count":6},{"metadata":{"id":"AE102779A0EE42E8A4128D44605553E5","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"time: 989 µs\n","name":"stdout"}],"source":"# AnalysisCSV(\"./stage1/output/text_mining_feature/debug_train_text_mining_feature_len.csv\")","execution_count":11},{"metadata":{"id":"7DDCC4D135FF46D086F1D9D77D7C29F3","mdEditEnable":false},"cell_type":"markdown","source":"提取集合相似度特征"},{"metadata":{"id":"C8534A0F74A54363AE989AD3FBED6EC9","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"regen_ngram_similarity_feature = False\nsimilar_arr = [\n    dist_utils.dice_ratio,\n    # dist_utils.jaccard_ratio,\n    dist_utils.edit_seq_ratio,\n    dist_utils.edit_set_ratio,\n    fuzz.ratio,\n    fuzz.partial_ratio,\n    fuzz.token_sort_ratio\n]","execution_count":10},{"metadata":{"id":"F06C42D8A5B649B2868E541787C39840","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def run_ngram_similarity(df, ngram, prefix):\n    # ngram\n    if ngram:\n        q_list = df['query'].apply(ngram)\n        t_list = df['title'].apply(ngram)\n    else:\n        q_list = df['query']\n        t_list = df['title']\n    ## 长度特征\n    with Timer(\"extract similarity\"):\n        for _ in similar_arr:\n            name = _.__name__\n            with Timer(\"cal {} sim\".format(name)):\n                df[\"{}_{}\".format(prefix, name)] = cal_sim(q_list, t_list, _)\n    del q_list, t_list\n    gc.collect()\n    return df\n\ndef process_ngram_similarity(df, prefix, savefile):\n    df = run_ngram_similarity(df, None, '%s_%s' % (prefix, 'text'))\n    df = run_ngram_similarity(df, ngram_utils.unigrams, '%s_%s' % (prefix, 'unigrams'))\n    df = run_ngram_similarity(df, ngram_utils.bigrams, '%s_%s' % (prefix, 'bigrams'))\n    df = run_ngram_similarity(df, ngram_utils.trigrams, '%s_%s' % (prefix, 'trigrams'))\n    return df","execution_count":8},{"metadata":{"id":"B042F9B774C24DFD848620F742E833B1","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract ngramSim feature' block...\nMem. usage decreased to 152.59 Mb (0.0% reduction)\n----->Started 'extract similarity' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:35.5s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:132.57s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:176.85s.\n----->Started 'cal ratio sim' block...\n----->Finished 'cal ratio sim' block, time used:70.39s.\n----->Started 'cal partial_ratio sim' block...\n----->Finished 'cal partial_ratio sim' block, time used:330.6s.\n----->Started 'cal token_sort_ratio sim' block...\n----->Finished 'cal token_sort_ratio sim' block, time used:272.39s.\n----->Finished 'extract similarity' block, time used:1018.32s.\n----->Started 'extract similarity' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:32.05s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:76.63s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:88.37s.\n----->Started 'cal ratio sim' block...\n----->Finished 'cal ratio sim' block, time used:131.24s.\n----->Started 'cal partial_ratio sim' block...\n----->Finished 'cal partial_ratio sim' block, time used:600.9s.\n----->Started 'cal token_sort_ratio sim' block...\n----->Finished 'cal token_sort_ratio sim' block, time used:455.59s.\n----->Finished 'extract similarity' block, time used:1384.78s.\n----->Started 'extract similarity' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:32.46s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:94.4s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:103.23s.\n----->Started 'cal ratio sim' block...\n----->Finished 'cal ratio sim' block, time used:167.1s.\n----->Started 'cal partial_ratio sim' block...\n----->Finished 'cal partial_ratio sim' block, time used:1016.98s.\n----->Started 'cal token_sort_ratio sim' block...\n----->Finished 'cal token_sort_ratio sim' block, time used:504.87s.\n----->Finished 'extract similarity' block, time used:1919.04s.\n----->Started 'extract similarity' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:30.16s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:114.16s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:123.1s.\n----->Started 'cal ratio sim' block...\n----->Finished 'cal ratio sim' block, time used:187.3s.\n----->Started 'cal partial_ratio sim' block...\n----->Finished 'cal partial_ratio sim' block, time used:1405.5s.\n----->Started 'cal token_sort_ratio sim' block...\n----->Finished 'cal token_sort_ratio sim' block, time used:506.58s.\n----->Finished 'extract similarity' block, time used:2366.81s.\nsaved ngramSim feature to ./stage1/output/text_mining_feature/online_trainTextMining_ngramSim.csv.gz\n----->Finished 'extract ngramSim feature' block, time used:7879.54s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_ngram_similarity_feature:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"ngramSim\", \n        process_func=process_ngram_similarity, \n        names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], drop_last_cols=['query', 'title'])","execution_count":11},{"metadata":{"id":"FBBBDAAE926D49038C9C5E824014F74C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"./stage1/output/text_mining_feature/debug_trainTextMining_feature_ngramSimilar.csv\")","execution_count":21},{"metadata":{"id":"F6447FEAEFAC431C89BEB6ECDD6208BF","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract ngramSim feature' block...\nMem. usage decreased to 76.29 Mb (0.0% reduction)\n----->Started 'extract similarity' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:17.78s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:61.66s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:90.05s.\n----->Started 'cal ratio sim' block...\n----->Finished 'cal ratio sim' block, time used:33.92s.\n----->Started 'cal partial_ratio sim' block...\n----->Finished 'cal partial_ratio sim' block, time used:171.25s.\n----->Started 'cal token_sort_ratio sim' block...\n----->Finished 'cal token_sort_ratio sim' block, time used:136.22s.\n----->Finished 'extract similarity' block, time used:510.89s.\n----->Started 'extract similarity' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:15.85s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:36.05s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:44.91s.\n----->Started 'cal ratio sim' block...\n----->Finished 'cal ratio sim' block, time used:65.59s.\n----->Started 'cal partial_ratio sim' block...\n----->Finished 'cal partial_ratio sim' block, time used:315.01s.\n----->Started 'cal token_sort_ratio sim' block...\n----->Finished 'cal token_sort_ratio sim' block, time used:233.73s.\n----->Finished 'extract similarity' block, time used:711.14s.\n----->Started 'extract similarity' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:16.22s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:48.95s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:53.71s.\n----->Started 'cal ratio sim' block...\n----->Finished 'cal ratio sim' block, time used:87.67s.\n----->Started 'cal partial_ratio sim' block...\n----->Finished 'cal partial_ratio sim' block, time used:583.38s.\n----->Started 'cal token_sort_ratio sim' block...\n----->Finished 'cal token_sort_ratio sim' block, time used:257.73s.\n----->Finished 'extract similarity' block, time used:1047.66s.\n----->Started 'extract similarity' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:14.72s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:58.66s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:64.2s.\n----->Started 'cal ratio sim' block...\n----->Finished 'cal ratio sim' block, time used:98.05s.\n----->Started 'cal partial_ratio sim' block...\n----->Finished 'cal partial_ratio sim' block, time used:861.49s.\n----->Started 'cal token_sort_ratio sim' block...\n----->Finished 'cal token_sort_ratio sim' block, time used:270.6s.\n----->Finished 'extract similarity' block, time used:1367.72s.\nsaved ngramSim feature to ./stage1/output/text_mining_feature/online_testTextMining_ngramSim.csv.gz\n----->Finished 'extract ngramSim feature' block, time used:4238.65s.\n","name":"stdout"}],"source":"if not OFFLINE and regen_ngram_similarity_feature:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, \"ngramSim\", \n    process_func=process_ngram_similarity, \n    names=ORI_TEST_NAMES, dtype=ORI_TEST_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n    drop_first_cols=['query_id', 'query_title_id'], drop_last_cols=['query', 'title'])","execution_count":12},{"metadata":{"id":"15E7A63098994D708D5CD5744E814A33","mdEditEnable":false},"cell_type":"markdown","source":"## 向量空间特征"},{"metadata":{"id":"BBE2052F8A5D48EBAFF63A4DC5CEE6AB","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"total 89M\r\ndrwxr-xr-x 2 kesci root  4.0K Jun 20 11:43 .\r\ndrwxr-xr-x 7 kesci root  4.0K Jun 19 09:08 ..\r\n-rw-r--r-- 1 kesci users  89M Jun 20 11:43 debug_tfidf_model.bin\r\n","name":"stdout"}],"source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nimport pickle\nfeature_save_dir = base_feature_save_dir + \"vector_space/\"\ntrain_feature_prefix = base_prefix + \"trainVectorSpace\"\ntest_feature_prefix = base_prefix + \"testVectorSpace\"\n! ls -alh ./stage1/output/vector_space/","execution_count":13},{"metadata":{"id":"AD8B31E0B0D24055ABB2462F7C9E0D7A","mdEditEnable":false},"cell_type":"markdown","source":"训练tfidf模型"},{"metadata":{"id":"DAE6BBDE89184CC89B739475558CE7AD","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"total 89M\r\n89M -rw-r--r-- 1 kesci users 89M Jun 20 11:43 debug_tfidf_model.bin\r\n","name":"stdout"}],"source":"regen_tfidf_model = True\nif OFFLINE:\n    tfidf_model_file = feature_save_dir+\"debug_tfidf_model.bin\"\nelse:\n    tfidf_model_file = feature_save_dir+\"online_tfidf_model.bin\"\n! ls -lsh ./stage1/output/vector_space","execution_count":14},{"metadata":{"id":"5B1C90A46AE844FA824D86B50A63650C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def train_tfidf(df, prefix, savefile):\n    word_tfidf = TfidfVectorizer(norm=\"l2\",\n                                    strip_accents=\"unicode\",\n                                    analyzer=\"word\",\n                                    ngram_range=(1, 2),\n                                    use_idf=True,\n                                    smooth_idf=True,\n                                    sublinear_tf=True, min_df=2, max_df=0.9)\n    new_query = df[\"query\"].unique()\n    new_title = df[\"title\"].values\n    print(new_query.shape)\n    print(new_title.shape)\n    corpus = np.concatenate([new_query, new_title])\n    # print(corpus[:10])\n    # print(corpus[10:])\n    del df\n    gc.collect()\n    with Timer(\"tf-idf fit\"):\n        word_tfidf.fit(corpus)\n        with open(tfidf_model_file, \"wb\") as f:\n            pickle.dump(word_tfidf, f)\n            print(\"Model dumped to {}\".format(tfidf_model_file))\n    return None","execution_count":15},{"metadata":{"id":"481C9684448446EDB76E03D030B50B3C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract tfidf feature' block...\nMem. usage decreased to 152.59 Mb (0.0% reduction)\n(1512239,)\n(10000000,)\n----->Started 'tf-idf fit' block...\nModel dumped to ./stage1/output/vector_space/online_tfidf_model.bin\n----->Finished 'tf-idf fit' block, time used:748.26s.\n----->Finished 'extract tfidf feature' block, time used:773.66s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_tfidf_model:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"tfidf\", \n        process_func=train_tfidf, names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, \n        process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], \n        drop_last_cols=['query', 'title'])","execution_count":16},{"metadata":{"id":"5985318916B1435D8687DE64F698F4E5","mdEditEnable":false},"cell_type":"markdown","source":"## 提取word2vec特征"},{"metadata":{"id":"07E9877B444D484E93CB0BC611F297FE","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"total 874M\r\ndrwxr-xr-x 2 kesci root  4.0K Jun 22 01:22 .\r\ndrwxr-xr-x 7 kesci root  4.0K Jun 19 09:08 ..\r\n-rw-r--r-- 1 kesci users  29M Jun 22 01:17 debug_trainWord2vec_senVecavgSim.csv.gz\r\n-rw-r--r-- 1 kesci users 282M Jun 21 12:33 online_testWord2vec_senVecavgSim.csv.gz\r\n-rw-r--r-- 1 kesci users 564M Jun 21 09:21 online_trainWord2vec_senVecavgSim.csv.gz\r\n","name":"stdout"}],"source":"from gensim.models import Word2Vec\nfrom gensim.models import KeyedVectors\nfrom gensim.models.callbacks import CallbackAny2Vec\nimport pickle\nfeature_save_dir = base_feature_save_dir + \"word2vec/\"\ntrain_feature_prefix = base_prefix + \"trainWord2vec\"\ntest_feature_prefix = base_prefix + \"testWord2vec\"\n! ls -alh ./stage1/output/word2vec","execution_count":2},{"metadata":{"id":"00019D0B86C54FAC8E9CCDEF35F7E344","collapsed":false,"scrolled":false,"mdEditEnable":false},"cell_type":"markdown","source":"### 生成word2vec句子相似度"},{"metadata":{"id":"E81C29274AFD4D838D3D2455266D6A3C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"regen_word2vec_sen_vec_sim = True\nword2vec_model_file = \"./stage1/input/word2vec.kv\"\ntfidf_model_file = \"./stage1/output/vector_space/online_tfidf_model.bin\"\nprocess_word2vec_sen_vec_mode = \"tfidf\"\nfrom scipy.spatial.distance import braycurtis, canberra, chebyshev, cityblock, correlation, cosine, euclidean, sqeuclidean\nsimilar_dis = [\n    braycurtis, \n    canberra, chebyshev, \n    cityblock, \n    cosine, euclidean, \n    sqeuclidean\n]\n# similar_radio = [\n#     fuzz.ratio,\n#     fuzz.partial_ratio,\n#     fuzz.token_sort_ratio\n# ]\nsimilar_arr = similar_dis\n","execution_count":3},{"metadata":{"id":"915F69140D7941E0840DF9223D9589C0","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# print(similar_arr)","execution_count":28},{"metadata":{"id":"8DDC1915D9AF4A0692DDC47880088AC9","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"if regen_word2vec_sen_vec_sim:\n    word2vec_model = KeyedVectors.load(word2vec_model_file, mmap='r')\n    with open(tfidf_model_file, \"rb\") as ff:\n        tfidf_model = pickle.load(ff)\n    tfidf_vocab = tfidf_model.vocabulary_","execution_count":4},{"metadata":{"id":"95D36E84AC9C4D368F7B6EE63164E892","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def getTfidfWeights1(raw_docs):\n    global tfidf_model, tfidf_vocab\n    with Timer(\"get tfidf weights\"):\n        X = tfidf_model.transform(raw_documents=raw_docs)\n        print(X)\n    #     for i, doc in enumerate(raw_docs):\n            \n    # res = [{_: X[i][tfidf_vocab[_]] for _ in doc.split() if _ in tfidf_vocab} for i, doc in enumerate(raw_docs)]\n    # del X\n    # gc.collect()\n    # return res","execution_count":38},{"metadata":{"id":"AF3F441F1D8141EE830506A64CB70AD0","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'get tfidf weights' block...\n  (0, 2881256)\t0.2312325554483072\n  (0, 2695414)\t0.44227262437367776\n  (0, 2695257)\t0.6890901406254859\n  (0, 2692668)\t0.43173484618363295\n  (0, 798245)\t0.29947659627090745\n----->Finished 'get tfidf weights' block, time used:0.7s.\n","name":"stdout"}],"source":"raw_docs = [\"20 20 21 123\"]\ntmp = getTfidfWeights1(raw_docs)","execution_count":40},{"metadata":{"id":"CDECCF235D094B0182DED24769FAF3F0","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def sent2vec(text):\n    # 计算embedding均值\n    global word2vec_model\n    return np.nan_to_num(\n          np.array([word2vec_model[w] for w in text.split() if w in word2vec_model] or [0.0] * 200\n          ).mean(axis=0)\n      )","execution_count":30},{"metadata":{"id":"FB4240B323894073890672D1EC879EAB","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def sent2vec1(text, weights):\r\n    # 计算embedding带权均值\r\n    global word2vec_model\r\n    return np.nan_to_num(\r\n          np.array([[_*weights[w] for _ in word2vec_model[w] if w in weights] or [0.0] * 200 for w in text.split() if w in word2vec_model] \r\n          or [0.0] * 200\r\n          ).mean(axis=0)\r\n      )","execution_count":31},{"metadata":{"id":"FEF992DC1226417590B0BA329DC801B1","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def process_word2vec_sen_vec(df, prefix, savefile):\n    # print(df.shape, df[:2])\n    with Timer(\"cal sent vec\"):\n        global process_word2vec_sen_vec_mode\n        if process_word2vec_sen_vec_mode == \"avg\":\n            q_sen_vec = list(map(sent2vec, df[\"query\"]))\n            t_sen_vec = list(map(sent2vec, df[\"title\"]))\n        elif process_word2vec_sen_vec_mode == \"tfidf\":\n            with Timer(\"cal weights\"):\n                q_sen_weights = getTfidfWeights(df[\"query\"])\n                t_sen_weights = getTfidfWeights(df[\"title\"])\n            q_sen_vec = list(map(sent2vec1, df[\"query\"], q_sen_weights))\n            t_sen_vec = list(map(sent2vec1, df[\"title\"], t_sen_weights))\n        # savefile += \"{}.npz\".format(process_word2vec_sen_vec_mode)\n        # np.savez(savefile, q_sent_vec, t_sent_vec)\n        # print(\"Sent vec saved to {}\".format(savefile))\n        for _ in similar_arr:\n            name = _.__name__\n            with Timer(\"cal {} sim\".format(name)):\n                df[\"{}_{}\".format(prefix, name)] = cal_sim(q_sen_vec, t_sen_vec, _)\n    return df","execution_count":32},{"metadata":{"id":"EAA93E0DDE01465C837D79A893136B06","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 提取训练数据特征\nif regen_word2vec_sen_vec_sim:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \n        \"senVec{}Sim\".format(process_word2vec_sen_vec_mode), \n        process_func=process_word2vec_sen_vec, names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, \n        process_chunkly=True, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], \n        drop_last_cols=['query', 'title'])\n# Finished 'extract senVecavgSim feature' block, time used:4160.86s.","execution_count":24},{"metadata":{"id":"357E526329B64A29B946DE1E987F3288","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"./stage1/output/word2vec/debug_trainWork2vec_senVecavgSim.csv.gz\")","execution_count":17},{"metadata":{"id":"6890A59F0214492BAFFF2076BA665237","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"./stage1/input/test.csv\")","execution_count":27},{"metadata":{"id":"ADCABA33318B4733833905C11E2B196E","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 提取训练数据特征\nif regen_word2vec_sen_vec_sim and not OFFLINE:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, \n        \"senVec{}Sim\".format(process_word2vec_sen_vec_mode), \n        process_func=process_word2vec_sen_vec, names=ORI_TEST_NAMES, dtype=ORI_TEST_DTYPE, \n        process_chunkly=True, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id'], \n        drop_last_cols=['query', 'title'])","execution_count":36},{"metadata":{"id":"152557B408BF4CEEA6C5FE653C6CD8D6","mdEditEnable":false},"cell_type":"markdown","source":"### Magic特征"},{"metadata":{"id":"4C2E0149E5FE465EBCB250DEAD7FB466","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"total 8.0G\r\ndrwxr-xr-x 2 kesci root  4.0K Jun 22 10:24 .\r\ndrwxr-xr-x 7 kesci root  4.0K Jun 19 09:08 ..\r\n-rw-r--r-- 1 kesci users 5.8K Jun 22 01:22 debug_trainMagic_ctrRateGlobal.csv.gz\r\n-rw-r--r-- 1 kesci users 122K Jun 22 01:23 debug_trainMagic_ctrRateLocal.csv.gz\r\n-rw-r--r-- 1 kesci users 5.4M Jun 22 05:25 debug_trainMagic_diffSetSim.csv.gz\r\n-rw-r--r-- 1 kesci users  62K Jun 20 12:49 debug_trainMagic_queryFreq.csv.gz\r\n-rw-r--r-- 1 kesci users  95K Jun 21 13:59 online_testMagic_ctrRateGlobal.csv.gz\r\n-rw-r--r-- 1 kesci users 1.2M Jun 21 14:09 online_testMagic_ctrRateLocal.csv.gz\r\n-rw-r--r-- 1 kesci users 931M Jun 22 09:34 online_testMagic_diffSetSimBigramsTitle.npy\r\n-rw-r--r-- 1 kesci users 201M Jun 22 10:29 online_testMagic_diffSetSim.csv.gz\r\n-rw-r--r-- 1 kesci users 1.2G Jun 22 10:01 online_testMagic_diffSetSimTrigramsTitle.npy\r\n-rw-r--r-- 1 kesci users 505M Jun 22 09:13 online_testMagic_diffSetSimUnigramsTitle.npy\r\n-rw-r--r-- 1 kesci users 602K Jun 21 13:27 online_testMagic_queryFreq.csv.gz\r\n-rw-r--r-- 1 kesci users 190K Jun 21 13:59 online_trainMagic_ctrRateGlobal.csv.gz\r\n-rw-r--r-- 1 kesci users 2.4M Jun 21 14:06 online_trainMagic_ctrRateLocal.csv.gz\r\n-rw-r--r-- 1 kesci users 1.8G Jun 22 07:20 online_trainMagic_diffSetSimBigramsTitle.npy\r\n-rw-r--r-- 1 kesci users 393M Jun 22 09:04 online_trainMagic_diffSetSim.csv.gz\r\n-rw-r--r-- 1 kesci users 2.3G Jun 22 08:12 online_trainMagic_diffSetSimTrigramsTitle.npy\r\n-rw-r--r-- 1 kesci users 929M Jun 22 06:42 online_trainMagic_diffSetSimUnigramsTitle.npy\r\n-rw-r--r-- 1 kesci users 1.2M Jun 21 12:36 online_trainMagic_queryFreq.csv.gz\r\n","name":"stdout"}],"source":"feature_save_dir = base_feature_save_dir + \"magic/\"\ntrain_feature_prefix = base_prefix + \"trainMagic\"\ntest_feature_prefix = base_prefix + \"testMagic\"\n! ls -alh ./stage1/output/magic/","execution_count":6},{"metadata":{"id":"415BAFF0C7C146A587DB4BA7DD677742","mdEditEnable":false},"cell_type":"markdown","source":"#### 提取query频率"},{"metadata":{"id":"82F529A01DFF4B1483991308775A9972","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"regen_query_freq = False\ntrain_query_freq = train_feature_prefix + \"_queryFreq\"\ntrain_freq_save_file = feature_save_dir+train_query_freq+\".csv.gz\"\nif not OFFLINE:\n    test_query_freq = test_feature_prefix + \"_queryFreq\"\n    test_freq_save_file = feature_save_dir+test_query_freq+\".csv.gz\"","execution_count":3},{"metadata":{"id":"52FD73F8CA96480F8289B30CE1207864","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def ExtractFreq(sourcefile, savefile, names, dtype, group_by, sort_col, feature_name):\n    df = ReadCSV(sourcefile, names=names, dtype=dtype, iterator=False)\n    grouped = df.groupby(group_by, as_index=False)[sort_col].count()\n    res = np.concatenate(list(map(lambda x: [x]*x, grouped[sort_col])))\n    # print(grouped[:3])\n    # print(res[:10])\n    tmp = pd.DataFrame({\n        feature_name: res\n    })\n    tmp.to_csv(savefile, compression=\"gzip\", index=None)\n    print(\"Feature saved to {}\".format(savefile))\n    del df, grouped, res, tmp\n    gc.collect()","execution_count":4},{"metadata":{"id":"3DC627A6B95E47B8AF09E6D22B442777","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"if regen_query_freq:\n    ExtractFreq(train_file, \n        train_freq_save_file, \n        ORI_TRAIN_NAMES, \n        ORI_TRAIN_DTYPE,\n        \"query_id\",\n        \"query_title_id\",\n        \"query_freq\")","execution_count":5},{"metadata":{"id":"B64F181229BD4E02B1D613A1F334D5E6","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"if regen_query_freq and not OFFLINE:\n    ExtractFreq(test_file, \n        test_freq_save_file, \n        ORI_TEST_NAMES, \n        ORI_TEST_DTYPE,\n        \"query_id\",\n        \"query_title_id\",\n        \"query_freq\")","execution_count":6},{"metadata":{"id":"7B0012A7D9154E67B7490EE4F2A87D40","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"./stage1/output/magic/debug_trainMagic_titleFreq.csv.gz\")","execution_count":24},{"metadata":{"id":"050487282F37427AA2167D5F2E9A50A4","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"./stage1/output/magic/debug_trainMagic_queryFreq.csv.gz\")","execution_count":25},{"metadata":{"id":"BFF2D03C630F454E8DD727509F512A40","collapsed":false,"scrolled":false,"mdEditEnable":false},"cell_type":"markdown","source":"#### 提取差集特征"},{"metadata":{"id":"07FF17550E1741328E64E5A1D1CB3523","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"from fuzzywuzzy import fuzz\r\nsimilar_arr = [\r\n    dist_utils.dice_ratio,\r\n    # dist_utils.jaccard_ratio,\r\n    dist_utils.edit_seq_ratio,\r\n    dist_utils.edit_set_ratio,\r\n    fuzz.ratio,\r\n    fuzz.partial_ratio,\r\n    fuzz.token_sort_ratio\r\n]\r\nregen_diff_sim = True","execution_count":3},{"metadata":{"id":"6EDBC7C64C1344E881BC1E5083EAD3D1","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def findDiff(arr, ngram):\n    set_list = list(map(lambda x: set(ngram(x)), arr))\n    res = []\n    for i, _ in enumerate(set_list):\n        result = _\n        for __ in set_list:\n            if _ != __:\n                result = result.difference(__)\n        res.append(list(result))\n    return res","execution_count":4},{"metadata":{"id":"005E57B7CEE743A5B02245F3E625C429","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def GetDiffSet(query_id, title, ngram):\r\n    tmp, res = [], []\r\n    for i in range(len(query_id)):\r\n      if i == 0:\r\n        tmp.append(title[i])\r\n      else:\r\n        if query_id[i] == query_id[i-1]:\r\n          tmp.append(title[i])\r\n        else:\r\n          res.append(findDiff(tmp, ngram))\r\n          tmp = [title[i]]\r\n    res.append(findDiff(tmp, ngram))\r\n    result = []\r\n    for _ in res:\r\n        result.extend(_)\r\n    return result","execution_count":5},{"metadata":{"id":"82F34AF6CED54AD1816859258246BA3C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def run_diff_set_sim(df, ngram, prefix, savefile, sign):\n    with Timer(\"cal diff set\"):\n        t_list = GetDiffSet(df[\"query_id\"], df[\"title\"], ngram)\n        q_list = df['query'].apply(ngram)\n        # 存储处理后的title列表\n        t_savefile = savefile + sign +\"Title.npy\"\n        np.save(t_savefile, t_list)\n        print(\"File saved to {}\".format(t_savefile))\n    ## 长度特征\n    with Timer(\"extract similarity\"):\n        for _ in similar_arr:\n            name = _.__name__\n            with Timer(\"cal {} sim\".format(name)):\n                df[\"{}_diffSetSim{}\".format(prefix, name)] = cal_sim(q_list, t_list, _)\n    del q_list, t_list\n    gc.collect()\n    return df\n\ndef process_diff_set_sim(df, prefix, savefile):\n    df = run_diff_set_sim(df, ngram_utils.unigrams, '%s_%s' % (prefix, 'unigrams'), savefile, \"Unigrams\")\n    df = run_diff_set_sim(df, ngram_utils.bigrams, '%s_%s' % (prefix, 'bigrams'), savefile, \"Bigrams\")\n    df = run_diff_set_sim(df, ngram_utils.trigrams, '%s_%s' % (prefix, 'trigrams'), savefile, \"Trigrams\")\n    return df","execution_count":6},{"metadata":{"id":"53D8E51301584D7C8F33FA721597ED12","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract diffSetSim feature' block...\nMem. usage decreased to 190.73 Mb (0.0% reduction)\n----->Started 'cal diff set' block...\nFile saved to ./stage1/output/magic/online_trainMagic_diffSetSimUnigramsTitle.npy\n----->Finished 'cal diff set' block, time used:1102.2s.\n----->Started 'extract similarity' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:23.49s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:44.68s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:57.86s.\n----->Started 'cal ratio sim' block...\n----->Finished 'cal ratio sim' block, time used:95.7s.\n----->Started 'cal partial_ratio sim' block...\n----->Finished 'cal partial_ratio sim' block, time used:496.68s.\n----->Started 'cal token_sort_ratio sim' block...\n----->Finished 'cal token_sort_ratio sim' block, time used:339.07s.\n----->Finished 'extract similarity' block, time used:1057.49s.\n----->Started 'cal diff set' block...\nFile saved to ./stage1/output/magic/online_trainMagic_diffSetSimBigramsTitle.npy\n----->Finished 'cal diff set' block, time used:1216.35s.\n----->Started 'extract similarity' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:25.82s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:78.08s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:89.46s.\n----->Started 'cal ratio sim' block...\n----->Finished 'cal ratio sim' block, time used:158.48s.\n----->Started 'cal partial_ratio sim' block...\n----->Finished 'cal partial_ratio sim' block, time used:1098.28s.\n----->Started 'cal token_sort_ratio sim' block...\n----->Finished 'cal token_sort_ratio sim' block, time used:455.53s.\n----->Finished 'extract similarity' block, time used:1905.64s.\n----->Started 'cal diff set' block...\nFile saved to ./stage1/output/magic/online_trainMagic_diffSetSimTrigramsTitle.npy\n----->Finished 'cal diff set' block, time used:1223.3s.\n----->Started 'extract similarity' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:24.8s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:95.94s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:108.61s.\n----->Started 'cal ratio sim' block...\n----->Finished 'cal ratio sim' block, time used:179.13s.\n----->Started 'cal partial_ratio sim' block...\n----->Finished 'cal partial_ratio sim' block, time used:1508.36s.\n----->Started 'cal token_sort_ratio sim' block...\n----->Finished 'cal token_sort_ratio sim' block, time used:493.01s.\n----->Finished 'extract similarity' block, time used:2409.86s.\nsaved diffSetSim feature to ./stage1/output/magic/online_trainMagic_diffSetSim.csv.gz\n----->Finished 'extract diffSetSim feature' block, time used:9622.45s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_diff_sim:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"diffSetSim\", \n        process_func=process_diff_set_sim, \n        names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['label', 'query_title_id'], drop_last_cols=['query_id', 'query', 'title'])","execution_count":7},{"metadata":{"id":"2B57FC160E49429FAD6B6CE4F758F2FE","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"(500000,) [list(['1017', '663', '87', '59', '18225', '37136', '3567', '33'])\n list(['14514', '9669', '4126', '15457', '799', '12875', '147', '660'])]\n","name":"stdout"}],"source":"# tmp = np.load(\"./stage1/output/magic/debug_trainMagic_diffSetSimUnigrams.npy\", allow_pickle=True)\n# print(tmp.shape, tmp[:2])","execution_count":19},{"metadata":{"id":"48D4E8F0D36E46CB80E37A8E29D6E2E5","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(train_file, print_rows=12)","execution_count":24},{"metadata":{"id":"48F23D753316423383948D9982C42BAC","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"./stage1/output/magic/debug_trainMagic_diffSetSim1.csv.gz\")","execution_count":80},{"metadata":{"id":"9FEE73DAEDD24A51A5691A873471A577","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract diffSetSim feature' block...\nMem. usage decreased to 95.37 Mb (0.0% reduction)\n----->Started 'cal diff set' block...\nFile saved to ./stage1/output/magic/online_testMagic_diffSetSimUnigramsTitle.npy\n----->Finished 'cal diff set' block, time used:546.98s.\n----->Started 'extract similarity' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:11.75s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:22.84s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:29.95s.\n----->Started 'cal ratio sim' block...\n----->Finished 'cal ratio sim' block, time used:53.76s.\n----->Started 'cal partial_ratio sim' block...\n----->Finished 'cal partial_ratio sim' block, time used:274.85s.\n----->Started 'cal token_sort_ratio sim' block...\n----->Finished 'cal token_sort_ratio sim' block, time used:176.2s.\n----->Finished 'extract similarity' block, time used:569.35s.\n----->Started 'cal diff set' block...\nFile saved to ./stage1/output/magic/online_testMagic_diffSetSimBigramsTitle.npy\n----->Finished 'cal diff set' block, time used:672.59s.\n----->Started 'extract similarity' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:13.06s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:40.97s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:60.38s.\n----->Started 'cal ratio sim' block...\n----->Finished 'cal ratio sim' block, time used:86.17s.\n----->Started 'cal partial_ratio sim' block...\n----->Finished 'cal partial_ratio sim' block, time used:603.36s.\n----->Started 'cal token_sort_ratio sim' block...\n----->Finished 'cal token_sort_ratio sim' block, time used:229.52s.\n----->Finished 'extract similarity' block, time used:1033.47s.\n----->Started 'cal diff set' block...\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_diff_sim:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, \"diffSetSim\", \n        process_func=process_diff_set_sim, \n        names=ORI_TEST_NAMES, dtype=ORI_TEST_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_title_id'], drop_last_cols=['query_id', 'query', 'title'])","execution_count":null},{"metadata":{"id":"B7F20AA36FE8477B8AE679790125C329","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"./stage1/output/magic/online_trainMagic_diffSetSim.csv.gz\")","execution_count":1},{"metadata":{"id":"2570D7A6D15A40A4BDC5AA14272C062F","mdEditEnable":false},"cell_type":"markdown","source":"#### 点击率特征"},{"metadata":{"id":"11F0EF4C03A04CA982BE108D9CB0B36B","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"regen_ctr_rate = True\nstat = {}","execution_count":37},{"metadata":{"id":"4C8A242C8C5544A69D769E24E1EF4053","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def ExtractGlobalCTR(df, prefix, savefile):\n    # 全局点击率\n    tmp = df[\"label\"].value_counts()\n    global_click_rate = tmp[1] / (tmp[0] + tmp[1])\n    feature_name = \"{}_globalCTR\".format(prefix)\n    df[feature_name] = [global_click_rate] * df.shape[0]\n    if not OFFLINE:\n        prefix = prefix.replace(\"train\", \"test\")\n        feature_name = feature_name.replace(\"train\", \"test\")\n        savefile = savefile.replace(\"train\", \"test\")+\".csv.gz\"\n        test_df = pd.DataFrame({\n            feature_name: [global_click_rate] * 5000000\n        }).to_csv(savefile, index=None, compression=\"gzip\")\n        print(\"Feature saved to {}\".format(savefile))\n        del test_df\n    del tmp\n    gc.collect()\n    return df","execution_count":42},{"metadata":{"id":"704B808FBD8C445289C5CD1F99330E40","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract ctrRateGlobal feature' block...\nMem. usage decreased to  2.38 Mb (68.7% reduction)\nsaved ctrRateGlobal feature to ./stage1/output/magic/debug_trainMagic_ctrRateGlobal.csv.gz\n----->Finished 'extract ctrRateGlobal feature' block, time used:4.79s.\n","name":"stdout"}],"source":"if regen_ctr_rate:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"ctrRateGlobal\", \n    ExtractGlobalCTR, names=ORI_TRAIN_NAMES,\n    dtype=None, process_chunkly=False, \n    drop_first_cols=['query_title_id', 'query', 'title'], drop_last_cols=['query_id', 'label'])","execution_count":43},{"metadata":{"id":"39BF45B506314BF9A8D04616B20D221A","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def ExtractLocalCTR(df, prefix, savefile):\n    global stat\n    grouped = df.groupby(\"query_id\", as_index=False)\n    count = grouped.size().values\n    if not stat:\n        label = grouped[\"label\"].sum()[\"label\"].values.astype(\"int32\")\n        for _ in range(len(count)):\n            item_len = count[_]\n            if item_len not in stat:\n                stat[item_len] = [1, label[_]]\n            else:\n                stat[item_len][0] += 1\n                stat[item_len][1] += label[_]\n        del label\n        print(stat)\n    res = [[ stat[_][1] / (_ * stat[_][0])]*_ for _ in count]\n    result = []\n    for _ in res:\n        result.extend(_)\n    df[\"{}_localCTR\".format(prefix)] = result\n    del res, grouped\n    gc.collect()\n    return df","execution_count":45},{"metadata":{"id":"33E353FEFC7D4577A377992D5FE489C5","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract ctrRateLocal feature' block...\nMem. usage decreased to  2.38 Mb (68.7% reduction)\n{11: [1834, 4011], 17: [658, 1727], 13: [1236, 2857], 3: [33728, 44915], 20: [4540, 12425], 4: [5026, 7386], 5: [4753, 7609], 7: [4878, 8538], 6: [4425, 7450], 8: [4544, 8524], 9: [2336, 4671], 12: [1523, 3377], 14: [1023, 2473], 19: [517, 1450], 16: [795, 2057], 15: [886, 2202], 10: [1983, 4125], 18: [577, 1578]}\nsaved ctrRateLocal feature to ./stage1/output/magic/debug_trainMagic_ctrRateLocal.csv.gz\n----->Finished 'extract ctrRateLocal feature' block, time used:5.63s.\n","name":"stdout"}],"source":"if regen_ctr_rate:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"ctrRateLocal\", \n    ExtractLocalCTR, names=ORI_TRAIN_NAMES,\n    dtype=None, process_chunkly=False, \n    drop_first_cols=['query_title_id', 'query', 'title'], drop_last_cols=['query_id', 'label'])","execution_count":46},{"metadata":{"id":"6360746B670045F4BB764785F47B713C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"if not OFFLINE and regen_ctr_rate:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, \"ctrRateLocal\", \n    ExtractLocalCRT, names=ORI_TEST_NAMES,\n    dtype=None, process_chunkly=False, \n    drop_first_cols=['query_title_id', 'query', 'title'], drop_last_cols=['query_id'])","execution_count":47}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}