{"cells":[{"cell_type":"markdown","metadata":{"id":"99AFB710F338484CA769DD4FB7A71F47","mdEditEnable":false},"source":"# Baseline\n\n本文档是使用tfIdf+lr并随机采样1000万条数据建立的Baseline模型。"},{"metadata":{"id":"5B370DC99A644BA09097241959E5904B","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"total 26837936\ndrwxr-xr-x 6 kesci root        4096 Jun  5 11:33 .\ndrwxrwxrwx 8 root  root        4096 Jun  5 11:29 ..\n-rw-r--r-- 1 kesci users 1143995991 Jun  2 16:03 fastText_classify.bin\n-rw-r--r-- 1 kesci users 9027388177 Jun  2 12:56 labeled_content\ndrwx------ 2 root  root       16384 May 26 04:29 lost+found\ndrwxr-xr-x 2 kesci users       4096 Jun  1 12:52 __pycache__\n-rw-r--r-- 1 root  root          38 May 26 04:30 .sidecarDownloadOnce\ndrwxr-xr-x 2 kesci users       4096 Jun  2 07:41 stats\ndrwxr-xr-x 2 kesci users       4096 Jun  5 11:33 submits\n-rw-r--r-- 1 kesci users  455810675 May 28 13:36 test_processed.csv\n-rw-r--r-- 1 kesci users 8126569615 Jun  2 13:12 train.txt\n-rw-r--r-- 1 kesci users 7827388177 Jun  4 15:31 unlabeled_content\n-rw-r--r-- 1 kesci root        2425 Jun  1 12:51 utils.py\n-rw-r--r-- 1 kesci users  900818562 Jun  2 13:12 valid.txt\nmkdir: cannot create directory ‘submits’: File exists\nmv: cannot stat 'kesci_submit': No such file or directory\n","name":"stdout"}],"source":"! ls -al\n! mkdir submits\n! mv kesci_submit submits/","execution_count":6},{"cell_type":"markdown","metadata":{"id":"75107ABF60474734B3218B323547CD10"},"source":"## 导入各种库"},{"cell_type":"code","execution_count":2,"metadata":{"id":"CD9FC0A1BD9E4080891FD56100DF1857","collapsed":false,"scrolled":false},"outputs":[],"source":"import pandas as pd\nimport numpy as np\nimport time\nimport random\nimport gc\nimport sys"},{"cell_type":"code","execution_count":3,"metadata":{"id":"DB23999D160C42F6A1015D571E3FF8C9","collapsed":false,"scrolled":false},"outputs":[],"source":"# 是否为线下调试\ndebug = False"},{"cell_type":"code","execution_count":4,"metadata":{"id":"97BE5B1479D84DE5AF29FD1846854E48","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"total 9.0G\r\n-rw-r--r-- 1 kesci 1000 426M May 22 04:05 test.csv\r\n-rw-r--r-- 1 kesci 1000 8.6G May 16 20:15 train.csv\r\n","name":"stdout"}],"source":"# 数据集参数\nif debug:\n    !ls -lh ../data\n    data_dir = \"../data/\"\n    train_data_file = data_dir + \"train_data.csv\"\nelse:\n    !ls -lh /home/kesci/input/bytedance/first-round/\n    data_dir = \"/home/kesci/input/bytedance/first-round/\"\n    train_data_file = data_dir + \"train.csv\"\n    test_data_file = data_dir + \"test.csv\"\n# csv的header\nori_train_names = [\"query_id\", \"query\", \"query_title_id\", \"title\", \"label\"]\nori_test_names = [\"query_id\", \"query\", \"query_title_id\", \"title\"]\ntrain_names = [\"feature\", \"label\"]\ntest_names = [\"query_id\", \"query_title_id\", \"feature\"]\nsubmit_names = [\"query_id\", \"query_title_id\", \"label\"]"},{"cell_type":"markdown","metadata":{"id":"F1E34647AB364B6892085DAE44C415F4"},"source":"## 辅助函数"},{"cell_type":"code","execution_count":5,"metadata":{"id":"D1272445B33D4F9D910FB6C7C1C52816","collapsed":false,"scrolled":false},"outputs":[],"source":"# 计算执行某个函数需要的时间\nclass Timer(object):\n    \"\"\"\n    Record the consumed time when ran a code block.\n    \"\"\"\n    def __init__(self, block_name, prefix=\"----->\"):\n        self.block_name = block_name\n        self.prefix = prefix\n\n    def __enter__(self):\n        print(self.prefix+\"Started '\"+self.block_name+\"' block...\")\n        self.time_start = time.time()\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        elapsed_time = round(time.time() - self.time_start, 2)\n        print(self.prefix+\"Finished '\"+self.block_name+\"' block, time used:\", str(elapsed_time)+\"s.\")"},{"cell_type":"code","execution_count":6,"metadata":{"id":"33A2EB76A8064AAB8457B362B4681B3F","collapsed":false,"scrolled":false},"outputs":[],"source":"# 读取CSV文件\ndef ReadCSV(filename, names, sep=\",\", iterator=True):\n    # http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html#pandas.read_csv\n    return pd.read_csv(\n        filename, \n        names=names,\n        sep=sep,\n        iterator=iterator\n    )"},{"cell_type":"code","execution_count":11,"metadata":{"id":"3AAEC94835BD44B6A76056D05E9BB5DB","collapsed":false,"scrolled":false},"outputs":[],"source":"# 批量读入数据，并apply处理函数\ndef ProcessChunk(filename, func, names, chunk_size=5000000):\n    reader = ReadCSV(filename, names)\n    while True:\n        try:\n            print(\"Reading chunk...\")\n            func(reader.get_chunk(chunk_size))\n        except StopIteration:\n            print(\"Finished process.\")\n            return\n# def handle(x):\n#     print(x)\n#     print()\n# ProcessChunk(train_data_file, handle, names=ori_train_names, chunk_size=5)"},{"cell_type":"code","execution_count":12,"metadata":{"id":"C1F5D0B58E1640538F27FC38BD86047E","collapsed":false,"scrolled":false},"outputs":[],"source":"# 蓄水池读文件, 本方法巨慢无比!\ndef ReservoirSample(filename, count, names=ori_train_names):\n    print(\"Reservoir sample...\")\n    reader = ReadCSV(filename, names)\n    try:\n        # 对于前面count个元素完全选择\n        res = reader.get_chunk(count)\n    except StopIteration:\n        print(\"Count exceeds the file size.\")\n        return res\n    i = count\n    while True:\n        try:\n            i += 1\n            # https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.randint.html\n            tmp = random.randint(1, i+1)\n            datapoint = reader.get_chunk(1).iloc[0]\n            if tmp <= count:\n                res.iloc[tmp - 1] = datapoint\n        except StopIteration:\n            print(\"Finished sample.\")\n            return res\n# tmp = ReservoirSample(train_data_file, 5)\n# print(tmp)"},{"cell_type":"code","execution_count":13,"metadata":{"id":"AED08A2AE24C4ABE81DBAC593EB9F9F0","collapsed":false,"scrolled":false},"outputs":[],"source":"# 按照rate比例从每个chunk中随机采样样本\ndef RandomSample(filename, rate, chunk_size=1000000, random_state=None, names=ori_train_names):\n    print(\"Random sample...\")\n    reader = ReadCSV(filename, names)\n    chunks = []\n    while True:\n        try:\n            # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html\n            chunks.append(reader.get_chunk(chunk_size).sample(\n                n=int(chunk_size*rate), \n                random_state=random_state)\n            )\n        except StopIteration:\n            print(\"Finished sample.\")\n            break\n    # 删除无用引用, https://blog.csdn.net/jiangjiang_jian/article/details/79140742\n    # for x in locals().keys():\n    #     if x != \"res\":\n    #         # 会被放入内存池？\n    #         del locals()[x]\n    # gc.collect()\n    return pd.concat(chunks, ignore_index=True)\n# tmp = RandomSample(train_data_file, .5, chunk_size=5)\n# print(tmp)"},{"cell_type":"code","execution_count":14,"metadata":{"id":"868FDCDAC95545979D65AA36EECC79D4","collapsed":false,"scrolled":false},"outputs":[],"source":"# 重新组合特征\ndef ProcessFeatures(filename, train=True, names=ori_train_names, datadir=data_dir):\n    reader = ReadCSV(filename, names)\n    f = lambda x: x[1] + \" s \" + x[3]\n    count, chunk_size = 1, 10000000\n    print(\"Start processing...\")\n    chunks = []\n    while True:\n        try:\n            chunks.append(reader.get_chunk(chunk_size))\n        except StopIteration:\n            print(\"Finished process.\")\n            break\n    df = pd.concat(chunks, ignore_index=True)\n    if train:\n        fname = \"train_processed.csv\"\n        pd.DataFrame({\n            \"feature\": df.apply(f, axis=1), \n            \"label\": df.label}).to_csv(\n            fname, header=None, index=None)\n    else:\n        fname = \"test_processed.csv\"\n        pd.DataFrame({\n            \"query_id\":df.iloc[:, 0],\n            \"query_title_id\": df.iloc[:, 2],\n            \"feature\": df.apply(f, axis=1)\n        }).to_csv(\n            fname, header=None, index=None)\n    \n    del df\n    gc.collect()\n    \n    print(\"Saved to the file.\")\n\n# with Timer(\"Process feature\"):\n#     ProcessFeatures(train_data_file)\n#     # 线上处理test数据时候需要调用\n#     if not debug:\n#         ProcessFeatures(test_data_file, train=False, names=ori_test_names)"},{"cell_type":"markdown","metadata":{"id":"92D969AB64594C188BBFEA40CE7E93E2"},"source":"## 数据预处理"},{"cell_type":"code","execution_count":15,"metadata":{"id":"B84852DACBE14E9A86C81EA3B881BA6A","collapsed":false,"scrolled":false},"outputs":[],"source":"def pr(o):\n    print(o[:5])\n    sys.exit(0)"},{"cell_type":"code","execution_count":8,"metadata":{"id":"3FB10C4D61C6455B953DC11E91611D6F","collapsed":false,"scrolled":false},"outputs":[],"source":"train_file = \"train_processed.csv\"\ntest_file = \"test_processed.csv\""},{"cell_type":"code","execution_count":17,"metadata":{"id":"E417A3A22C3A493DA6023886F7244893","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"Reading chunk...\n                                             feature  label\n0  1427 5661 29788 1427 387 2299 372 22 1586 1025...      1\n1  1427 5661 29788 1427 387 2299 372 22 1586 1025...      0\n2  1427 5661 29788 1427 387 2299 372 22 1586 1025...      1\n3  1427 5661 29788 1427 361 22 1374 279 1196 27 7...      0\n4  1427 5661 29788 1427 361 22 1374 279 1196 27 7...      1\n","name":"stdout"},{"output_type":"error","ename":"SystemExit","evalue":"0","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"]},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n","name":"stderr"}],"source":"# 看一下训练数据对不对\nProcessChunk(train_file, pr, names=train_names, chunk_size=500)"},{"cell_type":"code","execution_count":18,"metadata":{"id":"073B21086A874771890FEA8FC7B2E509","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"Reading chunk...\n   query_id  query_title_id                                            feature\n0         1               3  11202 184 50256 s 11202 184 2346 2527 274 383 ...\n1         1               1  11202 184 50256 s 11202 184 21479 808 383 34 1...\n2         1               4  11202 184 50256 s 11202 184 21479 15 227 383 3...\n3         1               2  11202 184 50256 s 11202 184 274 383 34 1033 15...\n4         2               1  1013 6811 14038 1156 s 361 628 1020 513 126 15...\n","name":"stdout"},{"output_type":"error","ename":"SystemExit","evalue":"0","traceback":["An exception has occurred, use %tb to see the full traceback.\n","\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"]}],"source":"# 看一下测试数据对不对\nif not debug:\n    ProcessChunk(test_file, pr, names=test_names, chunk_size=500)"},{"cell_type":"code","execution_count":19,"metadata":{"id":"CECFE7B083484DD9977BD82C0F2075AE","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"Random sample...\nFinished sample.\n","name":"stdout"}],"source":"# 随机采样1000万数据\nwith Timer(\"Random sample\"):\n    if debug:\n        chunk_size = 1000\n    else:\n        chunk_size = 5000000\n    train_random_data = RandomSample(train_file, .1, names=train_names, chunk_size=chunk_size)\n    train_data_num = len(train_random_data)"},{"cell_type":"code","execution_count":10,"metadata":{"id":"12253DB906C649B991B80306EAA8FDA2","collapsed":false,"scrolled":false},"outputs":[],"source":"# 全部采样所有的测试数据集\nif not debug:\n    test_data = ReadCSV(test_file, names=test_names, iterator=False)\n    test_data_num = len(test_data)"},{"cell_type":"markdown","metadata":{"id":"72B917E3E356496B886B9FF6F8CDD8D4","mdEditEnable":false},"source":"## 模型"},{"cell_type":"code","execution_count":22,"metadata":{"id":"DE032C070CD6439E856DD082D7CA7B44","collapsed":false,"scrolled":false},"outputs":[],"source":"from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.linear_model import SGDClassifier\n# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\nfrom sklearn.naive_bayes import GaussianNB"},{"cell_type":"code","execution_count":23,"metadata":{"id":"05F2EDA12E894DB49E34C60DDDA7DE01","collapsed":false,"scrolled":false},"outputs":[],"source":"def tokenizer(text):\n    return text.split(\" \")"},{"cell_type":"code","execution_count":24,"metadata":{"id":"C4C0B43E0DFB4B17A1476D4D7733D45A","collapsed":false,"scrolled":false},"outputs":[],"source":"tfidf_model = TfidfVectorizer(\n    tokenizer=tokenizer, \n    analyzer=\"word\",\n    ngram_range=(1,1))"},{"cell_type":"code","execution_count":25,"metadata":{"id":"C0DE7F38532D4A9D99804124CAE53879","collapsed":false,"scrolled":false},"outputs":[],"source":"def getTfidf(docs, train=True):\n    model = tfidf_model\n    if train:\n        X = model.fit_transform(docs)\n    else:\n        X = model.transform(docs)\n    return X"},{"cell_type":"code","execution_count":26,"metadata":{"id":"824A02B4EDAD4EEB9C1D0C6F66E1F70B","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"----->Started 'Process tfidf' block...\n----->Finished 'Process tfidf' block, time used: 294.24s.\n","name":"stdout"}],"source":"with Timer(\"Process tfidf\"):\n    if debug:\n        X = getTfidf(train_random_data.feature)\n    else:\n        X = getTfidf(pd.concat(\n                    [train_random_data.feature, \n                    test_data.feature], ignore_index=True))\n# 获得训练集的labels\ntrain_labels = train_random_data.label.to_list()"},{"cell_type":"code","execution_count":27,"metadata":{"id":"B1768058EE4E409D92755B5E5647A281","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"  (0, 68333)\t0.6124487441553906\n  (0, 587607)\t0.39283261251154483\n  (0, 201393)\t0.34001356533545896\n  (0, 751798)\t0.023164603119026277\n  (0, 58011)\t0.1267661282622556\n  (0, 348180)\t0.18883673981744695\n  (0, 148526)\t0.13439756192819877\n  (0, 25349)\t0.060688019472363484\n  (0, 154437)\t0.157491915288034\n  (0, 90847)\t0.22868015706451533\n  (0, 169005)\t0.15909368115083394\n  (0, 176935)\t0.16504170475470367\n  (0, 672644)\t0.2116534036060197\n  (0, 745365)\t0.32637938105251185\n[0, 0, 1, 1, 0]\n","name":"stdout"}],"source":"print(X[0])\nprint(train_labels[:5])"},{"cell_type":"code","execution_count":31,"metadata":{"id":"CEA202564168469EADB252272E2A5B03","collapsed":false,"scrolled":false},"outputs":[],"source":"def lrTrain(train=True, savefile=\"submit.csv\"):\n    \n    global X\n    \n    if train:\n        times = 1\n    else:\n        times = 1\n    for i in range(times):\n        \n        print(\"Prepare features...\")\n        train_features = X[:train_data_num]\n        test_features = X[train_data_num:]\n        \n        if train:\n            split_train = int(train_data_num*0.7)\n            train_X, test_X = train_features[:split_train], train_features[split_train:]\n            train_y, test_y = train_labels[:split_train], train_labels[split_train:]\n        else:\n            train_X, test_X = train_features, test_features\n            train_y = train_labels\n            \n        model = LogisticRegression(C=1, solver=\"liblinear\")\n        print(\"Fitting model...\")\n        pred = model.fit(train_X, train_y).predict_proba(test_X)[:, 1]\n        \n        if train:\n            fpr, tpr, thresholds = metrics.roc_curve(test_y, pred, pos_label=1)\n            res = metrics.auc(fpr, tpr)\n            print(\"AUC:\", res)\n        else:\n            res = []\n            for i in range(test_data_num):\n                tmp = test_data.iloc[i]\n                res.append([tmp[0], tmp[1], pred[i]])\n            print(res[:10])\n            pd.DataFrame(np.array(res)).to_csv(savefile, index=False, header=None)\n            \n    for x in locals().keys():\n        del locals()[x]\n    gc.collect()"},{"cell_type":"code","execution_count":35,"metadata":{"id":"808E527F8D3F492F8F92A26BB30445DF","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"----->Started 'lr train' block...\nPrepare features...\nFitting model...\n[[1, 3, 0.2428209424290729], [1, 1, 0.24676146383766], [1, 4, 0.2325881796989098], [1, 2, 0.23973552429059442], [2, 1, 0.3223512759810728], [2, 2, 0.3023735898439416], [2, 3, 0.35346710014962174], [3, 6, 0.05916494239325773], [3, 5, 0.10308273138490058], [3, 8, 0.11302303084530227]]\n----->Finished 'lr train' block, time used: 2421.55s.\n","name":"stdout"}],"source":"# 执行训练阶段\nwith Timer(\"lr train\"):\n    lrTrain(False, \"submit1.csv\")"},{"cell_type":"markdown","metadata":{"id":"805571559CFE49F582EFF70FFF4C984E","mdEditEnable":false},"source":"## 提交结果"},{"metadata":{"id":"DA7D644A945C4E04A829EE789526AD1C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"total 16839588\r\ndrwxr-xr-x 3 kesci root        4096 May 29 09:14 .\r\ndrwxrwxrwx 8 root  root        4096 May 29 08:34 ..\r\n-rwxr-xr-x 1 kesci users    7842088 May 25 15:15 kesci_submit\r\ndrwx------ 2 root  root       16384 May 26 04:29 lost+found\r\n-rw-r--r-- 1 root  root          38 May 26 04:30 .sidecarDownloadOnce\r\n-rw-r--r-- 1 kesci users  162605370 May 29 09:14 submit1.csv\r\n-rw-r--r-- 1 kesci users  162604756 May 28 17:25 submit.csv\r\n-rw-r--r-- 1 kesci users  455810675 May 28 13:36 test_processed.csv\r\n-rw-r--r-- 1 kesci users  820818562 May 28 09:32 train_10.csv\r\n-rw-r--r-- 1 kesci users  819693364 May 28 08:38 train_1.csv\r\n-rw-r--r-- 1 kesci users  817448885 May 28 08:44 train_2.csv\r\n-rw-r--r-- 1 kesci users  824399775 May 28 08:50 train_3.csv\r\n-rw-r--r-- 1 kesci users  827260894 May 28 08:56 train_4.csv\r\n-rw-r--r-- 1 kesci users  826309777 May 28 09:02 train_5.csv\r\n-rw-r--r-- 1 kesci users  825891483 May 28 09:08 train_6.csv\r\n-rw-r--r-- 1 kesci users  824105834 May 28 09:14 train_7.csv\r\n-rw-r--r-- 1 kesci users  821288738 May 28 09:20 train_8.csv\r\n-rw-r--r-- 1 kesci users  820170865 May 28 09:26 train_9.csv\r\n-rw-r--r-- 1 kesci users 8227388177 May 28 10:56 train_processed.csv\r\n","name":"stdout"}],"source":"!ls -al","execution_count":36},{"metadata":{"id":"98838920E7324167AD26355BDE4222E2","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"res1 = pd.DataFrame({\n    \"query_id\": test_data[\"query_id\"],\n    \"query_title_id\": test_data[\"query_title_id\"],\n    \"label\": 0.5\n})\nres1.to_csv(\"submit_baseline_0.5.csv\", header=None, index=None)","execution_count":22},{"metadata":{"id":"B0BAB76C457343A099EC020EBB1F09FC","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"   query_id  query_title_id  label\n0         1               3    0.5\n1         1               1    0.5\n2         1               4    0.5\n3         1               2    0.5\n4         2               1    0.5\n","name":"stdout"}],"source":"submit_baseline_1 = ReadCSV(\"submit_baseline_0.5.csv\", names=submit_names, iterator=False)\nprint(submit_baseline_1[:5])","execution_count":23},{"cell_type":"code","execution_count":24,"metadata":{"id":"DAE287ECE66B49C89A1736A473EA87A4","collapsed":false,"scrolled":false},"outputs":[{"output_type":"stream","text":"Kesci Submit Tool\nResult File: submit_baseline_0.5.csv (61.91 MiB)\nUploaded.       \n====================\nSubmit Success.\n{\"Stage\":0,\"Status\":0,\"ShownInHistory\":true,\"IsAucResult\":true,\"Selected\":false,\"_id\":\"5cf1218ef649f6002b61e431\",\"Competition\":\"5cc51043f71088002c5b8840\",\"Team\":\"5cda7d99b4de58002b94c3f8\",\"UploadDate\":\"2019-05-31T12:43:58.536Z\",\"Final\":true,\"Response\":\"\",\"SubmissionResults\":[],\"IP\":\"52.83.252.251\",\"FingerPrint\":\"\",\"UserAgent\":\"Go-http-client/1.1\",\"ResultFileName\":\"1559306632859435da4.csv\",\"ResultFileRealName\":\"submit_baseline_0.5.csv\",\"ResultFileSize\":0,\"ReviewInfos\":[],\"__v\":0}\n\n","name":"stdout"}],"source":"# 第一次执行需要\n# !wget -nv -O kesci_submit https://www.heywhale.com/kesci_submit&&chmod +x kesci_submit\n!./kesci_submit -token 490475a1ae106f67 -file submit_baseline_0.5.csv"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}