{"cells":[{"metadata":{"id":"CD15BE576B4C4D128B3AA9EB9A9A8C76","mdEditEnable":false},"cell_type":"markdown","source":"# 特征提取"},{"metadata":{"id":"40F26B9530E44CC49103F8FD48BE1CBA","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"False\n","name":"stdout"}],"source":"import sys, os, gc\nimport numpy as np\nimport pandas as pd\nimport pickle\nsys.path.append(\"./global\")\nfrom helper import ReadCSV, Timer, ExtractFeature, ORI_TRAIN_NAMES, ORI_TRAIN_DTYPE, ORI_TEST_NAMES, ORI_TEST_DTYPE, AnalysisCSV, OFFLINE, cal_sim\nimport dist_utils, ngram_utils\nbase_feature_save_dir = \"./stage1/output/\"\ntest_file = \"./stage1/input/test.csv\"\nif OFFLINE:\n    base_prefix = \"debug_\"\n    train_file = \"./stage1/input/train_last_50w.csv\"\n    CHUNK_SIZE = 100000\nelse:\n    base_prefix = \"online_\"\n    train_file = \"./stage1/input/train_last_1000w.csv\"\n    CHUNK_SIZE = 1000000\nprint(OFFLINE)","execution_count":1},{"metadata":{"id":"761C585EC2274901AB7E188FED28CA82","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Requirement already satisfied: networkx in /opt/conda/lib/python3.6/site-packages\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.6/site-packages (from networkx)\n","name":"stdout"}],"source":"# ! pip install  --index \"http://pypi/simple\" --trusted-host pypi fuzzywuzzy\n# ! pip install  --index \"http://pypi/simple\" --trusted-host pypi  pyemd\n# ! pip install  --index \"http://pypi/simple\" --trusted-host pypi simhash\n! pip install  --index \"http://pypi/simple\" --trusted-host pypi networkx","execution_count":12},{"metadata":{"id":"3C6CEED2F1574088BFB7BD0B3AFA68C0","mdEditEnable":false},"cell_type":"markdown","source":"## 文本挖掘特征"},{"metadata":{"id":"C1B9B465F2234AD68651BF514CC7D8E6","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"total 1.9G\r\ndrwxr-xr-x 2 kesci root  4.0K Jun 29 13:47 .\r\ndrwxr-xr-x 7 kesci root  4.0K Jun 19 09:08 ..\r\n-rw-r--r-- 1 kesci users 8.6M Jun 26 13:27 debug_trainTextMining_editSim.csv.gz\r\n-rw-r--r-- 1 kesci users 4.6M Jun 26 13:24 debug_trainTextMining_len.csv.gz\r\n-rw-r--r-- 1 kesci users 2.7M Jun 26 13:24 debug_trainTextMining_lenRel.csv.gz\r\n-rw-r--r-- 1 kesci users  21M Jun 24 12:15 debug_trainTextMining_ngramCharSim.csv.gz\r\n-rw-r--r-- 1 kesci users  34M Jun 25 14:00 debug_trainTextMining_ngramSim.csv.gz\r\n-rw-r--r-- 1 kesci users  20M Jun 26 13:30 debug_trainTextMining_ngramSimV1.csv.gz\r\n-rw-r--r-- 1 kesci users 2.4M Jun 29 13:24 debug_trainTextMining_ngramSubSeq.csv.gz\r\n-rw-r--r-- 1 kesci users 6.6M Jun 29 13:47 debug_trainTextMining_ngramSubSeqV1.csv.gz\r\n-rw-r--r-- 1 kesci users  86M Jun 25 17:42 online_testTextMining_editSim.csv.gz\r\n-rw-r--r-- 1 kesci users  47M Jun 20 13:22 online_testTextMining_len.csv.gz\r\n-rw-r--r-- 1 kesci users  27M Jun 25 16:09 online_testTextMining_lenRel.csv.gz\r\n-rw-r--r-- 1 kesci users 262M Jun 20 16:46 online_testTextMining_ngramSim.csv.gz\r\n-rw-r--r-- 1 kesci users 197M Jun 26 09:13 online_testTextMining_ngramSimV1.csv.gz\r\n-rw-r--r-- 1 kesci users 171M Jun 25 17:26 online_trainTextMining_editSim.csv.gz\r\n-rw-r--r-- 1 kesci users  92M Jun 20 13:19 online_trainTextMining_len.csv.gz\r\n-rw-r--r-- 1 kesci users  53M Jun 25 16:06 online_trainTextMining_lenRel.csv.gz\r\n-rw-r--r-- 1 kesci users 515M Jun 20 15:35 online_trainTextMining_ngramSim.csv.gz\r\n-rw-r--r-- 1 kesci users 385M Jun 26 08:14 online_trainTextMining_ngramSimV1.csv.gz\r\n","name":"stdout"}],"source":"from fuzzywuzzy import fuzz\nfeature_save_dir = base_feature_save_dir + \"text_mining_feature/\"\ntrain_feature_prefix = base_prefix + \"trainTextMining\"\ntest_feature_prefix = base_prefix + \"testTextMining\"\n! ls -alh ./stage1/output/text_mining_feature/","execution_count":13},{"metadata":{"id":"EBE478C8B05D40B680CBD2AB3E3CAFF1","mdEditEnable":false},"cell_type":"markdown","source":"### 提取长度特征"},{"metadata":{"id":"E7F6EF4CF5FB44CC850D8E2DA410704C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"regen_len_feature = False","execution_count":11},{"metadata":{"id":"60DD46D6363B47688636727332B06FBA","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def run_text_len(df, ngram, prefix):\n    # ngram\n    if ngram:\n        q_list = df['query'].apply(ngram)\n        t_list = df['title'].apply(ngram)\n    else:\n        q_list = df['query']\n        t_list = df['title']\n    ## 长度特征\n    with Timer(\"extract length\"):\n        df['%s_q-len' % prefix] = np.vectorize(len)(q_list)\n        df['%s_t-len' % prefix] = np.vectorize(len)(t_list)\n        df['%s_qt-len-radio'%prefix] = list(map(lambda a, b: a/b, \n            df['%s_q-len' % prefix], \n            df['%s_t-len' % prefix]))\n        df['%s_tq-len-radio'%prefix] = list(map(lambda a, b: b/a, \n            df['%s_q-len' % prefix], \n            df['%s_t-len' % prefix]))\n    del q_list, t_list\n    gc.collect()\n    return df\ndef process_text_len(df, prefix, savefile):\n    df = run_text_len(df, None, '%s_%s' % (prefix, 'text'))\n    df = run_text_len(df, ngram_utils.unigrams, '%s_%s' % (prefix, 'unigrams'))\n    return df","execution_count":12},{"metadata":{"id":"CBD06EEC5BBD4004B33CE283911513CF","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 提取训练数据特征\nif regen_len_feature:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"len\", process_func=process_text_len, \n        names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], drop_last_cols=['query', 'title'])","execution_count":13},{"metadata":{"id":"B490167AEC954DE19717808444B13724","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"./stage1/output/text_mining_feature/debug_trainTextMining_len.csv.gz\")","execution_count":7},{"metadata":{"id":"5CEF3CB2AEB44E038AD28D5EBC235D88","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"if not OFFLINE and regen_len_feature:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, \"len\", process_func=process_text_len, \n    names=ORI_TEST_NAMES, dtype=ORI_TEST_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n    drop_first_cols=['query_id', 'query_title_id'], drop_last_cols=['query', 'title'])","execution_count":6},{"metadata":{"id":"AE102779A0EE42E8A4128D44605553E5","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"time: 989 µs\n","name":"stdout"}],"source":"# AnalysisCSV(\"./stage1/output/text_mining_feature/debug_train_text_mining_feature_len.csv\")","execution_count":11},{"metadata":{"id":"62013FB257CA40309FEF59356E6D72F3","mdEditEnable":false},"cell_type":"markdown","source":"### 提取更多长度特征"},{"metadata":{"id":"A66F6665DDEF452992AA4EEFA376A080","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"regen_len_rel_feature = False","execution_count":7},{"metadata":{"id":"CBD7C43AAA6042D58C85A462CF32A9ED","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def run_text_len_rel(df, ngram, prefix):\n    # ngram\n    q_list = df['query'].apply(ngram)\n    t_list = df['title'].apply(ngram)\n    ## 长度特征\n    with Timer(\"extract length rel\"):\n        q_len = np.vectorize(len)(q_list)\n        t_len = np.vectorize(len)(t_list)\n        del q_list, t_list\n        gc.collect()\n        df['%s_qt-diff'%prefix] = list(map(lambda a, b: abs(a-b), q_len, t_len))\n        df['%s_qt-max'%prefix] = list(map(lambda a, b: max(a, b), q_len, t_len))\n        df['%s_qt-min'%prefix] = list(map(lambda a, b: min(a, b), q_len, t_len))\n        df['%s_qt-avg'%prefix] = list(map(lambda a, b: (a+b)/2, q_len, t_len))\n        del q_len, t_len\n        gc.collect()\n    return df\ndef process_text_len_rel(df, prefix, savefile):\n    df = run_text_len_rel(df, ngram_utils.unichars, '%s_%s' % (prefix, 'unichars'))\n    df = run_text_len_rel(df, ngram_utils.unigrams, '%s_%s' % (prefix, 'unigrams'))\n    return df","execution_count":8},{"metadata":{"id":"D738FC0D99CD49AB9F65A2BF8FDF3F9E","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract lenRel feature' block...\nMem. usage decreased to  7.63 Mb (0.0% reduction)\n----->Started 'extract length rel' block...\n----->Finished 'extract length rel' block, time used:3.31s.\n----->Started 'extract length rel' block...\n----->Finished 'extract length rel' block, time used:3.9s.\nsaved lenRel feature to ./stage1/output/text_mining_feature/debug_trainTextMining_lenRel.csv.gz\n----->Finished 'extract lenRel feature' block, time used:27.86s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_len_rel_feature:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"lenRel\", \n        process_func=process_text_len_rel, \n        names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], drop_last_cols=['query', 'title'])","execution_count":9},{"metadata":{"id":"8F7EF7AABEF547F2800619733A6E741C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"./stage1/output/text_mining_feature/debug_trainTextMining_lenRel.csv.gz\")","execution_count":15},{"metadata":{"id":"9074E817875942D1A8CA600F6DBCEBAB","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract lenRel feature' block...\nMem. usage decreased to 76.29 Mb (0.0% reduction)\n----->Started 'extract length rel' block...\n----->Finished 'extract length rel' block, time used:19.74s.\n----->Started 'extract length rel' block...\n----->Finished 'extract length rel' block, time used:19.97s.\nsaved lenRel feature to ./stage1/output/text_mining_feature/online_testTextMining_lenRel.csv.gz\n----->Finished 'extract lenRel feature' block, time used:180.14s.\n","name":"stdout"}],"source":"if not OFFLINE and regen_len_rel_feature:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, \"lenRel\", \n    process_func=process_text_len_rel, \n    names=ORI_TEST_NAMES, dtype=ORI_TEST_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n    drop_first_cols=['query_id', 'query_title_id'], drop_last_cols=['query', 'title'])","execution_count":13},{"metadata":{"id":"2B76B2EE7B7C45258B815B1BB4F0C1C5","mdEditEnable":false},"cell_type":"markdown","source":"### 提取编辑距离特征"},{"metadata":{"id":"E68A493A8B244468942CF4859F548D1E","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"regen_edit_sim_feature = False\nimport Levenshtein","execution_count":10},{"metadata":{"id":"66D053F91FB442728158DCA5C25ABE62","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"similar_arr = [\n    # 编辑距离，https://www.jb51.net/article/98449.htm;\n    # http://www.coli.uni-saarland.de/courses/LT1/2011/slides/Python-Levenshtein.html#Levenshtein-inverse\n    Levenshtein.distance,\n    Levenshtein.jaro,\n    Levenshtein.jaro_winkler,\n    # Levenshtein.ratio\n    # https://blog.csdn.net/qq_43174128/article/details/82595317\n    fuzz.ratio,\n    fuzz.partial_ratio,\n    fuzz.token_sort_ratio,\n    fuzz.partial_token_sort_ratio,\n    fuzz.token_set_ratio\n]","execution_count":11},{"metadata":{"id":"6FDAF1DCC57F4B958F5DB383FC836159","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def run_edit_sim_feature(df, prefix):\n    q_list = df['query']\n    t_list = df['title']\n    ## 长度特征\n    with Timer(\"extract edit sim\"):\n        for _ in similar_arr:\n            name = _.__name__\n            with Timer(\"cal {} sim\".format(name)):\n                df[\"{}_{}\".format(prefix, name)] = cal_sim(q_list, t_list, _)\n    del q_list, t_list\n    gc.collect()\n    return df\n\ndef process_edit_sim_feature(df, prefix, savefile):\n    df = run_edit_sim_feature(df, '%s_%s' % (prefix, 'text'))\n    return df","execution_count":12},{"metadata":{"id":"E20960C2CED0432089F1FE9D935EAB72","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract editSim feature' block...\nMem. usage decreased to  7.63 Mb (0.0% reduction)\n----->Started 'extract edit sim' block...\n----->Started 'cal distance sim' block...\n----->Finished 'cal distance sim' block, time used:2.55s.\n----->Started 'cal jaro sim' block...\n----->Finished 'cal jaro sim' block, time used:1.1s.\n----->Started 'cal jaro_winkler sim' block...\n----->Finished 'cal jaro_winkler sim' block, time used:1.26s.\n----->Started 'cal ratio sim' block...\n----->Finished 'cal ratio sim' block, time used:5.63s.\n----->Started 'cal partial_ratio sim' block...\n----->Finished 'cal partial_ratio sim' block, time used:27.78s.\n----->Started 'cal token_sort_ratio sim' block...\n----->Finished 'cal token_sort_ratio sim' block, time used:22.18s.\n----->Started 'cal partial_token_sort_ratio sim' block...\n----->Finished 'cal partial_token_sort_ratio sim' block, time used:49.13s.\n----->Started 'cal token_set_ratio sim' block...\n----->Finished 'cal token_set_ratio sim' block, time used:30.61s.\n----->Finished 'extract edit sim' block, time used:140.25s.\nsaved editSim feature to ./stage1/output/text_mining_feature/debug_trainTextMining_editSim.csv.gz\n----->Finished 'extract editSim feature' block, time used:158.45s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_edit_sim_feature:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"editSim\", \n        process_func=process_edit_sim_feature, \n        names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], drop_last_cols=['query', 'title'])","execution_count":13},{"metadata":{"id":"1314AD4E4E794EDB9BC13AA8140CD441","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract editSim feature' block...\nMem. usage decreased to 76.29 Mb (0.0% reduction)\n----->Started 'extract edit sim' block...\n----->Started 'cal distance sim' block...\n----->Finished 'cal distance sim' block, time used:18.15s.\n----->Started 'cal jaro sim' block...\n----->Finished 'cal jaro sim' block, time used:6.74s.\n----->Started 'cal jaro_winkler sim' block...\n----->Finished 'cal jaro_winkler sim' block, time used:7.09s.\n----->Started 'cal ratio sim' block...\n----->Finished 'cal ratio sim' block, time used:34.9s.\n----->Started 'cal partial_ratio sim' block...\n----->Finished 'cal partial_ratio sim' block, time used:175.09s.\n----->Started 'cal token_sort_ratio sim' block...\n----->Finished 'cal token_sort_ratio sim' block, time used:140.28s.\n----->Started 'cal partial_token_sort_ratio sim' block...\n----->Finished 'cal partial_token_sort_ratio sim' block, time used:288.69s.\n----->Started 'cal token_set_ratio sim' block...\n----->Finished 'cal token_set_ratio sim' block, time used:201.85s.\n----->Finished 'extract edit sim' block, time used:872.8s.\nsaved editSim feature to ./stage1/output/text_mining_feature/online_testTextMining_editSim.csv.gz\n----->Finished 'extract editSim feature' block, time used:998.44s.\n","name":"stdout"}],"source":"if not OFFLINE and regen_edit_sim_feature:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, \"editSim\", \n    process_func=process_edit_sim_feature, \n    names=ORI_TEST_NAMES, dtype=ORI_TEST_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n    drop_first_cols=['query_id', 'query_title_id'], drop_last_cols=['query', 'title'])","execution_count":34},{"metadata":{"id":"7DDCC4D135FF46D086F1D9D77D7C29F3","mdEditEnable":false},"cell_type":"markdown","source":"### 提取集合相似度特征"},{"metadata":{"id":"A9F24C2040384D4BBE2B355D542EA06F","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"regen_ngram_sim_feature = False\nimport Levenshtein","execution_count":14},{"metadata":{"id":"C8534A0F74A54363AE989AD3FBED6EC9","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"similar_arr = [\n    # 集合的交集关系\n    # 可以操作字符串，如\"abc\"；也可以操作字符数组，如['a', 'b', 'c']\n    dist_utils.dice_ratio,\n    dist_utils.jaccard_ratio,\n    # 编辑距离，https://www.jb51.net/article/98449.htm;\n    # http://www.coli.uni-saarland.de/courses/LT1/2011/slides/Python-Levenshtein.html#Levenshtein-inverse\n    dist_utils.edit_seq_ratio,\n    dist_utils.edit_set_ratio,\n]","execution_count":15},{"metadata":{"id":"F06C42D8A5B649B2868E541787C39840","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def run_ngram_similarity(df, ngram, prefix):\n    q_list = df['query'].apply(ngram)\n    t_list = df['title'].apply(ngram)\n    ## 长度特征\n    with Timer(\"extract ngram sim\"):\n        for _ in similar_arr:\n            name = _.__name__\n            with Timer(\"cal {} sim\".format(name)):\n                df[\"{}_{}\".format(prefix, name)] = cal_sim(q_list, t_list, _)\n        del q_list, t_list\n        gc.collect()\n    return df\n\ndef process_ngram_similarity(df, prefix, savefile):\n    df = run_ngram_similarity(df, ngram_utils.unichars, '%s_%s' % (prefix, 'unichars'))\n    # df = run_ngram_similarity(df, ngram_utils.bichars, '%s_%s' % (prefix, 'bichars'))\n    # df = run_ngram_similarity(df, ngram_utils.trichars, '%s_%s' % (prefix, 'trichars'))\n    df = run_ngram_similarity(df, ngram_utils.unigrams, '%s_%s' % (prefix, 'unigrams'))\n    df = run_ngram_similarity(df, ngram_utils.bigrams, '%s_%s' % (prefix, 'bigrams'))\n    df = run_ngram_similarity(df, ngram_utils.trigrams, '%s_%s' % (prefix, 'trigrams'))\n    return df","execution_count":16},{"metadata":{"id":"B042F9B774C24DFD848620F742E833B1","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract ngramSimV1 feature' block...\nMem. usage decreased to  7.63 Mb (0.0% reduction)\n----->Started 'extract ngram sim' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:2.3s.\n----->Started 'cal jaccard_ratio sim' block...\n----->Finished 'cal jaccard_ratio sim' block, time used:2.46s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:9.89s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:13.76s.\n----->Finished 'extract ngram sim' block, time used:28.78s.\n----->Started 'extract ngram sim' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:2.29s.\n----->Started 'cal jaccard_ratio sim' block...\n----->Finished 'cal jaccard_ratio sim' block, time used:2.0s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:5.44s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:6.39s.\n----->Finished 'extract ngram sim' block, time used:16.76s.\n----->Started 'extract ngram sim' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:2.34s.\n----->Started 'cal jaccard_ratio sim' block...\n----->Finished 'cal jaccard_ratio sim' block, time used:2.27s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:6.36s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:7.53s.\n----->Finished 'extract ngram sim' block, time used:19.13s.\n----->Started 'extract ngram sim' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:2.37s.\n----->Started 'cal jaccard_ratio sim' block...\n----->Finished 'cal jaccard_ratio sim' block, time used:2.02s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:8.7s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:8.51s.\n----->Finished 'extract ngram sim' block, time used:22.37s.\nsaved ngramSimV1 feature to ./stage1/output/text_mining_feature/debug_trainTextMining_ngramSimV1.csv.gz\n----->Finished 'extract ngramSimV1 feature' block, time used:169.09s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_ngram_sim_feature:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"ngramSimV1\", \n        process_func=process_ngram_similarity, \n        names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], drop_last_cols=['query', 'title'])","execution_count":17},{"metadata":{"id":"FBBBDAAE926D49038C9C5E824014F74C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"./stage1/output/text_mining_feature/debug_trainTextMining_ngramSim.csv.gz\")","execution_count":41},{"metadata":{"id":"F6447FEAEFAC431C89BEB6ECDD6208BF","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract ngramSimChars feature' block...\nMem. usage decreased to 76.29 Mb (0.0% reduction)\n----->Started 'extract ngram sim' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:15.78s.\n----->Started 'cal jaccard_ratio sim' block...\n----->Finished 'cal jaccard_ratio sim' block, time used:15.62s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:59.22s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:85.41s.\n----->Finished 'extract ngram sim' block, time used:178.06s.\n----->Started 'extract ngram sim' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:15.53s.\n----->Started 'cal jaccard_ratio sim' block...\n----->Finished 'cal jaccard_ratio sim' block, time used:12.36s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:33.62s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:42.01s.\n----->Finished 'extract ngram sim' block, time used:109.19s.\n----->Started 'extract ngram sim' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:15.51s.\n----->Started 'cal jaccard_ratio sim' block...\n----->Finished 'cal jaccard_ratio sim' block, time used:12.38s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:42.95s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:49.41s.\n----->Finished 'extract ngram sim' block, time used:128.33s.\n----->Started 'extract ngram sim' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:14.85s.\n----->Started 'cal jaccard_ratio sim' block...\n----->Finished 'cal jaccard_ratio sim' block, time used:11.74s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:54.06s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:58.11s.\n----->Finished 'extract ngram sim' block, time used:151.78s.\nsaved ngramSimChars feature to ./stage1/output/text_mining_feature/online_testTextMining_ngramSimChars.csv.gz\n----->Finished 'extract ngramSimChars feature' block, time used:1141.3s.\n","name":"stdout"}],"source":"if not OFFLINE and regen_ngram_sim_feature:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, \"ngramSimV1\", \n    process_func=process_ngram_similarity, \n    names=ORI_TEST_NAMES, dtype=ORI_TEST_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n    drop_first_cols=['query_id', 'query_title_id'], drop_last_cols=['query', 'title'])","execution_count":7},{"metadata":{"id":"34FF8ADD40D042E38EAA9C8DC3357D5C","mdEditEnable":false},"cell_type":"markdown","source":"### SimHash"},{"metadata":{"id":"EC370B7E7BD245158D2734F1EC4630EB","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"from simhash import Simhash\n# https://github.com/cjauvin/simhash/blob/master/tests/test_simhash.py\n# https://leons.im/posts/a-python-implementation-of-simhash-algorithm/\nregen_simhash = True\ntfidf_model_file = \"./stage1/output/vector_space/debug_tfidf_model.bin\"","execution_count":12},{"metadata":{"id":"B904E065A5484A0EBC4C2F9A27C9384D","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def process_ngram_simhash(df, prefix, savefile):\n    with Timer(\"cal tfidf vec\"):\n        with open(tfidf_model_file, \"rb\") as ff:\n            tfidf_model = pickle.load(ff)\n        q_vecs = tfidf_model.transform(df['query'])\n        t_vecs = tfidf_model.transform(df['title'])\n        voc = dict((i, w) for w, i in tfidf_model.vocabulary_.items())\n    with Timer(\"cal sim hash\"):\n        q_simhash = [\n            Simhash(\n                zip([voc[j] for j in Di.indices], Di.data)\n            )\n            for Di in q_vecs\n        ]\n        t_simhash = [\n            Simhash(\n                zip([voc[j] for j in Di.indices], Di.data)\n            )\n            for Di in t_vecs\n        ]\n    with Timer(\"cal sim hash sim\"):\n        df[\"{}Simhash\".format(prefix)] = list(map(\n            lambda x,y: x.distance(y), \n            q_simhash, t_simhash))\n        \n    del q_vecs, t_vecs, q_simhash, t_simhash\n    gc.collect()\n    return df\n\n# def process_ngram_simhash(df, prefix, savefile):\n#     # df = run_ngram_simhash(df, ngram_utils.unichars, '%s_%s' % (prefix, 'unichars'))\n#     # df = run_ngram_simhash(df, ngram_utils.bichars, '%s_%s' % (prefix, 'bichars'))\n#     # df = run_ngram_simhash(df, ngram_utils.trichars, '%s_%s' % (prefix, 'trichars'))\n#     df = run_ngram_simhash(df, ngram_utils.unigrams, '%s_%s' % (prefix, 'unigrams'))\n#     df = run_ngram_simhash(df, ngram_utils.bigrams, '%s_%s' % (prefix, 'bigrams'))\n#     # df = run_ngram_simhash(df, ngram_utils.trigrams, '%s_%s' % (prefix, 'trigrams'))\n#     return df","execution_count":13},{"metadata":{"id":"C3DF38230E854BE18E69868A0606675D","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract ngramSimHashV1 feature' block...\nMem. usage decreased to  7.63 Mb (0.0% reduction)\n----->Started 'cal tfidf vec' block...\n----->Finished 'cal tfidf vec' block, time used:27.81s.\n----->Started 'cal sim hash' block...\n----->Finished 'cal sim hash' block, time used:517.59s.\nsaved ngramSimHashV1 feature to ./stage1/output/vector_space/debug_trainVectorSpace_ngramSimHashV1.csv.gz\n----->Finished 'extract ngramSimHashV1 feature' block, time used:549.25s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_simhash:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"ngramSimHashV1\", \n        process_func=process_ngram_simhash, \n        names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], drop_last_cols=['query', 'title'])","execution_count":14},{"metadata":{"id":"C9F0E70E96A2465B8FBCF94E27F530D0","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"--->file shape:\n(500000, 1)\n--->10 rows of file:\n   debug_trainVectorSpaceSimhash\n0                             24\n1                             25\n2                             20\n3                             28\n4                             28\n5                             29\n6                             31\n7                             24\n8                             21\n9                             31\n--->file info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 500000 entries, 0 to 499999\nData columns (total 1 columns):\ndebug_trainVectorSpaceSimhash    500000 non-null int64\ndtypes: int64(1)\nmemory usage: 3.8 MB\nNone\n--->file describe:\n       debug_trainVectorSpaceSimhash\ncount                  500000.000000\nmean                       26.757976\nstd                         5.525289\nmin                         0.000000\n25%                        23.000000\n50%                        27.000000\n75%                        31.000000\nmax                        49.000000\n","name":"stdout"}],"source":"AnalysisCSV(\"./stage1/output/vector_space/debug_trainVectorSpace_ngramSimHashV1.csv.gz\", print_rows=10)","execution_count":16},{"metadata":{"id":"67AD058D138E43BAA3781D9CC9CCC2E2","mdEditEnable":false},"cell_type":"markdown","source":"### 最长公共子串"},{"metadata":{"id":"8271DCC453B24D2EB8F0BF3667D464E7","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"import py_common_subseq\nregen_subseq = True","execution_count":4},{"metadata":{"id":"2B000BEFCADD436AB632AEF50D087C27","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def run_ngram_subseq(df, ngram, prefix):\n    with Timer(\"cal sub seq\"):\n        query = df[\"query\"].apply(ngram)\n        title = df[\"title\"].apply(ngram)\n        df[\"{}SubSeqCount\".format(prefix)] = np.log(np.array(list(map(\n            lambda x, y: py_common_subseq.count_common_subsequences(x, y), \n            query, title))).astype(float))\n        del query, title\n        gc.collect()\n    return df\n\ndef process_ngram_subseq(df, prefix, savefile):\n    df = run_ngram_subseq(df, ngram_utils.unichars, '%s_%s' % (prefix, 'unichars'))\n    df = run_ngram_subseq(df, ngram_utils.bichars, '%s_%s' % (prefix, 'bichars'))\n    df = run_ngram_subseq(df, ngram_utils.trichars, '%s_%s' % (prefix, 'trichars'))\n    # df = run_ngram_subseq(df, ngram_utils.unigrams, '%s_%s' % (prefix, 'unigrams'))\n    # df = run_ngram_subseq(df, ngram_utils.bigrams, '%s_%s' % (prefix, 'bigrams'))\n    # df = run_ngram_subseq(df, ngram_utils.trigrams, '%s_%s' % (prefix, 'trigrams'))\n    return df ","execution_count":5},{"metadata":{"id":"6A0AB78AA49747CC95B2F27A078CF871","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract ngramSubSeq feature' block...\nMem. usage decreased to 152.59 Mb (0.0% reduction)\n----->Started 'cal sub seq' block...\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_subseq:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"ngramSubSeq\", \n        process_func=process_ngram_subseq, \n        names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], drop_last_cols=['query', 'title'])","execution_count":15},{"metadata":{"id":"2F8CE31451C84CDC834888EC8D51EBD7","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"./stage1/output/text_mining_feature/debug_trainTextMining_ngramSubSeqV1.csv.gz\")","execution_count":16},{"metadata":{"id":"29C92F1B1B794E7194CD02D53FC5BFC1","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 提取训练数据特征\nif regen_subseq:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, \"ngramSubSeq\", \n        process_func=process_ngram_subseq, \n        names=ORI_TEST_NAMES, dtype=ORI_TEST_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], drop_last_cols=['query', 'title'])","execution_count":null},{"metadata":{"id":"7636F25B70E3489D841110ED639046FB","mdEditEnable":false},"cell_type":"markdown","source":"### textRank"},{"metadata":{"id":"38F0AE32B7E34A218BD0DFC02A01D34F","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"from gensim.summarization.summarizer import summarize\nregen_textrank = True","execution_count":null},{"metadata":{"id":"19FEB6268CF04A3D89829DFCFEE220A0"},"cell_type":"code","outputs":[],"source":"","execution_count":null},{"metadata":{"id":"15E7A63098994D708D5CD5744E814A33","mdEditEnable":false},"cell_type":"markdown","source":"## 向量空间特征"},{"metadata":{"id":"BBE2052F8A5D48EBAFF63A4DC5CEE6AB","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"./stage1/output/vector_space/online_tfidf_model_ngram4.bin\ntotal 6.8G\ndrwxr-xr-x 2 kesci root  4.0K Jun 30 02:58 .\ndrwxr-xr-x 7 kesci root  4.0K Jun 19 09:08 ..\n-rw-r--r-- 1 kesci users  89M Jun 20 11:43 debug_tfidf_model.bin\n-rw-r--r-- 1 kesci users 1.2M Jun 28 14:44 debug_trainVectorSpace_ngramSimHash.csv.gz\n-rw-r--r-- 1 kesci users 374K Jun 29 02:52 debug_trainVectorSpace_ngramSimHashV1.csv.gz\n-rw-r--r-- 1 kesci users  30M Jun 29 07:22 debug_trainVectorSpace_tfidfVecLenChar.csv.gz\n-rw-r--r-- 1 kesci users  25M Jun 27 14:25 debug_trainVectorSpace_tfidfVecLen.csv.gz\n-rw-r--r-- 1 kesci users  31M Jun 30 02:58 debug_trainVectorSpace_tfidfVecLenMean.csv.gz\n-rw-r--r-- 1 kesci users  18M Jun 28 12:50 debug_trainVectorSpace_tfidfVecLenMore.csv.gz\n-rw-r--r-- 1 kesci users 4.1M Jun 28 12:59 debug_trainVectorSpace_tfidfVecLenMulti.csv.gz\n-rw-r--r-- 1 kesci users  30M Jun 29 06:37 debug_trainVectorSpace_tfidfVecLenV1.csv.gz\n-rw-r--r-- 1 kesci users  31M Jun 30 02:16 debug_trainVectorSpace_tfidfVecLenV2.csv.gz\n-rw-r--r-- 1 kesci users  12M Jun 26 15:18 debug_trainVectorSpace_tfidfVecSim.csv.gz\n-rw-r--r-- 1 kesci users  12M Jun 29 07:15 debug_trainVectorSpace_tfidfVecSimV1.csv.gz\n-rw-r--r-- 1 kesci users 249M Jun 27 14:59 online_testVectorSpace_tfidfVecLen.csv.gz\n-rw-r--r-- 1 kesci users 292M Jun 29 07:38 online_testVectorSpace_tfidfVecLenV1.csv.gz\n-rw-r--r-- 1 kesci users 119M Jun 26 15:52 online_testVectorSpace_tfidfVecSim.csv.gz\n-rw-r--r-- 1 kesci users 119M Jun 29 12:32 online_testVectorSpace_tfidfVecSimV1.csv.gz\n-rw-r--r-- 1 kesci users 7.8K Jun 29 06:49 online_tfidf_model_ngram2_char.bin\n-rw-r--r-- 1 kesci users 1.7G Jun 29 06:15 online_tfidf_model_ngram3.bin\n-rw-r--r-- 1 kesci users  94M Jun 30 01:40 online_tfidf_model_ngram3_nonorm.bin\n-rw-r--r-- 1 kesci users 1.9G Jun 30 02:11 online_tfidf_model_ngram4.bin\n-rw-r--r-- 1 kesci users 496M Jun 27 14:49 online_trainVectorSpace_tfidfVecLen.csv.gz\n-rw-r--r-- 1 kesci users 582M Jun 29 07:11 online_trainVectorSpace_tfidfVecLenV1.csv.gz\n-rw-r--r-- 1 kesci users 608M Jun 30 02:55 online_trainVectorSpace_tfidfVecLenV2.csv.gz\n-rw-r--r-- 1 kesci users 239M Jun 26 15:43 online_trainVectorSpace_tfidfVecSim.csv.gz\n-rw-r--r-- 1 kesci users 240M Jun 29 11:52 online_trainVectorSpace_tfidfVecSimV1.csv.gz\n","name":"stdout"}],"source":"import pickle\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfeature_save_dir = base_feature_save_dir + \"vector_space/\"\ntrain_feature_prefix = base_prefix + \"trainVectorSpace\"\ntest_feature_prefix = base_prefix + \"testVectorSpace\"\ntfidf_model_file = feature_save_dir+\"online_tfidf_model_ngram4.bin\"\nprint(tfidf_model_file)\n! ls -alh ./stage1/output/vector_space/","execution_count":2},{"metadata":{"id":"F2BDB780DD35416980B2CB7772ACCCD3","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"! rm ./stage1/output/vector_space/online_tfidf_model.bin","execution_count":8},{"metadata":{"id":"AD8B31E0B0D24055ABB2462F7C9E0D7A","mdEditEnable":false},"cell_type":"markdown","source":"### 训练tfidf模型"},{"metadata":{"id":"DAE6BBDE89184CC89B739475558CE7AD","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"./stage1/input/train_last_500w.csv\n","name":"stdout"}],"source":"regen_tfidf_model = True\nprint(train_file)","execution_count":3},{"metadata":{"id":"5B1C90A46AE844FA824D86B50A63650C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def train_tfidf(df, prefix, savefile):\n    word_tfidf = TfidfVectorizer(norm=\"l2\",\n                                    strip_accents=\"unicode\",\n                                    analyzer=\"word\",\n                                    ngram_range=(1, 4),\n                                    use_idf=True,\n                                    smooth_idf=True,\n                                    sublinear_tf=True, min_df=5, max_df=0.9)\n    new_query = df[\"query\"].unique()\n    new_title = df[\"title\"].values\n    # print(new_query.shape)\n    # print(new_title.shape)\n    corpus = np.concatenate([new_query, new_title])\n    # print(corpus[:10])\n    # print(corpus[10:])\n    del df\n    gc.collect()\n    with Timer(\"tf-idf fit\"):\n        word_tfidf.fit(corpus)\n        with open(tfidf_model_file, \"wb\") as f:\n            pickle.dump(word_tfidf, f)\n            print(\"Model dumped to {}\".format(tfidf_model_file))\n    return None","execution_count":4},{"metadata":{"id":"481C9684448446EDB76E03D030B50B3C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract tfidf feature' block...\nMem. usage decreased to 76.29 Mb (0.0% reduction)\n----->Started 'tf-idf fit' block...\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_tfidf_model:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"tfidf\", \n        process_func=train_tfidf, names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, \n        process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], \n        drop_last_cols=['query', 'title'])","execution_count":5},{"metadata":{"id":"75C8C3F4EF534B12ADC50BF155A934BE","mdEditEnable":false},"cell_type":"markdown","source":"### tfidf向量相似性"},{"metadata":{"id":"FDBEAC0E2434445CBE2B3784BBFA4F56","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"./stage1/output/vector_space/online_tfidf_model_ngram3.bin\n","name":"stdout"}],"source":"regen_tfidf_vec_sim = True\nprint(tfidf_model_file)","execution_count":14},{"metadata":{"id":"691C30D600E84925BEB68A9F656939A2","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics.pairwise\nfrom sklearn.metrics.pairwise import *\nsimilar_dis = [\n    paired_cosine_distances,\n    paired_euclidean_distances,\n    paired_manhattan_distances\n]","execution_count":15},{"metadata":{"id":"1418FD4036F544B58A4A0532E2EB875C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def process_tfidf_vec_sim(df, prefix, savefile):\n    with Timer(\"cal tfidf vec\"):\n        with open(tfidf_model_file, \"rb\") as ff:\n            tfidf_model = pickle.load(ff)\n        q_vec = tfidf_model.transform(df[\"query\"])\n        t_vec = tfidf_model.transform(df[\"title\"])\n    with Timer(\"cal tfidf sim\"):\n        for _ in similar_dis:\n            name = _.__name__\n            with Timer(\"cal {} sim\".format(name)):\n                df[\"{}_{}\".format(prefix, name)] = _(q_vec, t_vec)\n    return df","execution_count":16},{"metadata":{"id":"33FAACC8B97241C2815D36BD0E3FD903","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract tfidfVecSimV1 feature' block...\nMem. usage decreased to 152.59 Mb (0.0% reduction)\n----->Started 'cal tfidf vec' block...\n----->Finished 'cal tfidf vec' block, time used:956.27s.\n----->Started 'cal tfidf sim' block...\n----->Started 'cal paired_cosine_distances sim' block...\n----->Finished 'cal paired_cosine_distances sim' block, time used:25.42s.\n----->Started 'cal paired_euclidean_distances sim' block...\n----->Finished 'cal paired_euclidean_distances sim' block, time used:20.32s.\n----->Started 'cal paired_manhattan_distances sim' block...\n----->Finished 'cal paired_manhattan_distances sim' block, time used:22.01s.\n----->Finished 'cal tfidf sim' block, time used:67.75s.\nsaved tfidfVecSimV1 feature to ./stage1/output/vector_space/online_trainVectorSpace_tfidfVecSimV1.csv.gz\n----->Finished 'extract tfidfVecSimV1 feature' block, time used:1230.26s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_tfidf_vec_sim:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"tfidfVecSimV1\", \n        process_func=process_tfidf_vec_sim, names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, \n        process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], \n        drop_last_cols=['query', 'title'])","execution_count":17},{"metadata":{"id":"598C519DFDF74048B182E6505C0A7E01","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"./stage1/output/vector_space/debug_trainVectorSpace_tfidfVecSimV1.csv.gz\")","execution_count":18},{"metadata":{"id":"6275F3B4888E4E7C8D265DCC3A2AEC39","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract tfidfVecSimV1 feature' block...\nMem. usage decreased to 76.29 Mb (0.0% reduction)\n----->Started 'cal tfidf vec' block...\n----->Finished 'cal tfidf vec' block, time used:515.43s.\n----->Started 'cal tfidf sim' block...\n----->Started 'cal paired_cosine_distances sim' block...\n----->Finished 'cal paired_cosine_distances sim' block, time used:12.92s.\n----->Started 'cal paired_euclidean_distances sim' block...\n----->Finished 'cal paired_euclidean_distances sim' block, time used:10.5s.\n----->Started 'cal paired_manhattan_distances sim' block...\n----->Finished 'cal paired_manhattan_distances sim' block, time used:11.16s.\n----->Finished 'cal tfidf sim' block, time used:34.58s.\nsaved tfidfVecSimV1 feature to ./stage1/output/vector_space/online_testVectorSpace_tfidfVecSimV1.csv.gz\n----->Finished 'extract tfidfVecSimV1 feature' block, time used:666.02s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif not OFFLINE and regen_tfidf_vec_sim:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, \"tfidfVecSimV1\", \n        process_func=process_tfidf_vec_sim, names=ORI_TEST_NAMES, dtype=ORI_TEST_DTYPE, \n        process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], \n        drop_last_cols=['query', 'title'])","execution_count":19},{"metadata":{"id":"571373829A4B43CFA173AEDB3BCC8EAF","mdEditEnable":false},"cell_type":"markdown","source":"### tfidf长度特征"},{"metadata":{"id":"74796697CD964CE596198B4451A5D8A8","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"./stage1/output/vector_space/online_tfidf_model_ngram4.bin\n","name":"stdout"}],"source":"from np_utils import try_divide\nregen_tfidf_vec_len = True\nimport scipy, numpy\nprint(tfidf_model_file)","execution_count":3},{"metadata":{"id":"31EBDDCAB43D45A28B1F7B7F827F1D28","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def process_tfidf_vec_len(df, prefix, savefile):\n    with Timer(\"cal tfidf vec\"):\n        with open(tfidf_model_file, \"rb\") as ff:\n            tfidf_model = pickle.load(ff)\n        q_vec_len = np.array(tfidf_model.transform(df[\"query\"]).sum(1)).squeeze()\n        t_vec_len = np.array(tfidf_model.transform(df[\"title\"]).sum(1)).squeeze()\n    with Timer(\"cal tfidf len\"):\n        # Len\n        df['%s_QLen' % prefix] = q_vec_len\n        df['%s_TLen' % prefix] = t_vec_len\n        df['%s_QTLenRatio'%prefix] = list(map(lambda a, b: try_divide(a, b), q_vec_len, t_vec_len))\n        df['%s_TQLenRatio'%prefix] = list(map(lambda a, b: try_divide(b, a), q_vec_len, t_vec_len))\n        df['%s_QTDiff'%prefix] = list(map(lambda a, b: abs(a-b), q_vec_len, t_vec_len))\n        df['%s_QTMax'%prefix] = list(map(lambda a, b: max(a, b), q_vec_len, t_vec_len))\n        df['%s_QTMin'%prefix] = list(map(lambda a, b: min(a, b), q_vec_len, t_vec_len))\n        df['%s_QTAvg'%prefix] = list(map(lambda a, b: (a+b)/2, q_vec_len, t_vec_len))\n        df['%s_QTMulti'%prefix] = list(map(lambda a, b: a*b, q_vec_len, t_vec_len))\n        # df['%s_QSquare2'%prefix] = numpy.square(q_vec_len)\n        # df['%s_TSquare2'%prefix] = numpy.square(t_vec_len)\n        # df['%s_QSqrt'%prefix] = numpy.sqrt(q_vec_len)\n        # df['%s_TSqrt'%prefix] = numpy.sqrt(t_vec_len)\n        # df['%s_QLog'%prefix] = numpy.log(q_vec_len)\n        # df['%s_TLog'%prefix] = numpy.log(t_vec_len)\n        # p_corr = scipy.stats.pearsonr(q_vec_len, t_vec_len)[0]\n        # df['%s_PCorr'%prefix] = [p_corr] * len(q_vec_len)\n        del q_vec_len, t_vec_len\n        gc.collect()\n    return df","execution_count":5},{"metadata":{"id":"6669F53B4AFC4B5F84762938D65BFE97","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract tfidfVecLenMean feature' block...\nMem. usage decreased to  7.63 Mb (0.0% reduction)\n----->Started 'cal tfidf vec' block...\n----->Finished 'cal tfidf vec' block, time used:87.16s.\n----->Started 'cal tfidf len' block...\n----->Finished 'cal tfidf len' block, time used:9.81s.\nsaved tfidfVecLenMean feature to ./stage1/output/vector_space/debug_trainVectorSpace_tfidfVecLenMean.csv.gz\n----->Finished 'extract tfidfVecLenMean feature' block, time used:142.81s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_tfidf_vec_len:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"tfidfVecLenMean\", \n        process_func=process_tfidf_vec_len, names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, \n        process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], \n        drop_last_cols=['query', 'title'])","execution_count":5},{"metadata":{"id":"CA7B62FE85CD4A75BBC99F86EE396AF3","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"./stage1/output/vector_space/debug_trainVectorSpace_tfidfVecLenV1.csv.gz\")","execution_count":3},{"metadata":{"id":"6B239555BB7A4AAE9FC1E97081FA1635","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract tfidfVecLenV2 feature' block...\nMem. usage decreased to 76.29 Mb (0.0% reduction)\n----->Started 'cal tfidf vec' block...\n----->Finished 'cal tfidf vec' block, time used:540.42s.\n----->Started 'cal tfidf len' block...\n----->Finished 'cal tfidf len' block, time used:36.82s.\nsaved tfidfVecLenV2 feature to ./stage1/output/vector_space/online_testVectorSpace_tfidfVecLenV2.csv.gz\n----->Finished 'extract tfidfVecLenV2 feature' block, time used:760.42s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif not OFFLINE and regen_tfidf_vec_len:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, \"tfidfVecLenV2\", \n        process_func=process_tfidf_vec_len, names=ORI_TEST_NAMES, dtype=ORI_TEST_DTYPE, \n        process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id'], \n        drop_last_cols=['query', 'title'])","execution_count":6},{"metadata":{"id":"5985318916B1435D8687DE64F698F4E5","mdEditEnable":false},"cell_type":"markdown","source":"## 提取word2vec特征"},{"metadata":{"id":"07E9877B444D484E93CB0BC611F297FE","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"total 2.0G\r\ndrwxr-xr-x 2 kesci root  4.0K Jun 28 12:16 .\r\ndrwxr-xr-x 7 kesci root  4.0K Jun 19 09:08 ..\r\n-rw-r--r-- 1 kesci users  23M Jun 25 14:33 debug_trainWord2vec_senVecavgSim.csv.gz\r\n-rw-r--r-- 1 kesci users  26M Jun 26 13:39 debug_trainWord2vec_senVecavgSimV1.csv.gz\r\n-rw-r--r-- 1 kesci users  12M Jun 23 14:53 debug_trainWord2vec_senVecavgSK.csv.gz\r\n-rw-r--r-- 1 kesci users 8.8M Jun 23 17:46 debug_trainWord2vec_senVecavgWmd.csv.gz\r\n-rw-r--r-- 1 kesci users  23M Jun 25 14:55 debug_trainWord2vec_senVectfidfSim.csv.gz\r\n-rw-r--r-- 1 kesci users  25M Jun 28 12:05 debug_trainWord2vec_senVectfidfSimV1.csv.gz\r\n-rw-r--r-- 1 kesci users  25M Jun 28 12:16 debug_trainWord2vec_senVectfidfSimV1Sum.csv.gz\r\n-rw-r--r-- 1 kesci users 282M Jun 21 12:33 online_testWord2vec_senVecavgSim.csv.gz\r\n-rw-r--r-- 1 kesci users 251M Jun 27 03:59 online_testWord2vec_senVecavgSimV1.csv.gz\r\n-rw-r--r-- 1 kesci users 564M Jun 21 09:21 online_trainWord2vec_senVecavgSim.csv.gz\r\n-rw-r--r-- 1 kesci users 502M Jun 27 03:05 online_trainWord2vec_senVecavgSimV1.csv.gz\r\n-rw-r--r-- 1 kesci users 271M Jun 26 11:10 online_trainWord2vec_senVecavgSK.csv.gz\r\n","name":"stdout"}],"source":"import pickle\nfrom gensim.models import Word2Vec\nfrom gensim.models import KeyedVectors\nfrom gensim.models.callbacks import CallbackAny2Vec\nfrom scipy.stats import skew, kurtosis\nword2vec_model_file = \"./stage1/input/word2vec.kv\"\ntfidf_model_file = \"./stage1/output/vector_space/online_tfidf_model.bin\"\nfeature_save_dir = base_feature_save_dir + \"word2vec/\"\ntrain_feature_prefix = base_prefix + \"trainWord2vec\"\ntest_feature_prefix = base_prefix + \"testWord2vec\"\n! ls -alh ./stage1/output/word2vec","execution_count":9},{"metadata":{"id":"76A3616FFE05428F83B7C636DE6CE552","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def sent2vec1(text):\n    # 计算embedding均值\n    global word2vec_model, tfidf_idf, tfidf_vocab\n    words = text.split()\n    words_num = len(words)\n    return np.nan_to_num(\n          np.array([np.array(word2vec_model[w])*(\n             (1/words_num) * tfidf_idf[tfidf_vocab[w]]\n             ) for w in words \n             if w in word2vec_model and w in tfidf_vocab] or [0.0] * 200\n          ).sum(axis=0)\n      )","execution_count":25},{"metadata":{"id":"CDECCF235D094B0182DED24769FAF3F0","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def sent2vec(text):\n    # 计算embedding均值\n    global word2vec_model\n    return np.nan_to_num(\n          np.array([word2vec_model[w] for w in text.split() if w in word2vec_model] or [0.0] * 200\n          ).mean(axis=0)\n      )","execution_count":5},{"metadata":{"id":"00019D0B86C54FAC8E9CCDEF35F7E344","collapsed":false,"scrolled":false,"mdEditEnable":false},"cell_type":"markdown","source":"### 生成word2vec句子相似度"},{"metadata":{"id":"FE844A39B4D441F588A8C50DA105123E","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"regen_word2vec_sen_vec_sim = True\nprocess_word2vec_sen_vec_mode = \"tfidf\"\n# word2vec to sent: https://www.zhihu.com/question/29978268","execution_count":21},{"metadata":{"id":"E81C29274AFD4D838D3D2455266D6A3C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"similar_dis = [\n    dist_utils.cosine_distance, \n    dist_utils.jaccard_distance,\n    dist_utils.braycurtis_distance,\n    dist_utils.canberra_distance,\n    dist_utils.cityblock_distance,\n    dist_utils.euclidean_distance,\n    dist_utils.minkowski_distance\n]\nsimilar_arr = similar_dis","execution_count":22},{"metadata":{"id":"8DDC1915D9AF4A0692DDC47880088AC9","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"if regen_word2vec_sen_vec_sim:\n    word2vec_model = KeyedVectors.load(word2vec_model_file, mmap='r')","execution_count":16},{"metadata":{"id":"1C8A8131A3B24C538E2C5A29DE4A3873","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"if regen_word2vec_sen_vec_sim and process_word2vec_sen_vec_mode == \"tfidf\":\n    with open(tfidf_model_file, \"rb\") as ff:\n        tfidf_model = pickle.load(ff)\n    tfidf_idf = tfidf_model.idf_\n    tfidf_vocab = tfidf_model.vocabulary_","execution_count":17},{"metadata":{"id":"BC0508752BD04D269C4CCD97878EB71F","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"993383\n[ 5.15864267 13.26993733  8.96762552 14.42570803 16.16030909 12.98225526\n 14.42570803 15.87262701 15.31301123 15.87262701]\n4.024379974189072\n","name":"stdout"}],"source":"print(tfidf_vocab[\"13\"])\nprint(tfidf_idf[:10])\nprint(tfidf_idf[tfidf_vocab[\"13\"]])","execution_count":19},{"metadata":{"id":"FEF992DC1226417590B0BA329DC801B1","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def process_word2vec_sen_vec(df, prefix, savefile):\n    with Timer(\"cal sent vec\"):\n        global process_word2vec_sen_vec_mode\n        if process_word2vec_sen_vec_mode == \"avg\":\n            q_sen_vec = list(map(sent2vec, df[\"query\"]))\n            t_sen_vec = list(map(sent2vec, df[\"title\"]))\n        elif process_word2vec_sen_vec_mode == \"tfidf\":\n            q_sen_vec = list(map(sent2vec1, df[\"query\"]))\n            t_sen_vec = list(map(sent2vec1, df[\"title\"]))\n        # savefile += \"{}.npz\".format(process_word2vec_sen_vec_mode)\n        # np.savez(savefile, q_sent_vec, t_sent_vec)\n        # print(\"Sent vec saved to {}\".format(savefile))\n        for _ in similar_arr:\n            name = _.__name__\n            with Timer(\"cal {} sim\".format(name)):\n                df[\"{}_{}\".format(prefix, name)] = cal_sim(q_sen_vec, t_sen_vec, _)\n        del q_sen_vec, t_sen_vec\n        gc.collect()\n    return df","execution_count":23},{"metadata":{"id":"EAA93E0DDE01465C837D79A893136B06","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract senVectfidfSimV1Sum feature' block...\nMem. usage decreased to  7.63 Mb (0.0% reduction)\n----->Started 'cal sent vec' block...\n----->Started 'cal cosine_distance sim' block...\n----->Finished 'cal cosine_distance sim' block, time used:33.73s.\n----->Started 'cal jaccard_distance sim' block...\n----->Finished 'cal jaccard_distance sim' block, time used:27.93s.\n----->Started 'cal braycurtis_distance sim' block...\n----->Finished 'cal braycurtis_distance sim' block, time used:28.27s.\n----->Started 'cal canberra_distance sim' block...\n----->Finished 'cal canberra_distance sim' block, time used:41.03s.\n----->Started 'cal cityblock_distance sim' block...\n----->Finished 'cal cityblock_distance sim' block, time used:21.92s.\n----->Started 'cal euclidean_distance sim' block...\n----->Finished 'cal euclidean_distance sim' block, time used:26.94s.\n----->Started 'cal minkowski_distance sim' block...\n----->Finished 'cal minkowski_distance sim' block, time used:43.05s.\n----->Finished 'cal sent vec' block, time used:401.21s.\nsaved senVectfidfSimV1Sum feature to ./stage1/output/word2vec/debug_trainWord2vec_senVectfidfSimV1Sum.csv.gz\n----->Finished 'extract senVectfidfSimV1Sum feature' block, time used:418.85s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_word2vec_sen_vec_sim:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \n        \"senVec{}SimV1Sum\".format(process_word2vec_sen_vec_mode), \n        process_func=process_word2vec_sen_vec, names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, \n        process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], \n        drop_last_cols=['query', 'title'])","execution_count":26},{"metadata":{"id":"ADCABA33318B4733833905C11E2B196E","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract senVecavgSimV1 feature' block...\nMem. usage decreased to 76.29 Mb (0.0% reduction)\n----->Started 'cal sent vec' block...\n----->Started 'cal cosine_distance sim' block...\n----->Finished 'cal cosine_distance sim' block, time used:239.94s.\n----->Started 'cal jaccard_distance sim' block...\n----->Finished 'cal jaccard_distance sim' block, time used:257.73s.\n----->Started 'cal braycurtis_distance sim' block...\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/scipy/spatial/distance.py:1160: RuntimeWarning: invalid value encountered in double_scalars\n  return l1_diff.sum() / l1_sum.sum()\n","name":"stderr"},{"output_type":"stream","text":"----->Finished 'cal braycurtis_distance sim' block, time used:251.68s.\n----->Started 'cal canberra_distance sim' block...\n----->Finished 'cal canberra_distance sim' block, time used:383.57s.\n----->Started 'cal cityblock_distance sim' block...\n----->Finished 'cal cityblock_distance sim' block, time used:189.13s.\n----->Started 'cal euclidean_distance sim' block...\n----->Finished 'cal euclidean_distance sim' block, time used:248.57s.\n----->Started 'cal minkowski_distance sim' block...\n----->Finished 'cal minkowski_distance sim' block, time used:420.52s.\n----->Finished 'cal sent vec' block, time used:3090.11s.\nsaved senVecavgSimV1 feature to ./stage1/output/word2vec/online_testWord2vec_senVecavgSimV1.csv.gz\n----->Finished 'extract senVecavgSimV1 feature' block, time used:3244.02s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_word2vec_sen_vec_sim and not OFFLINE:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, \n        \"senVec{}SimV1\".format(process_word2vec_sen_vec_mode), \n        process_func=process_word2vec_sen_vec, names=ORI_TEST_NAMES, dtype=ORI_TEST_DTYPE, \n        process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id'], \n        drop_last_cols=['query', 'title'])","execution_count":12},{"metadata":{"id":"357E526329B64A29B946DE1E987F3288","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"./stage1/output/word2vec/debug_trainWord2vec_senVecavgSim.csv.gz\")","execution_count":74},{"metadata":{"id":"F8BC5809EC534E3680559FD378A629F1","mdEditEnable":false},"cell_type":"markdown","source":"### word2vec其他特征"},{"metadata":{"id":"E2F0C59AC64C48FB88C1DD00F8E6792F","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"word2vec_model_norm = None\nregen_word2vec_sen_vec_other = False\nprocess_word2vec_sen_vec_mode = \"avg\"","execution_count":10},{"metadata":{"id":"335A3AC4342F45A8B6409E565BD59C0F","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def norm_wmd(s1, s2):\n    global word2vec_model_norm\n    dis = np.nan_to_num(word2vec_model_norm.wmdistance(s1, s2))\n    return dis if dis<100 else 100","execution_count":11},{"metadata":{"id":"A75CAA83ECB7483A85E18278583B7282","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def wmd(s1, s2):\n    global word2vec_model\n    dis = np.nan_to_num(word2vec_model.wmdistance(s1, s2))\n    return dis if dis<100 else 100","execution_count":12},{"metadata":{"id":"D37E5667CBE84D61BD94A54807D4AC59","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def run_word2vec_sen_vec_wmd(df, ngram, prefix, name):\n    q_list = df['query'].apply(ngram)\n    t_list = df['title'].apply(ngram)\n    df['%s_wmd%s' % (prefix, name)] = cal_sim(q_list, t_list, wmd)\n    df['%s_normWmd%s' % (prefix, name)] = cal_sim(q_list, t_list, norm_wmd)\n    del q_list, t_list\n    gc.collect()\n    return df","execution_count":13},{"metadata":{"id":"DFD1EBFA93D54C63B798ACFD526C3F8C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def run_word2vec_sen_vec_sk(df, func, q_sen_vec, t_sen_vec, prefix, name):\n    df['%s_q%s' % (prefix, name)] = list(map(func, q_sen_vec))\n    df['%s_t%s' % (prefix, name)] = list(map(func, t_sen_vec))\n    df['%s_%s-diff'%(prefix, name)] = list(map(lambda a, b: abs(a-b), df['%s_q%s' % (prefix, name)], df['%s_t%s' % (prefix, name)]))\n    df['%s_%s-max'%(prefix, name)] = list(map(lambda a, b: max(a, b), df['%s_q%s' % (prefix, name)], df['%s_t%s' % (prefix, name)]))\n    df['%s_%s-min'%(prefix, name)] = list(map(lambda a, b: min(a, b), df['%s_q%s' % (prefix, name)], df['%s_t%s' % (prefix, name)]))\n    df['%s_%s-avg'%(prefix, name)] = list(map(lambda a, b: (a+b)/2, df['%s_q%s' % (prefix, name)], df['%s_t%s' % (prefix, name)]))\n    return df","execution_count":14},{"metadata":{"id":"3CC24C2852BD4FCFAF855DA809F7A497","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def process_word2vec_sen_vec_other(df, prefix, savefile):\n    \n    global word2vec_model_norm, word2vec_model_file\n    word2vec_model_norm = KeyedVectors.load(word2vec_model_file)\n    word2vec_model_norm.init_sims(replace=True)\n    \n    # with Timer(\"cal uni-wmd dis\"):\n    #     df = run_word2vec_sen_vec_wmd(df, ngram_utils.unigrams, prefix, \"Unigrams\")\n    # with Timer(\"cal bi-wmd dis\"):\n    #     df = run_word2vec_sen_vec_wmd(df, ngram_utils.bigrams, prefix, \"Bigrams\")\n        \n    with Timer(\"cal sent vec\"):\n        global process_word2vec_sen_vec_mode\n        if process_word2vec_sen_vec_mode == \"avg\":\n            q_sen_vec = list(map(sent2vec, df[\"query\"]))\n            t_sen_vec = list(map(sent2vec, df[\"title\"]))\n        elif process_word2vec_sen_vec_mode == \"tfidf\":\n            q_sen_vec = list(map(sent2vec1, df[\"query\"]))\n            t_sen_vec = list(map(sent2vec1, df[\"title\"]))\n    \n    with Timer(\"cal skew\"):\n        df = run_word2vec_sen_vec_sk(df, skew, q_sen_vec, t_sen_vec, prefix, \"Skew\")\n    with Timer(\"cal kurtosis\"):\n        df = run_word2vec_sen_vec_sk(df, kurtosis, q_sen_vec, t_sen_vec, prefix, \"Kurtosis\")\n        \n    del q_sen_vec, t_sen_vec\n    gc.collect()\n    \n    return df","execution_count":15},{"metadata":{"id":"DBD6C46BAC0345B68376EC52A2203471","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract senVecavgSK feature' block...\n----->Started 'process chunk' block...\nMem. usage decreased to 15.26 Mb (0.0% reduction)\n----->Started 'cal sent vec' block...\n----->Finished 'cal sent vec' block, time used:202.48s.\n----->Started 'cal skew' block...\n----->Finished 'cal skew' block, time used:548.07s.\n----->Started 'cal kurtosis' block...\n----->Finished 'cal kurtosis' block, time used:406.1s.\nsaved senVecavgSK feature to ./stage1/output/word2vec/online_trainWord2vec_senVecavgSK.csv.gz\n----->Finished 'process chunk' block, time used:1233.19s.\n----->Started 'process chunk' block...\nMem. usage decreased to 15.26 Mb (0.0% reduction)\n----->Started 'cal sent vec' block...\n----->Finished 'cal sent vec' block, time used:203.53s.\n----->Started 'cal skew' block...\n----->Finished 'cal skew' block, time used:548.57s.\n----->Started 'cal kurtosis' block...\n----->Finished 'cal kurtosis' block, time used:414.55s.\nsaved senVecavgSK feature to ./stage1/output/word2vec/online_trainWord2vec_senVecavgSK.csv.gz\n----->Finished 'process chunk' block, time used:1243.65s.\n----->Started 'process chunk' block...\nMem. usage decreased to 15.26 Mb (0.0% reduction)\n----->Started 'cal sent vec' block...\n----->Finished 'cal sent vec' block, time used:200.38s.\n----->Started 'cal skew' block...\n----->Finished 'cal skew' block, time used:528.22s.\n----->Started 'cal kurtosis' block...\n----->Finished 'cal kurtosis' block, time used:409.32s.\nsaved senVecavgSK feature to ./stage1/output/word2vec/online_trainWord2vec_senVecavgSK.csv.gz\n----->Finished 'process chunk' block, time used:1213.57s.\n----->Started 'process chunk' block...\nMem. usage decreased to 15.26 Mb (0.0% reduction)\n----->Started 'cal sent vec' block...\n----->Finished 'cal sent vec' block, time used:202.69s.\n----->Started 'cal skew' block...\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_word2vec_sen_vec_other:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \n        \"senVec{}SK\".format(process_word2vec_sen_vec_mode), \n        process_func=process_word2vec_sen_vec_other, names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, \n        process_chunkly=True, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_id', 'query_title_id', 'label'], \n        drop_last_cols=['query', 'title'])\n# Finished 'extract senVecavgSim feature' block, time used:4160.86s.","execution_count":19},{"metadata":{"id":"152557B408BF4CEEA6C5FE653C6CD8D6","mdEditEnable":false},"cell_type":"markdown","source":"## Magic特征"},{"metadata":{"id":"4C2E0149E5FE465EBCB250DEAD7FB466","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"total 7.4G\r\ndrwxr-xr-x 2 kesci root  4.0K Jun 30 01:44 .\r\ndrwxr-xr-x 7 kesci root  4.0K Jun 19 09:08 ..\r\n-rw-r--r-- 1 kesci users 5.8K Jun 26 13:43 debug_trainMagic_ctrRateGlobal.csv.gz\r\n-rw-r--r-- 1 kesci users 122K Jun 26 13:43 debug_trainMagic_ctrRateLocal.csv.gz\r\n-rw-r--r-- 1 kesci users  31M Jun 27 12:19 debug_trainMagic_diffSetLenCharsBicharsTitle.npy\r\n-rw-r--r-- 1 kesci users 2.7M Jun 27 12:26 debug_trainMagic_diffSetLenChars.csv.gz\r\n-rw-r--r-- 1 kesci users 6.0M Jun 27 12:18 debug_trainMagic_diffSetLenCharsUnicharsTitle.npy\r\n-rw-r--r-- 1 kesci users 970K Jun 26 13:19 debug_trainMagic_diffSetLen.csv.gz\r\n-rw-r--r-- 1 kesci users 448K Jun 27 12:11 debug_trainMagic_diffSetLenUnichars.csv.gz\r\n-rw-r--r-- 1 kesci users 6.0M Jun 27 12:11 debug_trainMagic_diffSetLenUnicharsUnicharsTitle.npy\r\n-rw-r--r-- 1 kesci users  89M Jun 24 15:16 debug_trainMagic_diffSetSimBigramsTitle.npy\r\n-rw-r--r-- 1 kesci users  31M Jun 27 12:16 debug_trainMagic_diffSetSimCharsBicharsTitle.npy\r\n-rw-r--r-- 1 kesci users 3.0M Jun 27 12:26 debug_trainMagic_diffSetSimChars.csv.gz\r\n-rw-r--r-- 1 kesci users 6.0M Jun 27 12:15 debug_trainMagic_diffSetSimCharsUnicharsTitle.npy\r\n-rw-r--r-- 1 kesci users  15M Jun 26 13:43 debug_trainMagic_diffSetSim.csv.gz\r\n-rw-r--r-- 1 kesci users 113M Jun 24 15:25 debug_trainMagic_diffSetSimTrigramsTitle.npy\r\n-rw-r--r-- 1 kesci users 448K Jun 27 12:10 debug_trainMagic_diffSetSimUnichars.csv.gz\r\n-rw-r--r-- 1 kesci users 6.0M Jun 27 12:10 debug_trainMagic_diffSetSimUnicharsUnicharsTitle.npy\r\n-rw-r--r-- 1 kesci users  47M Jun 24 15:10 debug_trainMagic_diffSetSimUnigramsTitle.npy\r\n-rw-r--r-- 1 kesci users  28M Jun 29 15:56 debug_trainMagic_diffSetTfidfLen.csv.gz\r\n-rw-r--r-- 1 kesci users  62K Jun 26 13:40 debug_trainMagic_queryFreq.csv.gz\r\n-rw-r--r-- 1 kesci users  95K Jun 21 13:59 online_testMagic_ctrRateGlobal.csv.gz\r\n-rw-r--r-- 1 kesci users 1.2M Jun 21 14:09 online_testMagic_ctrRateLocal.csv.gz\r\n-rw-r--r-- 1 kesci users  11M Jun 26 16:03 online_testMagic_diffSetLen.csv.gz\r\n-rw-r--r-- 1 kesci users 931M Jun 22 09:34 online_testMagic_diffSetSimBigramsTitle.npy\r\n-rw-r--r-- 1 kesci users 151M Jun 26 12:17 online_testMagic_diffSetSim.csv.gz\r\n-rw-r--r-- 1 kesci users 1.2G Jun 22 10:01 online_testMagic_diffSetSimTrigramsTitle.npy\r\n-rw-r--r-- 1 kesci users 448M Jun 27 23:15 online_testMagic_diffSetSimUnicharsBicharsTitle.npy\r\n-rw-r--r-- 1 kesci users  38M Jun 27 23:20 online_testMagic_diffSetSimUnichars.csv.gz\r\n-rw-r--r-- 1 kesci users  74M Jun 27 23:02 online_testMagic_diffSetSimUnicharsUnicharsTitle.npy\r\n-rw-r--r-- 1 kesci users 505M Jun 22 09:13 online_testMagic_diffSetSimUnigramsTitle.npy\r\n-rw-r--r-- 1 kesci users 602K Jun 26 11:19 online_testMagic_queryFreq.csv.gz\r\n-rw-r--r-- 1 kesci users 190K Jun 21 13:59 online_trainMagic_ctrRateGlobal.csv.gz\r\n-rw-r--r-- 1 kesci users 2.4M Jun 21 14:06 online_trainMagic_ctrRateLocal.csv.gz\r\n-rw-r--r-- 1 kesci users  19M Jun 26 16:01 online_trainMagic_diffSetLen.csv.gz\r\n-rw-r--r-- 1 kesci users 1.8G Jun 22 07:20 online_trainMagic_diffSetSimBigramsTitle.npy\r\n-rw-r--r-- 1 kesci users 620M Jun 27 22:45 online_trainMagic_diffSetSimCharsBicharsTitle.npy\r\n-rw-r--r-- 1 kesci users  60M Jun 27 22:53 online_trainMagic_diffSetSimChars.csv.gz\r\n-rw-r--r-- 1 kesci users 121M Jun 27 19:24 online_trainMagic_diffSetSimCharsUnicharsTitle.npy\r\n-rw-r--r-- 1 kesci users 294M Jun 26 12:02 online_trainMagic_diffSetSim.csv.gz\r\n-rw-r--r-- 1 kesci users 929M Jun 22 06:42 online_trainMagic_diffSetSimUnigramsTitle.npy\r\n-rw-r--r-- 1 kesci users 1.2M Jun 26 11:18 online_trainMagic_queryFreq.csv.gz\r\n","name":"stdout"}],"source":"feature_save_dir = base_feature_save_dir + \"magic/\"\ntrain_feature_prefix = base_prefix + \"trainMagic\"\ntest_feature_prefix = base_prefix + \"testMagic\"\n! ls -alh ./stage1/output/magic/\n! rm ./stage1/output/magic/online_testMagic_diffSetSimTrigramsTitle.npy","execution_count":12},{"metadata":{"id":"8720622D1CC5429E8E94166BED65485F","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"[list(['3567_31451', '59_193', '663_82', '66324_32684', '27_37136', '31451_27', '43993_59', '37136_663', '288_33', '87_87', '18225_87', '82_18225', '33_43993', '1017_3567', '27_288'])\n list(['660_12875', '31_4126', '10964_799', '147_31', '9669_15457', '27_660', '12875_9669', '4126_15', '14514_27', '799_14514'])]\n","name":"stdout"}],"source":"tmp = np.load(\"./stage1/output/magic/debug_trainMagic_diffSetSimBigramsTitle.npy\", allow_pickle=True)\nprint(tmp[:2])","execution_count":20},{"metadata":{"id":"C7ABCC63E7574E65ACB15A44075DCBB5","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"[list(['33', '37136', '1017', '59', '87', '663', '18225', '3567'])\n list(['15457', '4126', '9669', '799', '660', '12875', '147', '14514'])]\n","name":"stdout"}],"source":"tmp = np.load(\"./stage1/output/magic/debug_trainMagic_diffSetSimUnigramsTitle.npy\", allow_pickle=True)\nprint(tmp[:2])","execution_count":21},{"metadata":{"id":"415BAFF0C7C146A587DB4BA7DD677742","mdEditEnable":false},"cell_type":"markdown","source":"### 提取query频率"},{"metadata":{"id":"82F529A01DFF4B1483991308775A9972","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"regen_query_freq = False\ntrain_query_freq = train_feature_prefix + \"_queryFreq\"\ntrain_freq_save_file = feature_save_dir+train_query_freq+\".csv.gz\"\nif not OFFLINE:\n    test_query_freq = test_feature_prefix + \"_queryFreq\"\n    test_freq_save_file = feature_save_dir+test_query_freq+\".csv.gz\"","execution_count":32},{"metadata":{"id":"52FD73F8CA96480F8289B30CE1207864","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def ExtractFreq(sourcefile, savefile, names, dtype, group_by, sort_col, feature_name):\n    df = ReadCSV(sourcefile, names=names, dtype=dtype, iterator=False)\n    grouped = df.groupby(group_by, as_index=False)[sort_col].count()\n    res = np.concatenate(list(map(lambda x: [x]*x, grouped[sort_col])))\n    tmp = pd.DataFrame({\n        feature_name: res\n    })\n    tmp.to_csv(savefile, compression=\"gzip\", index=None)\n    print(\"Feature saved to {}\".format(savefile))\n    del df, grouped, res, tmp\n    gc.collect()","execution_count":29},{"metadata":{"id":"3DC627A6B95E47B8AF09E6D22B442777","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"Feature saved to ./stage1/output/magic/debug_trainMagic_queryFreq.csv.gz\n","name":"stdout"}],"source":"if regen_query_freq:\n    ExtractFreq(train_file, \n        train_freq_save_file, \n        ORI_TRAIN_NAMES, \n        ORI_TRAIN_DTYPE,\n        \"query_id\",\n        \"query_title_id\",\n        \"query_freq\")","execution_count":30},{"metadata":{"id":"B64F181229BD4E02B1D613A1F334D5E6","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"if regen_query_freq and not OFFLINE:\n    ExtractFreq(test_file, \n        test_freq_save_file, \n        ORI_TEST_NAMES, \n        ORI_TEST_DTYPE,\n        \"query_id\",\n        \"query_title_id\",\n        \"query_freq\")","execution_count":31},{"metadata":{"id":"7B0012A7D9154E67B7490EE4F2A87D40","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"./stage1/output/magic/debug_trainMagic_queryFreq.csv.gz\", print_rows=20)","execution_count":96},{"metadata":{"id":"050487282F37427AA2167D5F2E9A50A4","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"./stage1/output/magic/debug_trainMagic_queryFreq.csv.gz\")","execution_count":25},{"metadata":{"id":"BFF2D03C630F454E8DD727509F512A40","collapsed":false,"scrolled":false,"mdEditEnable":false},"cell_type":"markdown","source":"### 提取差集特征"},{"metadata":{"id":"07FF17550E1741328E64E5A1D1CB3523","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"regen_diff_sim = True\r\nsimilar_arr = [\r\n    dist_utils.dice_ratio,\r\n    dist_utils.jaccard_ratio,\r\n    dist_utils.edit_seq_ratio,\r\n    dist_utils.edit_set_ratio,\r\n]","execution_count":33},{"metadata":{"id":"6EDBC7C64C1344E881BC1E5083EAD3D1","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def findDiff(arr, ngram):\n    set_list = list(map(lambda x: set(ngram(x)), arr))\n    res = []\n    for i, _ in enumerate(set_list):\n        result = _\n        for __ in set_list:\n            if _ != __:\n                result = result.difference(__)\n        res.append(list(result))\n    return res","execution_count":34},{"metadata":{"id":"005E57B7CEE743A5B02245F3E625C429","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def GetDiffSet(query_id, title, ngram):\r\n    tmp, res = [], []\r\n    for i in range(len(query_id)):\r\n      if i == 0:\r\n        tmp.append(title[i])\r\n      else:\r\n        if query_id[i] == query_id[i-1]:\r\n          tmp.append(title[i])\r\n        else:\r\n          res.append(findDiff(tmp, ngram))\r\n          tmp = [title[i]]\r\n    res.append(findDiff(tmp, ngram))\r\n    result = []\r\n    for _ in res:\r\n        result.extend(_)\r\n    return result","execution_count":35},{"metadata":{"id":"82F34AF6CED54AD1816859258246BA3C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def run_diff_set_sim(df, ngram, prefix, savefile, name):\n    with Timer(\"cal diff set\"):\n        t_savefile = savefile + name +\"Title.npy\"\n        q_list = df['query'].apply(ngram)\n        if os.path.exists(t_savefile):\n            t_list = np.load(t_savefile, allow_pickle=True)\n        else:\n            t_list = GetDiffSet(df[\"query_id\"], df[\"title\"], ngram)\n            np.save(t_savefile, t_list) # 存储处理后的title列表\n            print(\"File saved to {}\".format(t_savefile))\n    ## 长度特征\n    with Timer(\"extract similarity\"):\n        for _ in similar_arr:\n            name = _.__name__\n            with Timer(\"cal {} sim\".format(name)):\n                df[\"{}_diffSetSim{}\".format(prefix, name)] = cal_sim(q_list, t_list, _)\n    del q_list, t_list\n    gc.collect()\n    return df\n    \ndef process_diff_set_sim(df, prefix, savefile):\n    # df = run_diff_set_sim(df, ngram_utils.unichars, '%s_%s' % (prefix, 'Unichars'), savefile, \"Unichars\")\n    # df = run_diff_set_sim(df, ngram_utils.bichars, '%s_%s' % (prefix, 'Bichars'), savefile, \"Bichars\")\n    df = run_diff_set_sim(df, ngram_utils.unigrams, '%s_%s' % (prefix, 'unigrams'), savefile, \"Unigrams\")\n    df = run_diff_set_sim(df, ngram_utils.bigrams, '%s_%s' % (prefix, 'bigrams'), savefile, \"Bigrams\")\n    df = run_diff_set_sim(df, ngram_utils.trigrams, '%s_%s' % (prefix, 'trigrams'), savefile, \"Trigrams\")\n    return df","execution_count":36},{"metadata":{"id":"53D8E51301584D7C8F33FA721597ED12","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract diffSetSim feature' block...\nMem. usage decreased to  9.54 Mb (0.0% reduction)\n----->Started 'cal diff set' block...\n----->Finished 'cal diff set' block, time used:3.54s.\n----->Started 'extract similarity' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:1.82s.\n----->Started 'cal jaccard_ratio sim' block...\n----->Finished 'cal jaccard_ratio sim' block, time used:1.6s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:3.21s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:3.95s.\n----->Finished 'extract similarity' block, time used:10.58s.\n----->Started 'cal diff set' block...\n----->Finished 'cal diff set' block, time used:5.08s.\n----->Started 'extract similarity' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:1.74s.\n----->Started 'cal jaccard_ratio sim' block...\n----->Finished 'cal jaccard_ratio sim' block, time used:1.45s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:5.54s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:5.75s.\n----->Finished 'extract similarity' block, time used:14.47s.\n----->Started 'cal diff set' block...\n----->Finished 'cal diff set' block, time used:5.4s.\n----->Started 'extract similarity' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:1.98s.\n----->Started 'cal jaccard_ratio sim' block...\n----->Finished 'cal jaccard_ratio sim' block, time used:1.5s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:6.31s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:6.8s.\n----->Finished 'extract similarity' block, time used:16.6s.\nsaved diffSetSim feature to ./stage1/output/magic/debug_trainMagic_diffSetSim.csv.gz\n----->Finished 'extract diffSetSim feature' block, time used:108.09s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_diff_sim:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"diffSetSim\", \n        process_func=process_diff_set_sim, \n        names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['label', 'query_title_id'], drop_last_cols=['query_id', 'query', 'title'])","execution_count":37},{"metadata":{"id":"48F23D753316423383948D9982C42BAC","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"./stage1/output/magic/debug_trainMagic_diffSetSim1.csv.gz\")","execution_count":80},{"metadata":{"id":"9FEE73DAEDD24A51A5691A873471A577","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract diffSetSim feature' block...\nMem. usage decreased to 95.37 Mb (0.0% reduction)\n----->Started 'cal diff set' block...\n----->Finished 'cal diff set' block, time used:22.76s.\n----->Started 'extract similarity' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:12.34s.\n----->Started 'cal jaccard_ratio sim' block...\n----->Finished 'cal jaccard_ratio sim' block, time used:11.17s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:24.96s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:29.84s.\n----->Finished 'extract similarity' block, time used:78.31s.\n----->Started 'cal diff set' block...\n----->Finished 'cal diff set' block, time used:40.83s.\n----->Started 'extract similarity' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:15.5s.\n----->Started 'cal jaccard_ratio sim' block...\n----->Finished 'cal jaccard_ratio sim' block, time used:13.51s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:42.08s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:44.11s.\n----->Finished 'extract similarity' block, time used:115.2s.\n----->Started 'cal diff set' block...\n----->Finished 'cal diff set' block, time used:41.25s.\n----->Started 'extract similarity' block...\n----->Started 'cal dice_ratio sim' block...\n----->Finished 'cal dice_ratio sim' block, time used:16.01s.\n----->Started 'cal jaccard_ratio sim' block...\n----->Finished 'cal jaccard_ratio sim' block, time used:13.01s.\n----->Started 'cal edit_seq_ratio sim' block...\n----->Finished 'cal edit_seq_ratio sim' block, time used:49.86s.\n----->Started 'cal edit_set_ratio sim' block...\n----->Finished 'cal edit_set_ratio sim' block, time used:55.45s.\n----->Finished 'extract similarity' block, time used:134.33s.\nsaved diffSetSim feature to ./stage1/output/magic/online_testMagic_diffSetSim.csv.gz\n----->Finished 'extract diffSetSim feature' block, time used:818.14s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nif regen_diff_sim:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, \"diffSetSim\", \n        process_func=process_diff_set_sim, \n        names=ORI_TEST_NAMES, dtype=ORI_TEST_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n        drop_first_cols=['query_title_id'], drop_last_cols=['query_id', 'query', 'title'])","execution_count":39},{"metadata":{"id":"B7F20AA36FE8477B8AE679790125C329","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# AnalysisCSV(\"./stage1/output/magic/online_trainMagic_diffSetSim.csv.gz\")","execution_count":1},{"metadata":{"id":"50F54926A22A41848D714A9F15C7A3EF","mdEditEnable":false},"cell_type":"markdown","source":"### 差集的tfidf"},{"metadata":{"id":"9973C681F5D7410684783A39036696B4","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"from np_utils import try_divide\ntfidf_model_file = \"./stage1/output/vector_space/debug_tfidf_model.bin\"","execution_count":52},{"metadata":{"id":"CED39BF2E31140129D5F4E6A0205D2AD","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"with open(tfidf_model_file, \"rb\") as ff:\n    tfidf_model = pickle.load(ff)\n    tfidf_vocab = tfidf_model.vocabulary_\n    tfidf_idf = tfidf_model.idf_","execution_count":35},{"metadata":{"id":"CF1C36C62C7042B080742936677D63A2","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def get_uni_sum_tfidf(ngrams):\n    l = len(ngrams)\n    return sum([tfidf_idf[tfidf_vocab[_]]/l for _ in ngrams if _ in tfidf_vocab])","execution_count":48},{"metadata":{"id":"B3F0C9A3CCD3497C82A1C50FC274C73E","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def run_diff_set_tfidf_len(df, ngram, prefix, savefile, name):\n    with Timer(\"cal diff set\"):\n        t_savefile = savefile + name +\"Title.npy\"\n        t_savefile = t_savefile.replace(\"TfidfLen\", \"Sim\")\n        if os.path.exists(t_savefile):\n            t_list = np.load(t_savefile, allow_pickle=True)\n        else:\n            pass\n    ## 长度特征\n    with Timer(\"extract similarity\"):\n        t_vec_len = list(map(get_uni_sum_tfidf, t_list))\n        q_vec_len = np.array(tfidf_model.transform(df[\"query\"]).sum(1)).squeeze()\n        df['%s_TLen1' % prefix] = t_vec_len\n        df['%s_QTLenRatio1'%prefix] = list(map(lambda a, b: try_divide(a, b), q_vec_len, t_vec_len))\n        df['%s_TQLenRatio1'%prefix] = list(map(lambda a, b: try_divide(b, a), q_vec_len, t_vec_len))\n        df['%s_QTDiff1'%prefix] = list(map(lambda a, b: abs(a-b), q_vec_len, t_vec_len))\n        df['%s_QTMax1'%prefix] = list(map(lambda a, b: max(a, b), q_vec_len, t_vec_len))\n        df['%s_QTMin1'%prefix] = list(map(lambda a, b: min(a, b), q_vec_len, t_vec_len))\n        df['%s_QTAvg1'%prefix] = list(map(lambda a, b: (a+b)/2, q_vec_len, t_vec_len))\n        df['%s_QTMulti1'%prefix] = list(map(lambda a, b: a*b, q_vec_len, t_vec_len))\n    del t_list, t_vec_len, q_vec_len\n    gc.collect()\n    return df\n    \ndef process_diff_set_tfidf_len(df, prefix, savefile):\n    # df = run_diff_set_sim(df, ngram_utils.unichars, '%s_%s' % (prefix, 'Unichars'), savefile, \"Unichars\")\n    # df = run_diff_set_sim(df, ngram_utils.bichars, '%s_%s' % (prefix, 'Bichars'), savefile, \"Bichars\")\n    df = run_diff_set_tfidf_len(df, ngram_utils.unigrams, '%s_%s' % (prefix, 'unigrams'), savefile, \"Unigrams\")\n    # df = run_diff_set_sim(df, ngram_utils.bigrams, '%s_%s' % (prefix, 'bigrams'), savefile, \"Bigrams\")\n    return df","execution_count":50},{"metadata":{"id":"E07D336F0F2B468C84098E12D421F7B8","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract diffSetTfidfLen feature' block...\nMem. usage decreased to  9.54 Mb (0.0% reduction)\n----->Started 'cal diff set' block...\n----->Finished 'cal diff set' block, time used:2.95s.\n----->Started 'extract similarity' block...\n----->Finished 'extract similarity' block, time used:21.96s.\nsaved diffSetTfidfLen feature to ./stage1/output/magic/debug_trainMagic_diffSetTfidfLen.csv.gz\n----->Finished 'extract diffSetTfidfLen feature' block, time used:51.98s.\n","name":"stdout"}],"source":"# 提取训练数据特征\nExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"diffSetTfidfLen\", \n    process_func=process_diff_set_tfidf_len, \n    names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n    drop_first_cols=['label', 'query_title_id'], drop_last_cols=['query_id', 'query', 'title'])","execution_count":53},{"metadata":{"id":"2570D7A6D15A40A4BDC5AA14272C062F","mdEditEnable":false},"cell_type":"markdown","source":"### 点击率特征"},{"metadata":{"id":"11F0EF4C03A04CA982BE108D9CB0B36B","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"regen_ctr_rate = True\nstat = {}","execution_count":38},{"metadata":{"id":"4C8A242C8C5544A69D769E24E1EF4053","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def ExtractGlobalCTR(df, prefix, savefile):\n    # 全局点击率\n    tmp = df[\"label\"].value_counts()\n    global_click_rate = tmp[1] / (tmp[0] + tmp[1])\n    feature_name = \"{}_globalCTR\".format(prefix)\n    df[feature_name] = [global_click_rate] * df.shape[0]\n    if not OFFLINE:\n        prefix = prefix.replace(\"train\", \"test\")\n        feature_name = feature_name.replace(\"train\", \"test\")\n        savefile = savefile.replace(\"train\", \"test\")+\".csv.gz\"\n        test_df = pd.DataFrame({\n            feature_name: [global_click_rate] * 5000000\n        }).to_csv(savefile, index=None, compression=\"gzip\")\n        print(\"Feature saved to {}\".format(savefile))\n        del test_df\n    del tmp\n    gc.collect()\n    return df","execution_count":39},{"metadata":{"id":"704B808FBD8C445289C5CD1F99330E40","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract ctrRateGlobal feature' block...\nMem. usage decreased to  2.38 Mb (68.7% reduction)\nsaved ctrRateGlobal feature to ./stage1/output/magic/debug_trainMagic_ctrRateGlobal.csv.gz\n----->Finished 'extract ctrRateGlobal feature' block, time used:4.06s.\n","name":"stdout"}],"source":"if regen_ctr_rate:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"ctrRateGlobal\", \n    ExtractGlobalCTR, names=ORI_TRAIN_NAMES,\n    dtype=None, process_chunkly=False, \n    drop_first_cols=['query_title_id', 'query', 'title'], drop_last_cols=['query_id', 'label'])","execution_count":40},{"metadata":{"id":"39BF45B506314BF9A8D04616B20D221A","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def ExtractLocalCTR(df, prefix, savefile):\n    global stat\n    grouped = df.groupby(\"query_id\", as_index=False)\n    count = grouped.size().values\n    if not stat:\n        label = grouped[\"label\"].sum()[\"label\"].values.astype(\"int32\")\n        for _ in range(len(count)):\n            item_len = count[_]\n            if item_len not in stat:\n                stat[item_len] = [1, label[_]]\n            else:\n                stat[item_len][0] += 1\n                stat[item_len][1] += label[_]\n        del label\n        print(stat)\n    res = [[ stat[_][1] / (_ * stat[_][0])]*_ for _ in count]\n    result = []\n    for _ in res:\n        result.extend(_)\n    df[\"{}_localCTR\".format(prefix)] = result\n    del res, grouped\n    gc.collect()\n    return df","execution_count":41},{"metadata":{"id":"33E353FEFC7D4577A377992D5FE489C5","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract ctrRateLocal feature' block...\nMem. usage decreased to  2.38 Mb (68.7% reduction)\n{11: [1834, 4011], 17: [658, 1727], 13: [1236, 2857], 3: [33728, 44915], 20: [4540, 12425], 4: [5026, 7386], 5: [4753, 7609], 7: [4878, 8538], 6: [4425, 7450], 8: [4544, 8524], 9: [2336, 4671], 12: [1523, 3377], 14: [1023, 2473], 19: [517, 1450], 16: [795, 2057], 15: [886, 2202], 10: [1983, 4125], 18: [577, 1578]}\nsaved ctrRateLocal feature to ./stage1/output/magic/debug_trainMagic_ctrRateLocal.csv.gz\n----->Finished 'extract ctrRateLocal feature' block, time used:5.16s.\n","name":"stdout"}],"source":"if regen_ctr_rate:\n    ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"ctrRateLocal\", \n    ExtractLocalCTR, names=ORI_TRAIN_NAMES,\n    dtype=None, process_chunkly=False, \n    drop_first_cols=['query_title_id', 'query', 'title'], drop_last_cols=['query_id', 'label'])","execution_count":42},{"metadata":{"id":"6360746B670045F4BB764785F47B713C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"if not OFFLINE and regen_ctr_rate:\n    ExtractFeature(test_file, feature_save_dir, test_feature_prefix, \"ctrRateLocal\", \n    ExtractLocalCRT, names=ORI_TEST_NAMES,\n    dtype=None, process_chunkly=False, \n    drop_first_cols=['query_title_id', 'query', 'title'], drop_last_cols=['query_id'])","execution_count":43},{"metadata":{"id":"553A6881D6BF4F1490D4B4C30521704C","mdEditEnable":false},"cell_type":"markdown","source":"### diffSetLen"},{"metadata":{"id":"06A4B0993A304A4683B8A34D545412E0","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def run_diff_set_len(df, ngram, prefix, savefile, name):\n    with Timer(\"cal diff set\"):\n        t_savefile = savefile + name +\"Title.npy\"\n        t_savefile = t_savefile.replace(\"Len\", \"Sim\")\n        q_list = df['query'].apply(ngram)\n        print(t_savefile)\n        if os.path.exists(t_savefile):\n            t_list = np.load(t_savefile, allow_pickle=True)\n        else:\n            pass\n            # t_list = GetDiffSet(df[\"query_id\"], df[\"title\"], ngram)\n            # np.save(t_savefile, t_list) # 存储处理后的title列表\n            # print(\"File saved to {}\".format(t_savefile))\n    ## 长度特征\n    with Timer(\"extract length rel\"):\n        q_len = np.vectorize(len)(q_list)\n        t_len = np.vectorize(len)(t_list)\n        df['%s_difft-len' % prefix] = t_len\n        df['%s_diffqt-len-radio'%prefix] = list(map(lambda a, b: a/b, q_len, t_len))\n        df['%s_difftq-len-radio'%prefix] = list(map(lambda a, b: b/a, q_len, t_len))\n        df['%s_diffqt-diff'%prefix] = list(map(lambda a, b: abs(a-b), q_len, t_len))\n        df['%s_diffqt-max'%prefix] = list(map(lambda a, b: max(a, b), q_len, t_len))\n        df['%s_diffqt-min'%prefix] = list(map(lambda a, b: min(a, b), q_len, t_len))\n        df['%s_diffqt-avg'%prefix] = list(map(lambda a, b: (a+b)/2, q_len, t_len))\n    del q_list, t_list, q_len\n    gc.collect()\n    return df\n    \ndef process_diff_set_len(df, prefix, savefile):\n    df = run_diff_set_sim(df, ngram_utils.unichars, '%s_%s' % (prefix, 'Unichars'), savefile, \"Unichars\")\n    df = run_diff_set_sim(df, ngram_utils.bichars, '%s_%s' % (prefix, 'Bichars'), savefile, \"Bichars\")\n    # df = run_diff_set_len(df, ngram_utils.unigrams, '%s_%s' % (prefix, 'unigrams'), savefile, \"Unigrams\")\n    # df = run_diff_set_len(df, ngram_utils.bigrams, '%s_%s' % (prefix, 'bigrams'), savefile, \"Bigrams\")\n    # df = run_diff_set_len(df, ngram_utils.trigrams, '%s_%s' % (prefix, 'trigrams'), savefile, \"Trigrams\")\n    return df","execution_count":16},{"metadata":{"id":"69EF571B968C45C28A20008AEB4F5E65","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract diffSetLen feature' block...\nMem. usage decreased to 190.73 Mb (0.0% reduction)\n----->Started 'cal diff set' block...\n./stage1/output/magic/online_trainMagic_diffSetSimUnigramsTitle.npy\n----->Finished 'cal diff set' block, time used:44.36s.\n----->Started 'extract length rel' block...\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in long_scalars\n","name":"stderr"},{"output_type":"stream","text":"----->Finished 'extract length rel' block, time used:52.39s.\nsaved diffSetLen feature to ./stage1/output/magic/online_trainMagic_diffSetLen.csv.gz\n----->Finished 'extract diffSetLen feature' block, time used:265.21s.\n","name":"stdout"}],"source":"ExtractFeature(train_file, feature_save_dir, train_feature_prefix, \"diffSetLen\", \n    process_func=process_diff_set_len, \n    names=ORI_TRAIN_NAMES, dtype=ORI_TRAIN_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n    drop_first_cols=['label', 'query_title_id'], drop_last_cols=['query_id', 'query', 'title'])","execution_count":17},{"metadata":{"id":"A5E51AB6858D4A328F0943A72658E2C6","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"----->Started 'extract diffSetLen feature' block...\nMem. usage decreased to 95.37 Mb (0.0% reduction)\n----->Started 'cal diff set' block...\n./stage1/output/magic/online_testMagic_diffSetSimUnigramsTitle.npy\n----->Finished 'cal diff set' block, time used:24.19s.\n----->Started 'extract length rel' block...\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:19: RuntimeWarning: divide by zero encountered in long_scalars\n","name":"stderr"},{"output_type":"stream","text":"----->Finished 'extract length rel' block, time used:30.42s.\nsaved diffSetLen feature to ./stage1/output/magic/online_testMagic_diffSetLen.csv.gz\n----->Finished 'extract diffSetLen feature' block, time used:141.74s.\n","name":"stdout"}],"source":"ExtractFeature(test_file, feature_save_dir, test_feature_prefix, \"diffSetLen\", \n    process_func=process_diff_set_len, \n    names=ORI_TEST_NAMES, dtype=ORI_TEST_DTYPE, process_chunkly=False, chunk_size=CHUNK_SIZE, \n    drop_first_cols=['label', 'query_title_id'], drop_last_cols=['query_id', 'query', 'title'])","execution_count":18},{"metadata":{"id":"7B19393D67AA4A93A626B32F31E6296B","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"! ps aux","execution_count":null}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}